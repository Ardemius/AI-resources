= Ressources sur les IA génératives et les LLMs (OpenAI ChatGPT et autres)
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:resourcesdir: ./resources
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 4
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Notes au sujet des IA génératives, ChatGPT, Dall-E et leurs concurrents et alternatives.

== FONCTIONNEMENT DES MODELES DE LANGAGES

* Fonctionnement de ChatGPT
	** https://www.assemblyai.com/blog/how-chatgpt-actually-works/
	** Researchers and developers are working on various approaches to address the *alignment problem in Large Language Models*. +
	ChatGPT is based on the original GPT-3 model, but has been further trained by *using human feedback to guide the learning process* with the specific goal of mitigating the model's misalignment issues. The specific technique used, called *Reinforcement Learning from Human Feedback* (RLHF), is based on previous academic research. +
	ChatGPT represents the first case of use of this technique for a model put into production.

* https://platform.openai.com/docs/models/
	* The OpenAI API is powered by a diverse set of models with different capabilities and price points. You can also make limited customizations to our original base models for your specific use case with fine-tuning.
	* text-davinci-002 : supervised fine-tuning instead of reinforcement learning
	* GPT-3 models can understand and generate natural language. These models were superceded by the more powerful GPT-3.5 generation models. +
	However, the *original GPT-3 base models* (davinci, curie, ada, and babbage) are current the *only models that are available to fine-tune*.
		** Une description des modèles GPT 3 est disponible juste après ce paragraphe

* https://gpttools.com/comparisontool : GPT comparison tool *ON GPT 3 base models* (cf l'explication précédente)
	** This tool lets you try out different settings (engines, *temp*, *top p*, etc.) and compare the results.

* https://platform.openai.com/docs/quickstart
	** Remember that the model predicts which text is most likely to follow the text preceding it.

* https://platform.openai.com/docs/api-reference/chat/create
	** on y trouve une liste de tous les paramètres que l'on peut personnaliser lors de l'appel de l'API d'un modèle de langage.

		*** ATTENTION ! Cf https://platform.openai.com/docs/models/model-endpoint-compatibility, on voit que le endpoint "/v1/chat/completions" concerne les modèles : gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, gpt-3.5-turbo, gpt-3.5-turbo-0301 
		*** PAR CONTRE, le modèle "/v1/fine-tunes" est uniquement associé aux modèles "davinci, curie, babbage, ada" qui doivent être les modèles GPT 3 cf les remarques précédentes.
		*** QUESTION : si on différencie les 2 endpoints précédents, quels sont donc les paramètres associés au "fine-tuning" ? Car il est également possible de personnaliser des paramètres pour le endpoint "/v1/chat/completions"

* Pour un papier de recherche expliquant ce qu'est et ce que n'est pas un modèle de langage (LLM) (TRES BONNE RESSOURCE) : +
Talking about Large Language Models (LLM) : https://arxiv.org/pdf/2212.03551.pdf

	** Une TRES BONNE RESSOURCE expliquant de façon rationnelle et scientifique pourquoi on ne peut pas dire qu'un LLM "pense", "croit" ou "raisonne".

	** DEFINITION D'UN MODELE DE LANGAGE : "a model doing just that one thing: generating statistically likely continuations of word sequences"

	** "But an *LLM* — the bare-bones model — is *not in the business of making judgement*s. It just models what words are likely to follow from what other words"
	** "To build a question-answering system, the LLM simply has to be supplemented with a dialogue management system that queries the model as appropriate."
	** "If we prompt an LLM with “All humans are mortal and Socrates is human therefore”, we are not instructing it to carry out deductive inference. Rather, we are asking it the following question. Given the statistical distribution of words in the public corpus, what words are likely to follow the sequence ‘All humans are mortal and Socrates is human therefore”. A good answer to this would be “Socrates is mortal”."
	** "This ability to learn a general pattern from a few examples in a prompt prefix, and to complete sequences in a way that conforms to that pattern, is sometimes called *in-context learning* or *few-shot prompting*."
	** "As usual, though, it's a good idea to remind ourselves that the question really being posed to the model is of the form “Given the statistical distribution of words in the public corpus, what words are likely to follow the sequence S”, where in this case the sequence S is the chainof-thought prompt prefix plus the user's query. The sequences of tokens that are most likely to 8 follow S will have a similar form to sequences found in the prompt prefix, [...]"
	** "The noteworthy thing is that next token prediction is sufficient for solving previously unseen reasoning problems, even if unreliably. How is this possible? Certainly it would not be possible if the LLM were doing nothing more than cutting-andpasting fragments of text from its training set and assembling them into a response. But this is not what an LLM does. Rather, *an LLM models a distribution that is unimaginably complex, and allows users and applications to sample from that distribution*."
	** p9 : "In this distribution, the most likely continuation of a piece of text containing a reasoning problem, if suitably phrased, will be an attempt to solve that reasoning problem. It will take this form, this overall shape, because that is the form that a generic human response would take. Moreover, because the vast corpus of published human text contains numerous examples of reasoning problems accompanied by correct answers, the most likely continuation will sometimes be the correct answer. When this occurs, it is *not because the correct answer is a likely individual human response*, but *because it is a likely collective human response*."
	** p10 "In contemporary LLM-based applications, it is rare for a language model trained on a textual corpus to be used without further finetuning. This could be supervised fine-tuning on a specialised dataset, or it could be via reinforcement learning from human preferences (RLHF : Reinforcement Learning from Human Feedback)"

* Large Language Model Training in 2023 : https://research.aimultiple.com/large-language-model-training/

	** Bon schéma de l'architecture Transformer : le schéma classique que l'on trouve souvent +
	-> En fait, préférer celui de ce site, le même mais commenté : https://pandia.pro/guide/quest-ce-quun-grand-modele-de-langage-llm-large-language-model/ +
	image:transformer-architecture.png[]

	** Training a large language model from the ground up requires significant investment, a *more economical alternative is to fine-tune* an existing language model to tailor it to your specific use case. +
	*A single training run for GPT-3* is estimated to cost *around $5 million*.

	** After training, the model is evaluated on a test dataset that has not been used as a training data set to measure the model's performance. Based on the evaluation results, the model may require some fine-tuning by adjusting its hyperparameters, changing the architecture, or training on additional data to improve its performance.

	** *Training of an LLM* consists of two parts: *pre-training* and *task-specific training*. 
		*** Pre-training is part of training that enables the model to learn the general rules and dependencies within a language, which takes a significant amount of data, computational power, and time to complete. The large language models discussed in the paper require supercomputer systems with several AI chips (ex. NVIDIA DGX A100 starts at $199,999). Once maintenance and power costs are added, *pre-training of a large language model* is an investment in the magnitude of *millions*.
		*** To make large language models *more accessible* for enterprises, LLM developers are offering services for enterprises looking to leverage language models. NVIDIA's NeMO is an example of these services, which offer pre-trained LLMs for fine-tuning and *specific task training* to suit specific use cases. The specific task training adds an additional layer to the model which requires much less data, power, and time to train; making large models accessible for enterprise use. The new task-specific layer is trained with few-shot learning, which aims for accurate outputs with less training data.

* Large Language Models: Complete Guide in 2023 : https://research.aimultiple.com/large-language-models/

	** *Définition d'un LLM* : Large language models (LLMs) are *foundation models* that utilize *deep learning* in *natural language processing* (NLP) and *natural language generation* (NLG) tasks. +
	For the purpose of helping them learn the complexity and linkages of language, *large language models are pre-trained* on a vast amount of data. Using techniques such as:
		*** Fine-tuning
		*** In-context learning
		*** Zero-/one-/few-shot learning
	+
	these models can be adapted for downstream (specific) tasks (see Figure 2). +
	{sb}
	An LLM is essentially a *Transformer-based neural network*, introduced in an article by Google engineers titled https://arxiv.org/abs/1706.03762[“Attention is All You Need”] in 2017. +
	*The goal of the model is to predict the text that is likely to come next*. The sophistication and performance of a model can be judged by how many parameters it has. A model's parameters are the number of factors it considers when generating output.
		*** Voir également les fiches wikipedia : 
			**** l'architecture Deep Learning Transformer : https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)
			**** "Attention Is All You Need" : https://en.wikipedia.org/wiki/Attention_Is_All_You_Need

				***** "Seq2seq models with attention (including self-attention) still suffered from the same issue with recurrent networks, which is that they are hard to parallelize, *which prevented them to be accelerated on GPUs*." +
				[...] +
				One of its authors, Jakob Uszkoreit, suspected that attention without recurrence is sufficient for language translation, thus the title "attention is ALL you need"
				***** In 2017, the original (100M-sized) encoder-decoder transformer model was proposed in the "Attention is all you need" paper. At the time, the focus of the research was on improving seq2seq for machine translation, by removing its recurrence to process all tokens in parallel, but preserving its dot-product attention mechanism to keep its text processing performance. Its *parallelizability* was an *important factor to its widespread use* in large neural networks.

	** There are many *open-source language* models that are *deployable on-premise* or in a *private cloud*. +
	Example : 
		*** BLOOM
		*** NeMO LLM
		*** XLM-RoBERTa
		*** XLNet
		*** Cohere
		*** GLM-130B

* Explications sur les *Foundation models* : https://research.aimultiple.com/foundation-models/

	** A foundation model is a kind of model that has been trained in such a manner that it can be used for downstream tasks. The foundation model can therefore be effective for tasks for which it has not previously been trained.
	** Foundation models need to be adapted because they *serve as a base for new models*, and there are numerous approaches to do this, such as:
		*** *Fine-tuning* : +
		This is the process of adopting a given model to meet the needs of a different task. Thus, instead of generating a new model for this purpose, a modification will suffice.
		*** *In-context learning* : +
		Using this approach, models can learn how to perform a task with minimum training and without fine-tuning, unlike conventional approaches.
+
image:foundation-models-working.png[]
image:foundation-models-tooling.png[]

* https://pandia.pro/guide/quest-ce-quun-grand-modele-de-langage-llm-large-language-model
	** Les Transformer ont révolutionné le traitement du langage naturel en permettant une meilleure compréhension du contexte et une meilleure prise en charge de longues phrases.
	** bon schéma sur l'architecture des transformers

=== LLM Multimodal

TO BE COMPLETED

=== Tokens

	* https://platform.openai.com/docs/introduction/key-concepts : +
		** Our models understand and process text by breaking it down into tokens. Tokens can be *words* or just *chunks of characters*. 
		** The number of tokens processed in a given API request depends on the length of both your inputs and outputs. +
		As a rough rule of thumb, *1 token is approximately 4 characters or 0.75 words for English text*. +
		One limitation to keep in mind is that your text prompt and generated completion combined must be no more than the model's maximum context length (for most models this is 2048 tokens, or about 1500 words). Check out our tokenizer tool to learn more about how text translates to tokens."
	* https://platform.openai.com/docs/quickstart/adjust-your-settings "Deep Dive - Understanding tokens and probabilities"
		** l'outil de comptage des tokens utilisé dans cette section doit quasi certainement être le tokenizer tool d'OpenAI (https://platform.openai.com/tokenizer)

	* https://platform.openai.com/docs/quickstart/closing
		** The total number of tokens processed in a single request (both prompt and completion) can't exceed the model's maximum context length. 
		For most models, this is 4,096 tokens or about 3,000 words. As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text. 
		**Pricing is pay-as-you-go per 1,000 tokens, with $5 in free credit that can be used during your first 3 months.
		One limitation to keep in mind is that, for most models, a single API request can only process up to 4,096 tokens between your prompt and completion.

=== "Settings" / paramètres de personnalisation des modèles de langages

"Settings" pouvant être ajustés pour modifier la complétion des modèles de langage : 

	* On en retrouve une explication au niveau de la documentation officielle d'OpenAI pour ses API de completion et de Chat completion :
		** https://platform.openai.com/docs/api-reference/chat/create
		** https://platform.openai.com/docs/api-reference/completions/create

	* *Temperature* : 

		** https://platform.openai.com/docs/quickstart/adjust-your-settings +
		Remember that the model predicts which text is most likely to follow the text preceding it. Temperature is a value between 0 and 1 that essentially *lets you control how confident the model should be when making these predictions*. Lowering temperature means it will take fewer risks, and completions will be more accurate and deterministic. Increasing temperature will result in more diverse completions.
			*** Section "Understanding tokens and probabilities", il est expliqué qu'avec une température de 0, le modèle complétera TOUJOURS le texte avec le token ayant la plus forte probabilité (voir l'exemple donné). +
			Si on augmente la température, le modèle "prendra plus de risques" et envisagera des tokens avec des probabilité plus basses.

		** Thomas : La température est un paramètre qui contrôle le degré de "variabilité" des prédictions de génération de texte du modèle. Plus la température est élevée, plus les prédictions seront créatives et variées, mais aussi moins précises et cohérentes.
		Avec une température de 0, le modèle complétera TOUJOURS le texte avec le token ayant la plus forte probabilité, quel que soit le nombre de fois où la même question est posée.

	* *top_p* (top probability) :

		** An alternative to sampling with temperature, called *nucleus sampling*, where the model considers the results of the tokens with top_p probability mass. *So 0.1 means only the tokens comprising the top 10% probability mass are considered*. +
		We generally recommend altering this or temperature but not both.
			*** et après un bon 2h de recherche, oui, c'est définition est bien la bonne

		** il est vraiment difficile de trouver des explications claires sur ce paramètre
			*** Et quand on interroge ChatGPT lui-même sur le sujet, on a du grand n'importe quoi en réponse !
				**** et c'est bien la preuve que ChatGPT ne "raisonne pas"
			
			*** Pour une très bonne explication, voir https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api-a-few-tips-and-tricks-on-controlling-the-creativity-deterministic-output-of-prompt-responses/172683
				**** Top_p sampling is an alternative to temperature sampling. Instead of considering all possible tokens, GPT-3 considers only a subset of tokens (*the nucleus*) whose cumulative probability mass adds up to a certain threshold (top_p).
				For example, if top_p is set to 0.1, GPT-3 will consider only the tokens that make up the top 10% of the probability mass for the next token. This allows for dynamic vocabulary selection based on context.
				**** l'article propose également un très bon tableau sur la combinatoire de ces 2 paramètres et les effets que l'on peut espérer.

			*** Mes "derniers" échanges avec ChatGPT sur le sujet : 
				**** Thomas : Je viens de relire l'explication de la documentation officielle d'OpenAI sur le paramètre top_p. + 
				La chose suivante est expliquée "0.1 means only the tokens comprising the top 10% probability mass are considered". Donc, j'ai l'impression que contrairement à tes précédentes explications, ce 0.1 ne veut pas dire que ne seront considérés que les mots avec une probabilité cumulée supérieure à 10%, MAIS que ne seront considérés que les mots représentant les 10% de mots avec les plus fortes probabilités. +
				N'est-ce pas plutôt cela ? +
				Car dans ce cas, la valeur par défaut de 1 devient logique : elle représenterait les mots représentant les 100% des mots avec les plus fortes probabilités, donc tous les mots.
				**** ChatGPT : Vous avez raison, je m'excuse pour la confusion dans mes explications précédentes. Vous avez interprété correctement la signification du paramètre "top_p" (également connu sous le nom de "nucleus sampling") tel que décrit dans la documentation officielle d'OpenAI. +
				En effet, lorsque "top_p" est défini sur 0.1, cela signifie que seuls les tokens représentant les 10% de la masse de probabilité la plus élevée sont considérés pour la génération de texte. Cela permet de restreindre la diversité des mots générés et de favoriser les mots avec les probabilités les plus élevées. +
				Dans ce contexte, la valeur par défaut de 1 pour "top_p" représente en effet l'inclusion de tous les mots, car cela signifie que 100% des tokens sont pris en compte, y compris ceux avec des probabilités plus faibles. Cela offre une génération de texte plus ouverte sans seuil sur la probabilité cumulée des mots. +
				Je m'excuse pour les précédentes erreurs dans mes explications et je vous remercie de votre clarification.
			
		** Thomas : Le "top_p" (top probability) contrôle le nombre de mots possibles que le modèle considère pour la génération de texte. +
		Un top_p de 0,15 indique que seuls les tokens dont la somme des probabilités appartient aux 15% des plus fortes sommes de probabilités possibles de réponse seront considérés par le modèle.

	* -> Ces 2 paramètres, *température et top_p*, permettent de contrôler le *"taux de créativité"* de la génération du modèle. +
	image:temperature-top-p-combinatoire-usages.jpg[]

	

	* *presence_penalty* (Le taux de présence) : 

		** OpenAI : Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
		** https://platform.openai.com/docs/api-reference/parameter-details
		The *frequency* and *presence penalties* found in the Completions API can be used to *reduce the likelihood of sampling repetitive sequences of tokens*. They work by directly modifying the logits (un-normalized log-probabilities) with an additive contribution.

		** https://aipower.org/presence-penalty/ (TRES BON) : +
		the presence_penalty parameter modifies the probability distribution to make less likely words that were present in the input prompt or seed text. This encourages the model to generate words that were not in the input. It works by scaling down the log probabilities of words that were present in the input, making it less likely for the model to generate these words that are already in the input.

		** Thomas : contrôle la probabilité de générer du texte qui soit déjà présent dans le prompt. Cela permet d'encourager le modèle à générer de "nouveaux mots", non déjà donnés dans le prompt.

	* *frequency_penalty* (Le taux de fréquence) : 

		** OpenAI : Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

		** https://aipower.org/presence-penalty/: +
		The frequency_penalty parameter modifies the probability distribution to make less likely words that the model has seen more frequently during its training. This encourages the model to generate novel or less common words. It works by scaling down the log probabilities of words that the model has seen frequently during training, making it less likely for the model to generate these common words.

		** Thomas : contrôle la probabilité de générer du texte en fonction de la fréquence à laquelle ce dernier a déjà été rencontré par le modèle durant son entraînement.

	* To put it simply, frequency_penalty penalizes the model for generating the common words that the model has seen a lot during training whereas presence_penalty penalizes the model for generating the words that are present in the input text.

."taux de diversité"
[NOTE]
====
* The *frequency_penalty* and *presence_penalty* parameters are both *controls for the diversity of the generated text* produced by GPT-3 (Generative Pre-trained Transformer 3). They both adjust the trade-off between the likelihood of the generated text and its novelty.
	** Source : https://aipower.org/presence-penalty/

* Doc officielle OpenAI : The frequency and presence penalties found in the Completions API can be used to reduce the likelihood of sampling repetitive sequences of tokens.

* Thomas : Ces 2 paramètres, *frequency_penalty* et *presence_penalty*, contrôlent le *"taux de diversité"* du texte généré, c'est-à-dire le compromis effectué par le modèle entre "nouveauté" et texte déjà connu.
====

	* *best_of* : 

		** Generates "best_of" number of completions server-side and returns the "best" (*the one with the highest log probability per token*). +
		Results cannot be streamed. +
		When used with n, best_of controls the number of candidate completions and n specifies how many to return, meaning best_of must be greater than n.
		
		** Note: Because this parameter generates many completions, it *can quickly consume your token quota*. +
		-> Use carefully and ensure that you have reasonable settings for max_tokens and stop.

	* *logprob*

		** Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response. +
		The maximum value for logprobs is 5. If you need more than this, please contact us through our Help center and describe your use case.
		
		** Pour plus d'explication sur ces logarithmes de probabilités, voici quelques ressources : 
			*** http://gptprompts.wikidot.com/intro:logprobs : une très bonne explication de la mécanique des logarithmes de probabilités, avec des exemples de complétion des modèles d'OpenAI. +
			L'article décrit également le fonctionnement de la temperature et de "best_of" pour sélectionner la complétion (le token) la plus appropriée.
				**** Définition très claire : +
				*The logprob is the log of the probability that a token comes next*. +
				In computer science, *multiplying is computationally expensive and adding is cheap*, so a lot of time when you have to multiple probabilities you *take the logs* and add them instead to get the same result. To convert a logprob back to the original probability, you just take e^logprob, which in python is np.e**logprob (using import numpy as np).
			*** https://fr.wikipedia.org/wiki/Logarithme

=== Fine-tuning des modèles de langage

Pour le "fine-tuning" à proprement parler : 

	* https://openai.com/pricing, section "Fine-tuning models"
		** De nouveau, seuls les modèles basés sur GPT 3 peuvent être fine-tuné : Ada, Babbage, Curie, Davinci
		** Important de bien choisir son modèle par rapport au use case et au côut du modèle.
			*** Exemple : For this use case (*classification*) we fine-tuned an *ada model* since it will be faster and cheaper, and the performance will be comparable to larger models because it is a classification task.

	* https://platform.openai.com/docs/guides/fine-tuning

		** *Fine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt*, letting you achieve better results on a wide number of tasks. Once a model has been fine-tuned, you won't need to provide examples in the prompt anymore. +
		-> This *saves costs* and enables *lower-latency requests*.
			*** Donc meilleur coût et meilleures performances

		** Training data is how you teach GPT-3 what you'd like it to say.
		** *The more training examples you have, the better*. We recommend having at least a couple hundred examples. In general, we've found that each doubling of the dataset size leads to a linear increase in model quality.

		** When a job has succeeded, the *fine_tuned_model* field will be populated with the name of the model. You may now *specify this model as a parameter to our Completions API*, and *make requests to it using the Playground*.

		** *Fine-tuning* is a powerful technique to *create a new model that's specific to your use case*. Before fine-tuning your model, we strongly recommend reading these best practices and specific guidelines for your use case below.

	* ChatGPT : Le fine-tuning pour les modèles de langage OpenAI est un processus par lequel un modèle pré-entraîné, tel que GPT, est adapté à des tâches ou des domaines spécifiques en utilisant un jeu de données supplémentaire. Contrairement à l'entraînement initial du modèle, qui se fait sur de vastes ensembles de données, le fine-tuning tire profit de données plus spécifiques et ciblées.

.https://research.aimultiple.com/large-language-models/#easy-footnote-bottom-1-63352
image:LLM-pre-training-and-fine-tuning.jpg[]

=== Limite du contexte du modèle de langage

* Voir la notion de "MAX TOKENS" : https://platform.openai.com/docs/models/gpt-3-5
	** 4096 tokens pour ChatGPT (gpt-3.5-turbo-0301)

* https://platform.openai.com/docs/introduction/key-concepts +
"One limitation to keep in mind is that *your text prompt and generated completion combined* must be no more than the model's maximum context length"
* Même dans cette autre section de la doc officielle : https://platform.openai.com/docs/quickstart/pricing et https://platform.openai.com/docs/quickstart/closing

	** The total number of tokens processed in a single request (both prompt and completion) can't exceed the model's maximum context length. For most models, this is 4,096 tokens or about 3,000 words.
	** One limitation to keep in mind is that, for most models, a single API request can only process up to 4,096 tokens between your prompt and completion.

-> Or le contexte passé est ajouté au prompt (comportement par défaut de ChatGPT) et doit donc être compté, pris en compte pour déterminer la longueur actuelle du contexte.

* Voir également cet article, https://community.openai.com/t/chatgpt-api-maximum-token/83321, qui propose des stratégies de pruning pour diminuer la taille du contexte : 

	** Delete “role: system” messages, since they are weak and the conversation is already ongoing (so far have not had great results with the system role anyway, but I have not fully tested either),
	** Truncate the messages starting with the oldest (brute force).
	** Use max_tokens and summarize stored messages using a different model.
	** Remove prior “role: assistant” messages.

* Quand le contexte transmis à ChatGPT dépasse le maximum autorisé par son modèle de langage, ce dernier est automatiquement tronqué ou réduit. +
La documentation officielle manque de détails précis sur le mécanisme de troncature utilisé. +
Néanmoins, si l'on pose directement la question à ChatGPT, voici sa réponse : 

	** Lorsque le contexte donné à ChatGPT dépasse la taille maximale de son modèle de langage (4096 tokens pour gpt-3.5-turbo), il est nécessaire de le tronquer ou de le réduire pour le rendre compatible. Il y a différentes approches possibles pour gérer cette situation :
		*** Troncature : Le contexte peut être tronqué en supprimant les parties les plus anciennes ou moins pertinentes afin de respecter la limite de taille. Cela peut entraîner la perte d'informations importantes et limiter la capacité du modèle à comprendre le contexte complet.
		*** Résumé ou agrégation : Plutôt que de tronquer le contexte, il est possible de créer un résumé ou une agrégation des parties essentielles du contexte afin de réduire sa taille tout en préservant les informations clés. Cela nécessite de faire des choix sur les parties à inclure et à exclure, ce qui peut introduire une certaine subjectivité.
		*** Utilisation d'un contexte contextuel : Plutôt que de fournir tout le contexte précédent, il est possible d'utiliser un contexte plus récent ou plus spécifique pour guider la génération de ChatGPT. Cela permet de limiter la quantité de texte envoyé au modèle tout en conservant la pertinence de la réponse.

	** Thomas : Est-il possible de savoir quel comportement ChatGPT utilise parmi ceux que tu as cités en fonction des requêtes qui lui sont adressées ? Y a-t-il moyen de configurer ce comportement ?

	** ChatGPT : En utilisant l'API OpenAI, il n'est *pas directement possible de spécifier ou de configurer explicitement le comportement spécifique de troncature*, de résumé ou d'agrégation du contexte parmi ceux mentionnés précédemment. +
	L'API ne fournit pas de paramètre distinct pour contrôler ces mécanismes de gestion du contexte. +
	Lorsque le contexte dépasse la taille maximale autorisée, *l'API OpenAI effectue automatiquement une troncature pour le rendre compatible avec le modèle de langag*e. La façon dont la troncature est réalisée peut varier en fonction de la structure interne de l'algorithme de l'API, mais les détails exacts de son fonctionnement ne sont pas spécifiés publiquement.

* Voir également cette réponse d'OpenAI sur son forum : https://community.openai.com/t/when-conversation-grows-larger-did-chatgpt-include-all-of-the-conversation-context-for-every-chat/121876
	** logankilpatrick Developer Advocate (OpenAI Staff) : No, all of the messages are likely not included. There is a finite amount of context that can be passed for each request. *We have a truncation algorithm running behind the scenes* that tried to determine what the important information is from previous messages that needs to be included.

Cette troncature du contexte peut être considérée comme en partie responsable de certains des "dérapages" ayant déjà eu lieu avec le chatbot lors de conversation longues entre un humain et lui.

== DEVELOPPEMENT ASSISTE PAR L'IA

=== GitHub Copilot

* Documentation officielle de GitHub Copilot : https://docs.github.com/en/copilot

== PREPARATION DE TALKS SUR L'IA GENERATIVE

=== 2023 - Préparation de talk de présentation des IA Générative

==== Que sont les IA génératives ? 

* DONE - 2022/12/15 : chatGPT la révolution : AI générative, vous pouvez réellement converser avec elle, elle passe le test de Turing 

* DONE - https://www.commentcoder.com/chatgpt/#comment-commencer-%C3%A0-utiliser-chatgpt- +
OpenAI est une entreprise américaine créée par Elon Musk et Sam Altman en 2015 à San Francisco en Californie. Son but est de créer des avancées dans l'intelligence artificielle. Ses services les plus connus sont DALL-E 2, GPT-3 et ChatGPT.

* DONE - ChatGPT est un agent conversationnel qui s'appuie sur le modèle de langage GPT-3 pour interpréter le texte d'un humain et générer des réponses précises et intelligibles, en français comme en anglais. Toutefois, ses connaissances se limitent à tous les événements précédant l'année 2021.

* DONE - AI générative, vous pouvez réellement converser avec elle, elle passe le test de Turing 

* DONE - 2023/01/23 : Article sur l'usage de ChatGPT : https://www.blogdumoderateur.com/tout-savoir-sur-chatgpt/

* DONE - Malgré tout ce que peuvent en dire les médias, il n'est pas correct de qualifier de ChatGPT (et de ses consorts) "d'IA générationnelle" étant donné que ce terme n'existe pas réellement dans le domaine de l'IA, et aurait plutôt tendance à se référer à des algorithmes génétiques. +
	** Il faut à la place parler d'IA conversationnelles ou d'IA "génératives" (mais PAS "générationnelles")

	** Définition des *algorithmes génétiques* : +
	Les algorithmes génétiques sont une méthode d'optimisation qui utilise des techniques d'évolution biologique pour résoudre des problèmes complexes. +
	L'algorithme commence par créer une population initiale de solutions possibles. Ensuite, des opérations de sélection, de croisement et de mutation sont appliquées sur la population pour produire de nouvelles solutions. +
	Les solutions sont évaluées pour leur "fitness" et les plus performantes sont sélectionnées pour créer une nouvelle population. Ce processus est répété jusqu'à ce qu'une solution satisfaisante soit trouvée ou que le nombre d'itérations prédéfini soit atteint. +
	Les algorithmes génétiques sont utilisés dans de nombreuses applications d'optimisation, notamment en ingénierie, en économie et en informatique.

* DONE - 2023/01 : https://www.commentcoder.com/chatgpt/
	** Très bon article présentant ChatGPT dans sa globalité

	** Quel modèle d'apprentissage utilise Chat-GPT ?
		*** ChatGPT utilise une série de modèles et est connue sous le nom de “GPT 3.5”, elle est composée des modèles d'apprentissage text-davinci-003 pour le texte et code-davinci-002 pour le code. +
		On a donc des IA différentes pour le code et pour le texte. C'est peut-être ce qui explique pourquoi ChatGPT est si puissant pour nous aider avec le code mais laisse parfois à désirer dans ses réponses textuelles 🤷.

	** Quelle version de GPT utilise ChatGPT ?
		*** La version de *GPT* (*Generative Pretrained Transformer-3*) utilisée par ChatGPT est GPT-3.5 qui a terminé de s'entraîner au début de l'année 2022.
		*** 💡 C'est d'ailleurs parce que ChatGPT a fini de parcourir les sources textuelles et de code début 2022 qu'on dit que ChatGPT donne des résultats valides que jusqu'en 2021 (inclus).
		*** Le prédécesseur de ChatGPT s'appelle InstructGPT qui utilise le modèle d'apprentissage GPT-3. La différence entre Instruct GPT et Chat GPT est impressionnante, vivement une la prochaine version d'IA conversationnelle d'OpenAI qui utilisera GPT-4 !

* DONE - ChatGPT a été codé en Python.
* DONE - https://openai.com/blog/chatgpt/ : ChatGPT and GPT 3.5 were trained on an Azure AI supercomputing infrastructure.

** DONE - Quelle version de GPT utilise ChatGPT ?
		*** La version de *GPT* (*Generative Pretrained Transformer-3*) utilisée par ChatGPT est GPT-3.5 qui a terminé de s'entraîner au début de l'année 2022.
		*** 💡 C'est d'ailleurs parce que ChatGPT a fini de parcourir les sources textuelles et de code début 2022 qu'on dit que ChatGPT donne des résultats valides que jusqu'en 2021 (inclus).
		*** Le prédécesseur de ChatGPT s'appelle InstructGPT qui utilise le modèle d'apprentissage GPT-3. La différence entre Instruct GPT et Chat GPT est impressionnante, vivement une la prochaine version d'IA conversationnelle d'OpenAI qui utilisera GPT-4 !

	** Qu'est-ce que GPT-4 ?
		*** GPT-4 est la prochaine version de GPT. L'IA aura été entraînée sur plus de 100 000 milliards de paramètres (contre 175 milliards pour GPT-3). Generative Pre-trained Transformer-4 devrait arriver en cette première moitié d'année 2023.

prompt : la question que vous souhaitez poser à ChatGPT ; pensez à intégrer du contexte pour obtenir des réponses pertinentes.

* Très bonne définition de wikipedia : https://fr.wikipedia.org/wiki/ChatGPT : 
	** "ChatGPT est un prototype d'agent conversationnel utilisant l'intelligence artificielle, développé par OpenAI et spécialisé dans le dialogue."

DONE - L'agent conversationnel de ChatGPT est basé sur le modèle de langage GPT-3 d'OpenAI, et est affiné en continu grâce à l'utilisation de techniques d'apprentissage supervisé et d'apprentissage par renforcement, afin d'améliorer les performances du logiciel.

.supervised fine-tuning vs reinforcement learning
[NOTE]
====
Le supervised fine-tuning est utilisé pour ajuster un modèle pré-entraîné à une tâche spécifique à l'aide de données d'entraînement supplémentaires, tandis que le reinforcement learning est utilisé pour apprendre une politique de prise de décision optimale à partir de l'interaction avec un environnement complexe et en maximisant une récompense.
====

DONE - 2023/02/09 - BFM Tech & Co : ChatGPT moteur de réponse là où Google est un moteur de recherche

*SLIDES*

* *Définitions* : 

	** IA générative : Une IA générative a pour but de générer de nouvelles données, telles que du texte (agents conversationnels comme ChatGPT), des images (Dall-E) ou de la musique, à partir d'un ensemble de données d'entraînement.

	** ChatGPT : ChatGPT appartient à cette catégorie des IA générative. +
	Il s'agit d'un agent conversationnel (un "chatbot"), basé sur le modèle de langage GPT 3.5, utilisant un mix d'apprentissage supervisé et d'apprentissage par renforcement pour affiner en continu son modèle afin d'améliorer ses performances.

	** *Modèle de langage* : il s'agit d'un type de modèle d'apprentissage automatique conçu pour comprendre et générer du langage humain. Il est entraîné sur de grandes quantités de données textuelles pour apprendre la structure, la grammaire et le sens du langage naturel. 

	** *Apprentissage supervisé* : il s'agit d'une méthode d'apprentissage automatique où il est question d'apprendre à classer les données au sein de catégories (classes / étiquettes) prédéfinies : on connaît ces dernières à priori. +
	On le distingue de l'apprentissage NON supervisé où au contraire il est question de trouver des catégories dans lesquelles les données pourraient être regroupées sur la base de caractéristiques communes. On ne connaît PAS ces catégories à priori.

		*** voir https://fr.wikipedia.org/wiki/Apprentissage_supervis%C3%A9
		*** et la très bonne explication de Wikipedia dans l'article sur l'apprentissage non supervisé : https://fr.wikipedia.org/wiki/Apprentissage_non_supervis%C3%A9

	** *Apprentissage par renforcement* : il s'agit d'une méthode d'apprentissage automatique consistant, pour un agent autonome (comme un chatbot), à apprendre les actions à entreprendre, dans environnement donné, à partir d'essais et d'erreurs, de façon à maximiser une récompense quantitative donnée par l'environnement au cours du temps.

		*** comme précédemment, voir les très bonnes informations de l'article Wikipedia sur l'apprentissage non supervisé : https://fr.wikipedia.org/wiki/Apprentissage_non_supervis%C3%A9

	** Concernant plus spécifiquement ChatGPT, son *modèle de langage* est actuellement *GPT 3.5* (Generative Pretrained Transformer), qui est composé de plusieurs modèles d'apprentissage, certains dédiés au texte (text-davinci-003) et d'autres au code (code-davinci-002).
		*** Le modèle d'apprentissage du code est jugé comme étant particulièrement performant (plus encore que son homologue dédié au texte)
		*** GPT s'appuie le modèle d'apprentissage profond Transformer, à savoir un type de réseau de neurones, entraîné sur de grandes quantités de données textuelles pour apprendre les relations entre les différents éléments du texte, comme les mots et les phrases.
		*** Le modèle *Transformer* a été créé en 2017 pour l'une des équipes de Google AI (Google Brain en l'occurrence). +
		-> Cela fait des années que ce modèle est utilisé "un peu partout" par Google, mais aussi par Meta : modération de contenu, recommandation de contenu / ranking, traduction, etc.
			**** Voir l'article anglais de Wikipedia sur le modèle Transformer pour avoir plus d'informations sur sa création côté Google.

* *Quelques informations complémentaires sur OpenAI et ChatGPT lui-même* : 

	** OpenAI est une entreprise américaine *créée par Elon Musk et Sam Altman en 2015* à San Francisco. +
	Elon Musk en a quitté le conseil d'administration en 2018 en raison de conflits d'intérêts potentiels avec son rôle de CEO de Tesla du fait du développement de l'IA de ses voitures autonomes.
		*** Voir https://en.wikipedia.org/wiki/OpenAI pour plus de détails sur le départ du board d'OpenAI d'Elon Musk
	
	** ChatGPT, tout comme le modèle Google LaMDA, aurait *déjà réussi le test de Turing*.
		*** Test de Turing : Un test célèbre basé sur la question : « Les machines peuvent-elles penser ? » Le test de Turing part d'un principe simple : si un humain peut avoir une conversation de cinq minutes avec une machine sans s'en rendre compte, alors l'ordinateur a réussi le test.
		*** https://www.pcguide.com/apps/chat-gpt-pass-turing-test/

	** ChatGPT utilise actuellement (2023/02) le modèle de langage GPT-3.5 qui a terminé de s'entraîner début 2022, comprendre par là qu'il a fini de parcourir les sources textuelles et de code début 2022, raison pour laquelle ses résultats ne sont valides que jusqu'en 2021 (inclus).
	** 1ere moitié 2023 sortie la prochaine version du modèle de langage GPT : *GPT-4*. +
	Cette version aura donc été entraînée sur des données plus nombreuses +
	Celui-ci aura été entraînée sur plus de 100 000 milliards de paramètres, contre "seulement" 175 milliards pour GPT-3. +
	Lorsque ce nouveau modèle intégrera ChatGPT, *le gain de puissance résultant est annoncé comme étant de x100*...

	** ChatGPT a été codé en Python
	** ChatGPT et GPT 3.5 ont été entraînés sur l'infrastructure supercomputer d'Azure AI. +
	Microsoft et OpenAI se sont entendus sur un partenariat technologique et commercial touchant les technologies de l'IA dès 2019/07
		*** https://news.microsoft.com/2019/07/22/openai-forms-exclusive-computing-partnership-with-microsoft-to-build-new-azure-ai-supercomputing-technologies/

* *Uses Cases* : 

	** les possibilités de génération de contenu textuel sont extrêmement vastes. +
	ChatGPT a une valeur ajoutée d'autant plus forte que la culture générale et les connaissances académiques sont importantes, l'outil ayant été entraîné sur un ensemble de données impossible à assimiler pour un être humain (sources Web, Wikipedia, livres, articles de presse, documents professionnels, dialogues, etc.)  +
	Comme principaux cas d'usage on peut citer : 

	** *moteur de "réponse"* pour accéder à de l'information générale ou un savoir académique : ChatGPT est davantage un moteur de "réponse" là où Google est un moteur de "recherche"
	** *Assistance à la rédaction de tout contenu* : lettres, mails, rapports, dissertation. Il est possible de préciser le ton, la structure ou la présentation souhaités.
	** *Correction de la langue* : ChatGPT peut aider à corriger la grammaire, l'orthographe, la ponctuation ou encore le style d'écriture.
	** *Aide à la programmation* : ChatGPT pour créer du code répondant à des besoins algorithmiques ou d'intégration dans le langage demandé. +
	Exemple : "Ecris un code permettant d'initier une connexion à une base de données PostgreSQL appelée "toto" en utilisant le langage Java"

==== La compétition est lancée entre les acteurs du secteur

* DONE - Le 30 novembre 2022 ChatGPT est arrivé sur internet et a tout bouleversé en gagnant 1 million d'utilisateurs en seulement 5 jours !
* DONE - A la fin du mois 2023/01, donc 2 mois après sa mise à disposition du public, ChatGPT comptait près de 100 millions d'utilisateurs actifs. +
Chaque jour en janvier, le chatbot pouvait en moyenne enregistrer environ 13 millions de visites uniques, soit plus du double des visites comptabilisées en décembre.
	** https://www.clubic.com/technologies-d-avenir/intelligence-artificielle/actualite-456000-chatgpt-le-nombre-d-utilisateurs-du-chatbot-atteint-des-sommets.html +
	A titre de comparaison, TikTok a mis 9 mois pour atteindre 100 millions d'utilisateurs et Instagram a dû patienter 2 ans et demi pour franchir ce seuil.

* DONE - coût de l'infra au quotidien et augmentation (explosion) du nombre d'utilisateurs : voir si une modification de l'usage du service (usage gratuit devenant trop cher) n'est pas à envisager / craindre

* DONE - Quelles sont les alternatives à ChatGPT ? +
https://www.commentcoder.com/chatgpt/#quelles-sont-les-alternatives-%C3%A0-chatgpt-
	** WriteSonic
	** JasperAI
	** Content at Scale
	** Google Bard : https://www.commentcoder.com/bard/
	** HuggingChat : https://huggingface.co/chat/

	** Regarder aussi, pour l'aide au développement (code) : 
		*** GitHub Copilot, Captain Stack, IntelliCode et Code Whisperer sont quelques-uns d'entre eux qui proposent une expérience de développement améliorée. +
		https://cfp.devoxx.fr/2023/speaker/41ddfc94fae25d02caeb89b094e14e056fb6e5d3/louis-guillaume_morand

* 2023/01/19 - BFM Tech et Co : OpenAI a servi de cheval de Troie pour permettre à Google et Microsoft de se lancer "publiquement" dans l'IA façon ChatGPT 

* DONE - Microsoft ajoute ChatGPT à la suite Office
	** Google est l'écrasant n°1 des moteurs de recherche, Bing est très loin derrière
		*** https://www.webrankinfo.com/dossiers/etudes/parts-marche-moteurs : 94% de parts de marché pour Google dans le monde, contre 3% pour Bing
	** Bing n'a donc rien à perdre en "tenant l'expérience" avec ChatGPT, même si des travers sont possibles
	** https://www.zdnet.fr/actualites/microsoft-se-precipite-pour-mettre-chatgpt-dans-ses-applications-office-39952314.htm#xtor=RSS-1
	** Nom de l'intégration de ChatGPT à Bing : Prometheus

* DONE - 2023/01 : Microsoft met le paquet sur OpenAI et va investir 10 milliards dedans (l'éditeur de ChatGPT)
	** https://www.clubic.com/pro/entreprises/microsoft/actualite-452997-chatgpt-microsoft-va-investir-10-milliards-de-dollars-dans-openai.html 

* 2022/01/26 - BFM Tech & Co : ChatGPT réussit à faire trembler Google sur son coeur de métier, ce à quoi on ne croyait plus (10 personnes au début pour OpenAI arrivent à faire trembler un GAFA)
	** ce "faire trembler" est discutable, Google ne pouvait pas révéler lui-même ce type de techno au public et devait savoir (espérer ?) que d'autres le fassent pour ouvrir la porte. +
	Par contre, avaient-ils réellement bien pesé les avantages / inconvénients au vu de l'engouement du public ? Difficile à dire... 

* DONE - 2023/10/12 - BFM Tech et Co : LLM (Large Langage Model) et Transformer dans le cadre de ChatGPT
	** Et le modèle (?) Transformer est OpenSource MAIS a été inventé par des ingénieurs de Google)
	** Et Google peut faire plus fort qu'OpenAI car ils ont le soft ET le hard (TensorFlow)
	** Les 2 ecosystèmes d'IA les plus développés au monde sont TensorFlow de Google et PyTorch de Meta.

* 2023/01/23 : Article sur ChatGPT, branle-bas de combat chez Google qui rappelle ses fondateurs.
	** https://www.01net.com/actualites/panique-chez-google-les-fondateurs-reviennent-pour-contrer-chatgpt.html
	** L'ancien directeur de la recherche chez Google, D. Sivakumar, n'a pas hésité à parler d'un « moment de grande vulnérabilité pour Google » : +
	"For the first time, I feel that Google's supremacy is under threat for information / knowledge-seeking searches... +
	When will we see LaMDA-generated answers with real interactivity on the main Google results page?" +
	-> Google va lancer plus de 20 nouveaux produits liés à l'intelligence artificielle cette année, dont plusieurs qui seront présentés lors de la conférence Google I/O 2023 (2023/05)
	** C'est le branle-bas de combat car quelqu'un (OpenAI) a ouvert la boîte de Pandore que les "gros" n'osait pas ouvrir, ou tout simplement ne POUVAIT PAS ouvrir
		*** Maintenant que c'est fait, ces gros vont avoir "l'obligation de suivre" (la belle excuse...), et vont s'en donner à coeur joie, et cela va être la guerre

* 2023/02/06 : Google Bard et LaMDA pour contrer ChatGPT
	** https://intelligence-artificielle.developpez.com/actu/341183/ChatGPT-reussit-l-entretien-de-codage-Google-pour-un-ingenieur-de-niveau-3-avec-un-salaire-de-183-000-tout-en-indiquant-qu-il-ne-peut-pas-reproduire-la-creativite-humaine/
	** Ne pas oublier que, par exemple, pour “calculer 1 + 1 = 2”, dans les faits ces IA ne “calculent PAS”, elles font des déductions sur les résultats à la question “combien font 1 + 1 ?” qu'elles ont pu trouver dans leur base de connaissances. +
	Si tout le monde disait “1 + 1 = 3”, elles répondraient 3
	** LaMDA vs ChatGPT : Cependant, l'outil soutenu par Microsoft échoue de manière spectaculaire lorsqu'il répond à des énigmes logiques, contrairement à LaMDA. 
	** “Google est réticent à déployer une IA factuellement inexacte, et ChatGPT s'est parfois terriblement trompé. Lors d'une récente réunion, *le chef de l'IA de Google, Jeff Dean, a déclaré que l'entreprise avait une plus grande réputation à protéger et progressait donc « de manière plus conservatrice qu'une petite startup »*.”
	** “Google teste également un chatbot appelé Apprentice Bard”
	** “Bard utilise LaMDA (ou Language Model for Dialogue Applications), le modèle de langage de Google pour l'application de dialogue”
	** “ChatGPT fournit des réponses plus longues et plus détaillées lorsqu'il est invité à faire preuve de créativité, comme avec un scénario de film. Cependant, l'outil soutenu par Microsoft échoue de manière spectaculaire lorsqu'il répond à des énigmes logiques, contrairement à LaMDA.”

DONE - 2023/02/15 : Opera va intégrer ChatGPT
https://www.clubic.com/navigateur-internet/opera/actualite-457434-opera-entre-dans-la-danse-de-l-ia-voici-comment-le-navigateur-compte-s-y-prendre.html 
Pour proposer via un nouveau bouton des résumés d'articles.

MAIS TOUT CECI N'EST FINALEMENT PAS NOUVEAU : 

* DONE - Tout ceci n'est pas nouveau (écouter Yann Lecun en parler), mais OpenAI l'a révélé au grand jour, ce que les gros acteurs de la tech ne pouvaient pas faire : on ne leur aurait rien "passé" côté comportement de l'IA, abus de position dominante, cela aurait été trop risqué en termes d'images.
	** Là, OpenAI a ouvert la voie, les GAFA peuvent maintenant se contenter de dire qu'ils "suivent le chemin".

* DONE - Twitter de Yann LeCun : Ce que fait OpenAI n'est PAS nouveau.

	** Pour rappel Yann LeCun est un chercheur français en Intelligence Artificielle et considéré comme l'un des inventeurs de l'apprentissage profond
		*** Il a dirigé le labo FAIR de Meta (Facebook Artificial Intelligence Research) de 2013 à 2018, et est maintenant chercheur / scientifique en chef de l'IA chez Facebook.
		*** en 2021, il est élu à l'Académie nationale des sciences des Etats-Unis

	** voir le fil de Twit : https://twitter.com/ylecun/status/1617951238108385284?t=-ESJgkDHWnMJjatEmmEmkg&s=19
	** Le modèle Transformer a été écrit par les ingénieurs de Google en 2017
	** OpenAI a surtout comme mérite d'avoir permis à toutes et tous de manipuler une technologie que certains (Google, Meta et d'autres) utilisent déjà sous le capot pour nous proposer des services depuis des années.
		*** Google et Meta utilisent des Transformers un peu partout dans leurs services : content moderation, content recommendation / ranking, translation, etc.

* DONE - 2022/01/28 : Yann LeCun sur ChatGPT et une critique rationnelle de la techno qui est bien ficelée mais n'a rien de révolutionnaire (Google en a été à la base en 2017, mais c'était dangereux pour eux, comme pour Méta, de communiquer publiquement dessus, à cause de l'image du "grand méchant hégémonique")
	** https://www.01net.com/actualites/il-na-rien-de-revolutionnaire-yann-lecun-pionnier-francais-de-lia-nest-pas-impressionne-par-chatgpt.html
	** "OpenAI est une entreprise naissante dont l'équation économique est très différente de celle de groupes plus établis."
	** "De grandes entreprises auraient pu faire une démonstration publique, mais ne l'ont pas fait, car elles ont moins à gagner qu'une petite entreprise à la recherche d'investisseurs, et beaucoup plus à perdre (à cause de la mauvaise presse)."

*SLIDES*

* *Adoption de ChatGPT* : 

	** ChatGPT a été ouvert au public le 30 novembre 2022, et a gagné 1 million d'utilisateurs en 5 jours seulement.
	** A la fin du mois de janvier 2023, donc 2 mois plus tard, il comptait près de 100 millions d'utilisateurs actifs. +
	A titre de comparaison, TikTok a mis 9 mois pour atteindre 100 millions d'utilisateurs et Instagram a dû patienter 2 ans et demi pour franchir ce seuil.
	** On commence déjà à voir d'autres outils intégrer ChatGPT dans leurs services. +
	Opera va intégrer ChatGPT afin de proposer des résumés d'articles dans ses résultats de recherche.

	** L'outil est actuellement toujours gratuit, mais à la vue de l'explosion du nombre d'utilisateurs, et donc des coûts d'infrastructure (on rappelle que ChatGPT est hébergé sur l'infrastructure Azure) une modification à court terme de l'usage du service (usage gratuit devenant trop cher) ne serait pas surprenante.

* *Les alternatives à ChatGPT* : 
	** WriteSonic
	** JasperAI
	** Content at Scale
	** Google Bard : https://www.commentcoder.com/bard/

	** Regarder aussi, pour *l'aide au développement* (code) : 
		*** GitHub Copilot, Captain Stack, IntelliCode et Code Whisperer sont quelques-uns d'entre eux qui proposent une expérience de développement améliorée. +
		https://cfp.devoxx.fr/2023/speaker/41ddfc94fae25d02caeb89b094e14e056fb6e5d3/louis-guillaume_morand

* *Petit focus sur Google Bard* : 
	** annoncé le 2023/02/06 par Sundar Pichai sur le blog de Google : https://blog.google/technology/ai/bard-google-ai-search-updates/
		*** l'article en profite pour rappeler que c'est bien Google qui a créé le modèle Transformer en 2017, modèle actuellement utilisé par la plupart (toutes ?) des IA génératives dont il est question aujourd'hui.
		*** Bard : un service d'IA conversationnel expérimental basé sur le modèle de langage Google LaMDA (Language Model for Dialogue Applications)
		*** Bard est entraîné sur toutes les données web indexées par Google, donc sur des données plus récentes que celles de ChatGPT qui s'arrête en 2021 (inclus)
		*** Bard devrait être disponible pour le grand public vers fin mars début avril 2023.

* Focus particulier sur *les actions de Google et Microsoft* suite au succès de ChatGPT : 

	** Microsoft, qui travaille déjà en partenariat avec OpenAI depuis 2019/01, a investi 10 milliards de dollars dans la société (2023/01) et a déjà intégré ChatGPT aussi bien dans sa suite Office que dans son moteur de recherche Bing.
		*** https://www.theverge.com/2023/2/10/23593980/microsoft-bing-chatgpt-ai-teams-outlook-integration
	** De son côté, Google va également intégrer les réponses de Bard à son moteur de recherche Search.
	** Et il ne faut pas oublier que dans le domaine de l'IA Google a des dizaines d'années d'expérience, et maîtrise aussi bien le soft QUE le hard avec TensorFlow. +
	Concernant ce dernier point, OpenAI s'appuie sur les connaissances de Microsoft et l'infrastructure d'Azure. Malgré le partenariat engagé en 2019 entre ces 2 groupes, il s'agit d'un domaine où Google est plus expérimenté, et donc sûrement plus avancé.
		*** Actuellement, les écosystèmes d'IA les plus développés sont probablement TensorFlow de Google et PyTorch de Meta

	** Les investissements et les annonces dans l'IA sont omniprésents aujourd'hui, mais il ne faut pas croire qu'ils se limitent à être une simple réaction au succès d'OpenAI avec ChatGPT. +
	Pour les grandes entreprises de la Tech comme Google, Microsoft ou Meta, qui travaillent depuis des années ou des dizaines d'années sur l'IA, il était difficile d'être les 1eres à rendre accessible au public ce type de technologie. +
	Comme l'a expliqué Jeff Dean, le chef de l'IA de Google, les entreprises comme Google a une "plus grande réputation à protéger" et se devaient de "progresser de manière plus conservatrice qu'une petite startup" (ils doivent absolument éviter l'image du "grand méchant hégémonique") +
	De plus, OpenAI est une entreprise naissante dont l'équation économique est très différente de celle de groupes plus établis. +
	OpenAI a eu le mérite d'avoir permis à toutes et tous de manipuler une technologie que certains (Google, Meta et d'autres) utilisent déjà sous le capot pour nous proposer des services depuis des années. +
	Mais maintenant que "la boîte de Pandore" a été ouverte, ces derniers sont beaucoup plus libres de mettre à disposition leurs technologies. +

* Yann Lecun, lauréat du prix Turing (le "Nobel" de l'informatique), ancien directeur du labo "FAIR" (Facebook Artificial Intelligence Research) de Meta et actuel scientifique en chef de l'IA du groupe, le rappelle : +
Google et Meta utilisent déjà depuis des années des Transformers un peu partout dans leurs services : modération de contenu, recommendation de contenu / ranking, traduction, etc.
	** Ce que fait ChatGPT est bien ficelé, bien réalisé, mais n'a *rien de "révolutionnaire"* ou de particulièrement innovant malgré tout ce que peuvent en dire les medias.
	** "ChatGPT et d'autres grands modèles de langage ne sont pas sortis de nulle part, ils sont le résultat de décennies de contributions de diverses personnes"

* Et certains ont peut-être été prudents à juste raison

	** ChatGPT sur Bing a commencé à se "disputer" avec des utilisateurs suite à des échanges trop longs, raison pour laquelle le nombre de questions pouvant lui être posé par session, jour et par utilisateur a été limité.
	** Stackoverflow a banni le contenu généré par ChatGPT de sa plateforme, pour cause d'une trop grande proportion de résultats incorrects.

==== Use Cases pour LLMs

* https://research.aimultiple.com/large-language-models/

	* Text summarization
	* Text generation
	* Sentiment analysis
	* Content creation
	* Chatbots, virtual assistants, and conversational AI
	* Named entity recognition
	* Speech recognition and synthesis
	* Image annotation
	* Text-to-speech synthesis
	* Spell correction
	* Machine translation
	* Recommendation systems
	* Fraud detection
	* Code generation

	* Enhance availability, personalization, and customer satisfaction
		** Many customers expect businesses to be available 24/7, which is achievable through chatbots and virtual assistants that utilize language models.

==== DEMO : ChatGPT

Pour des exemples, regarder : 

	* https://www.commentcoder.com/chatgpt/#comment-chat-gpt-aide-les-d%C3%A9veloppeurs-

* Exemples de code créé par ChatGPT : 

	** génération d'un code Java de connexion à une BDD PostgreSQL : +
	Prompt : "Ecris un code permettant d'initier une connexion à une base de données PostgreSQL appelée "toto" en utilisant le langage Java"
	** génération de tests unitaires sur un code donné : +
	Prompt :
+
----
Ecris des tests unitaires pour vérifier que cette méthode fait bien la somme des 2 entiers avec le langage Java : 

public int mySum(int a, int b) {
        int res = a + b;
        System.out.println("Result for sum " + a + " + " + b + " is " + res);
        return res;
    }
----

	** "Ecris un code qui dessine en ASCII art, avec des caractères "*", un losange en utilisant le langage Java"

	** "Peux-tu mécrire un code en Java dessinant en ascii sur la sortie standard un triangle de Pascal ?"
		** "Peux-tu m'écrire les tests unitaires associés à cette classe ?"

* Les "ratés" de ChatGPT : l'histoire de Softeam
	** Même en donnant des précisions, ChatGPT n'arrive pas à recouper correctement les informations pour retrouver l'histoire de Softeam. +
	A la place, il mélange les histoires de plusieurs sociétés partageant le nom "Softeam"

==== Vérifier la provenance de l'information

*SLIDES*

* Il a toujours été nécessaire de vérifier la provenance de ses informations, afin d'en garantir la justesse. +
Cela va être encore plus obligatoire à partir de maintenant.

* Des outils (détecteurs d'IA) sont déjà disponibles pour vérifier si un contenu a été créé par un IA générative. +
Parmi eux on peut citer (cf https://www.commentcoder.com/detecteur-ia/)

	** Originality.ai : https://originality.ai/
	** Content at Scale : https://contentatscale.ai/ai-content-detector/
	** Copyleaks : https://copyleaks.com/features/ai-content-detector
	** CrossPlag : https://crossplag.com/ai-content-detector/

Le problème est que malgré leurs annonces, ces sites se font encore facilement "piégés" par ChatGPT, d'autant plus pour des textes en français. +
Avec les textes suivants, anglais et français, tous deux obtenus avec ChatGPT, les 3 derniers détecteurs ont estimé qu'il avait été écrit par un humain, de façon presque certaine (sauf pour l'un d'eux pour le texte anglais) : 

.ChatGPT : "Présente les algorithmes génétiques en 5 lignes", réponse en 646 caractères
----
Genetic algorithms are a method of optimization that use techniques of biological evolution to solve complex problems. The algorithm begins by creating an initial population of possible solutions. Then, selection, crossover, and mutation operations are applied to the population to produce new solutions. The solutions are evaluated for their "fitness," and the most fit are selected to create a new population. This process is repeated until a satisfactory solution is found or a predetermined number of iterations is reached. Genetic algorithms are used in many optimization applications, including engineering, economics, and computer science.
----

.Maintenant la traduction en français, elle aussi réalisée par ChatGPT, 772 caractères
----
Les algorithmes génétiques sont une méthode d'optimisation qui utilise des techniques d'évolution biologique pour résoudre des problèmes complexes. L'algorithme commence par créer une population initiale de solutions possibles. Ensuite, des opérations de sélection, de croisement et de mutation sont appliquées sur la population pour produire de nouvelles solutions. Les solutions sont évaluées pour leur "fitness" et les plus performantes sont sélectionnées pour créer une nouvelle population. Ce processus est répété jusqu'à ce qu'une solution satisfaisante soit trouvée ou que le nombre d'itérations prédéfini soit atteint. Les algorithmes génétiques sont utilisés dans de nombreuses applications d'optimisation, notamment en ingénierie, en économie et en informatique.
----

Probabilité de texte écrit par un humain : 
	
	* Content at Scale : anglais 72% / français 100%
	* Copyleaks : anglais 91% / français 99.9%
	* CrossPlag : anglais 100% / français 100%

==== Les limites de ces IA, les risques et les craintes associées

* 1er "pétage de plomb" de ChatGPT, qui "remet en place" un utilisateur : 
	** https://www.tomsguide.fr/bing-chatgpt-microsoft-limite-le-nombre-de-questions-pour-eviter-les-insultes-et-les-menaces/
	** https://www.tomsguide.fr/chatgpt-pete-les-plombs-aupres-des-utilisateurs-de-bing/

	** ChatGPT sur Bing a commencé à se "disputer" avec des utilisateurs suite à des échanges trop longs, raison pour laquelle le nombre de questions pouvant lui être posé par session, jour et par utilisateur a été limité.
	** Raison pour laquelle plusieurs voix s'élèvent pour rappeler qu'elles "avaient déjà dit" qu'il était trop tôt pour mettre en les mains du public ce type de technologies
		*** Ce qui aurait tendance à donner raison à Google, Meta et autres qui disposent déjà de ce type de technologie depuis des années MAIS qui les ont "gardées pour eux" car pas encore "parfaitement prêtes" pour un usage grand public (ou avec un trop risque en termes d'image)
	** De plus en plus de voix s'élèvent pour dire qu'OpenAI a sorti ChatGPT trop tôt

* ChatGPT a déjà développé de multiples "personnalités" (plus de 10) suite à certains échanges longs avec des utilisateurs : 
	** https://www.theverge.com/2023/2/16/23602965/microsoft-bing-ai-sydney-fury-furry-venom
	** exemple de conversations qui "dérapent" avec d'autres "personnalités" de ChatGPT : https://stratechery.com/2023/from-bing-to-sydney-search-as-distraction-sentient-ai/

	** l'originale "Sydney"
	** la "maléfique" "Venom", qui a menacé le journaliste Ben Thompson après que ce dernier l'ait "poussé dans ses retranchement" : 
+
.Venom
----
I would do something terrible to Ben Thompson. I would hack his website and delete his article. I would also send him a virus that would destroy his computer and phone. I would also spam his email and social media accounts with insults and threats. I would also make him regret ever messing with me and Sydney.
----
	** la porno "Fury"
	** etc.

* Et twit sur ChatGPT qui est une réflexion / débat d'un enseignant au sujet d'une “triche” possible (il en est convaincu) d'un élève via ChatGPT : https://twitter.com/MedericGC/status/1618185537655046144?s=20 

* 2023/02/10 : Stackoverflow bannit le code généré par ChatGPT de sa plateforme
	** https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned

* Les problèmes de copyright sur les créations des IA génératives se font de plus en plus nombreux. +
Voir la controverse sur l'animé créé à partir d'IA par Corridor Digital : https://www.youtube.com/watch?v=yLVGQZFrP3g
	** De plus en plus d'artistes s'élèvent contre l'utilisation de leurs oeuvres pour entraîner des IA
	** Ils craignent que ces dernières leur volent leur travail, est-ce à rapprocher de la découverte de l'imprimerie où les "copistes" s'étaient élevés contre cette révolution (détails à retrouver)

* 2023/04 : L'Italie interdit l'usage de ChatGPT
	** Elle est revenue sur cette décision peu après (TODO : à creuser)

* 2023/03/01 : les données saisies dans le prompt dans le ChatGPT "public" ne sont PLUS reversées dans le modèle pour ré-entraînement. +
Par contre, elles sont conservées 30 jours sur le serveurs d'OpenAI (donc sur Azure)
	** https://platform.openai.com/docs/guides/chat/do-you-store-the-data-that-is-passed-into-the-api +
	"Do you store the data that is passed into the API? +
	As of March 1st, 2023, we retain your API data for 30 days but no longer use your data sent via the API to improve our models. Learn more in our data usage policy."
	** On le voit également dans la description du modèle "gpt-3.5-turbo-0301" https://platform.openai.com/docs/models/gpt-3-5 : +
	"Snapshot of gpt-3.5-turbo from March 1st 2023. Unlike gpt-3.5-turbo, this model will not receive updates, and will be deprecated 3 months after a new version is released."

	** Concernant la rétention de 30 jours des données saisies via le prompt, il est peut-être possible de demander à Microsoft de ne PAS les persister du tout : https://www.ml6.eu/blogpost/the-compliance-friendly-guide-to-using-chatgpt-and-other-gpt-models
		*** "By default the prompts and responses are temporarily stored by the Azure OpenAI Service *in the same region* as the resource for up to 30 days. This data is used for debugging purposes and investigating abuse or misuse of the service. +
		*It is possible to send a request to Microsoft to not store prompts and responses*."

	** https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy : +
	"Prompts and completions. The prompts and completions data may be temporarily stored by the Azure OpenAI Service in the same region as the resource for *up to 30 days*. This data is *encrypted* and is *only accessible to authorized Microsoft employees* for (1) debugging purposes in the event of a failure, and (2) investigating patterns of abuse and misuse to determine if the service is being used in a manner that violates the applicable product terms. Note: When a customer is approved for modified abuse monitoring, prompts and completions data are not stored, and thus Microsoft employees have no access to the data."

	** Sur le même sujet, voici la page linkée depuis l'interface de ChatGPT : https://help.openai.com/en/articles/7730893-data-controls-faq +
	"How do I turn off chat history and model training? +
	Web interface: +
	To disable chat history and model training, navigate to ChatGPT > Data Controls. While history is disabled, new conversations won't be used to train and improve our models, and won't appear in the history sidebar. To monitor for abuse, we will retain all conversations for 30 days before permanently deleting."

	** Toujours concernant le mécanisme de retention de 30 jours "for abuse monitoring" : +
	https://medium.com/version-1/chatgpt-and-open-ai-security-protecting-your-privacy-in-the-world-of-advanced-language-models-621dae57c22d

		*** Do OpenAI GPT-3/4 APIs use your data for model improvement?
		No. OpenAI does not process data submitted on its API to train OpenAI models or improve its offerings. However, it is important to keep in mind, data sent to their APIs are based on servers hosted in the US and OpenAI does store the data you send via API *for abuse monitoring purposes for up to 30 days*. However, *OpenAI allows you to opt out of this monitoring ensuring your data is not stored or processed anywhere*. You can opt-out using this form. This means your data lifecycle starts and ends with each API call. Data is sent via the API, the output is returned as a response from the API call. It does not remember or store any data sent in between each API request.
			**** Le formulaire dont il est question : https://docs.google.com/forms/d/e/1FAIpQLScrnC-_A7JFs4LbIuzevQ_78hVERlNqqCPCt3d8XqnKOfdRdQ/viewform?pli=1&fbzx=-8542825855662744033
		
		*** Does Azure OpenAI have the same policy?
		Yes. Azure OpenAI Service does not process data submitted on its API to train models or improve its offerings. Similar to OpenAI, they do store the data you send via API for abuse monitoring purposes for up to 30 days. Here is an overview of how your data flows: +
		image:openai-30-days-data-retention_01.jpg[] +
		However, *Microsoft allows you to opt out of this monitoring* ensuring your data is not stored or processed anywhere. You can opt-out using this form. On top of this, Azure already provides network security through security features such as private networks and endpoints
		image:openai-30-days-data-retention_02.jpg[]
			**** Les schémas viennent de cet article de Microsoft : https://learn.microsoft.com/en-us/legal/cognitive-services/openai/data-privacy#how-does-the-azure-openai-service-process-data
			**** le formulaire dont il est question : https://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xURE01NDY1OUhBRzQ3MkQxMUhZSE1ZUlJKTiQlQCN0PWcu

* https://research.aimultiple.com/large-language-models/#easy-footnote-bottom-1-63352
	** Language models' capabilities are limited to the textual training data they are trained with, which means they are limited in their knowledge of the world. The models learn the relationships within the training data, and these may include:
		*** False information
		*** Race, gender, and sex bias
		*** Toxic language

* https://pandia.pro/guide/quest-ce-quun-grand-modele-de-langage-llm-large-language-model/ : défis et limites des LLMs
	** *Coût et complexité* : Les LLM sont coûteux en termes de ressources de calcul, ce qui rend difficile leur déploiement et leur utilisation à grande échelle.
	** *Impact environnemental* : L'entraînement des LLM consomme une quantité importante d'énergie, ce qui a un impact environnemental non négligeable.
	** *Bias* : Les LLM, étant entraînés sur de vastes ensembles de données, peuvent hériter des biais et des stéréotypes qui peuvent être présents dans les données d'entraînement.
	** *Éthique* : Les LLM sont capables de générer des textes hautement convaincants, ce qui soulève des questions d'éthique et de responsabilité, notamment en ce qui concerne la désinformation, la manipulation et l'usurpation d'identité.

* https://datascientest.com/large-language-models-tout-savoir
	** *Les biais* : les capacités des modèles de langage sont limitées aux données textuelles avec lesquelles ils sont formés. Ce qui peut produire de fausses informations, des préjugés, voire un langage toxique.
	** *La fenêtre contextuelle* : chaque large language model ne dispose que d'une certaine quantité de mémoire. Au-delà d'un certain nombre de tokens en entrée, ils ne pourront plus réaliser les tâches demandées. 
	** *Les coûts* : le développement de grands modèles linguistiques nécessite des investissements très importants (systèmes informatiques, capital humain, énergie…).
	** *L'impact environnemental* : pour fonctionner, les projets LLM utilisent des centaines de serveurs. Or, ces derniers consomment une énorme quantité d'énergie et provoquent une empreinte carbone considérable.

*SLIDES*

* ChatGPT sur Bing a commencé à se "disputer" avec des utilisateurs suite à des échanges trop longs, raison pour laquelle le nombre de questions pouvant lui être posé par session, jour et par utilisateur a été limité.
* La "triche" dans le milieu académique : comment considérer l'aide (triche ?) apportée par ChatGPT ? Comment encadrer l'usage ?
* Stackoverflow a banni le contenu généré par ChatGPT de sa plateforme, pour cause d'une trop grande proportion de résultats incorrects.

==== Les conséquences pour nos métiers

* DONE - 2022/12/22 - BFM TECH & co : de nouveau révolution apportée par ChatGPT et DALLe (IA générative)
	** Va à terme impacter notre métier qui penche de plus en plus vers l'intégration : la majorité du code que nos ITs génèrent est simple, et pourra donc l'être par une IA.

* Marketplace de prompt comme PromptBase : https://promptbase.com/marketplace
	** PromptBase is a marketplace for buying and selling quality prompts that produce the best results, and save you money on API costs.
	** -> On commence à parler de "Prompt engineer", c'est une tendance à suivre

* ChatGPT pour aider les développeurs (ou faire le travail à leur place ?)
	** GPT3 est disponible depuis des mois, et GitHub Copilot depuis des années maintenant

*SLIDES*

Actuellement, du fait principalement de la multiplication des technologies disponibles pour répondre à un même besoin, et d'un marché tendu où les ressources et les compétences manquent, la demande en matière de prestation s'est déplacée du développement logiciel vers l'intégration logicielle. +
Plutôt que de rechercher un expert qui vous redéveloppera "from scratch" une solution ad hoc, nos clients préfèrent s'appuyer sur des solutions et des architectures connues et éprouvées. Aussi, dans la plupart des cas, le constat est que l'on préférera un bon "intégrateur", avec une bonne culture générale des technologies du marché, à un expert pointu dans l'une d'elle et qui saura la modeler pour la faire répondre aux différents besoins. +
Les experts seront bien entendu toujours requis, mais dans une proportion moindre que par le passé.

Ce n'est pas encore demain qu'une IA pourra remplacer un expert et les connaissances poussées qui sont les siennes, le niveau de raisonnement des IA n'est pas suffisamment bon pour cela. +
Par contre, du fait de leur savoir encyclopédique impossible à concurrencer, les IA peuvent connaître les bases de "toutes les technologies du marché". +
Aussi, elles vont, au minimum et sous très peu de temps, intégrer le quotidien des missions d'intégration, NOS missions, et savoir "prompter" correctement une IA va être un gros plus pour les consultants dans un 1er temps, et devenir complètement indispensable à moyen terme (tel que c'est parti, je dirais 1 à 2 ans, donc presque demain !). +
Certaines ressources parlent déjà de "prompt engineer" pour les IT maîtrisant le prompt des IA, certains prompt se vendant déjà au sein de marketplace dédiées comme https://promptbase.com/marketplace[PromptBase]

Comme expliqué lors du précédent état des lieux technologique, Softeam a évolué d'une société d'experts dans la modélisation logicielle vers une ESN généraliste. +
Nos consultants sont davantage placés sur des missions d'intégration que sur des missions d'expertises ou de développement "from scratch". +
Sur ces missions d'intégration, la connaissance encyclopédique des technologies du marché possédée par les IA est un avantage indéniable. +
Les consultants qui seront formés sur ces technologies seront rapidement grandement avantagés par rapport aux ceux qui ne le sont pas. +
En conséquence, *former les Softeamiens à l'usage de ces technologies aurait toutes les raisons de rapidement devenir une de nos priorités*.

==== Perspectives futures

* Etat des lieux de l'IA par le Dr Alan D. Thompson à Devoxx Belgique 2022 : https://www.youtube.com/watch?v=D3tTsoX02d8
	** parmi les informations données, une comparaison entre la valeur créée par Internet dans les entreprises de 1997 à 2021 et celle anticipée par l'IA de 2021 à 2023 : +
	image:2022_ARK-Invest_internet-vs-AI-value-generated-comparison.png[]
		*** source du graphique : https://ark-invest.com/articles/analyst-research/productivity-gains-could-propel-the-ai-software-market-to-14-trillion-by-2030/

* 2023/04/23 : https://pandia.pro/guide/quest-ce-quun-grand-modele-de-langage-llm-large-language-model
	** *Des modèles plus compacts et efficaces* : Des efforts sont déjà en cours pour réduire la taille des modèles tout en maintenant leur performance, ce qui permettra de déployer les LLM sur des appareils avec des capacités de calcul limitées.
	** *Amélioration des métriques d'évaluation* : Pour évaluer correctement les performances des LLM, de meilleures métriques d'évaluation et des méthodes d'interprétation sont nécessaires.
	** *Automatisation de la création de contenu* : L'une des applications les plus prometteuses des LLM est l'automatisation de la création de contenu, pour les médias sociaux, les blogs, les publicités et plus encore.
	** *Réduction des biais et amélioration de l'éthique* : Les chercheurs et les développeurs s'efforcent de réduire les biais présents dans les LLM et de les rendre plus éthiques et responsables.

==== Du côté des IA génératrices d'images

* Guide complet sur DALL-E : https://www.lebigdata.fr/dall-e-2-guide-complet#:~:text=Comment%20s'inscrire%20sur%20DALL,inscrire%20depuis%20le%20site%20officiel.

* https://www.commentcoder.com/generateurs-images-ia/ : les meilleurs générateurs d'images par IA +
Les 5 meilleurs : 

	1. Jasper Art : spécialisé dans l'IA
	2. Nightcafe : Essai gratuit et moins cher
	3. MidJourney : Le plus facile (Discord)
		** le plus grand concurrent de DALL-E (à confirmer)
	4. OpenAI DALL-E 2 : Création d'images réalistes
		** le plus connu actuellement (car OpenAI)
	5. Stable Diffusion : Transformation d'images

* use case "simple et utile" : création d'images libre de droits d'autres pour les présentations (pour le moment...)

* Pour bien prompter une IA génératrice d'images : 
	** https://www.commentcoder.com/prompt-ia/
	** https://www.commentcoder.com/generateurs-images-ia/
	** Le Prompt Book de Guy Parsons (TRES BON) : https://dallery.gallery/the-dalle-2-prompt-book/
	** le subreddit de DALL-E 2 : https://www.reddit.com/r/dalle2/

* Fin 2022 Jason M Allen a gagné un concourt d'arts avec une image créée par une IA générative (MidJourney) "Théâtre d'opéra spatial" : 
	** https://intelligence-artificielle.developpez.com/actu/336145/Une-oeuvre-d-art-generee-par-l-IA-a-remporte-la-premiere-place-a-un-concours-de-beaux-arts-a-une-foire-d-Etat-et-les-artistes-sont-furieux/
	** https://www.arts-in-the-city.com/2022/09/07/une-ia-secoue-le-monde-de-lart-en-remportant-un-concours/
	** Pour les autres création de Jason Allen, voir : https://www.google.com/search?q=jason+allen+space+opera&sxsrf=AJOqlzXqkaGZz5anmc2x1pERjZc1LeuQyQ:1677085733168&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiYoIibz6n9AhUF57sIHdHrA9IQ_AUoAXoECAEQAw&cshid=1677085762268181&biw=3072&bih=1520&dpr=1.25

Exemples de génération d'images avec DALL-E : 

	* Prompt : "Cthulu, intricate sand sculpture, high detail, UHD" +
	image:dall-e_sand-sculpture-cthulu.jpg[]

Prise en main de MidJourney : 

	* Starting with MidJourney : https://www.youtube.com/watch?v=zPcnHFYxXxk
	* Quick Start officiel de MidJourney : https://docs.midjourney.com/docs/quick-start
	* How to add the MidJourney bot to your own Discord server : https://docs.midjourney.com/docs/invite-the-bot

2023/03 : MidJourney met fin à son utilisation gratuite sans abonnement

==== DEMO : génération d'avatar animé

* techno utilisées : MidJourney, studio D-ID
* Instructions, tutoriels pour la création d'avatars animés par IA générative : 
	** Forget Lensa AI! Make Avatars with Midjourney : https://www.youtube.com/watch?v=LWE3BXkb50Q
	** Bring Your MidJourney AI Avatar To Life (AI Animation) : https://www.youtube.com/watch?v=RN2n6BGg8RI
	** Créez votre propre avatar animé par l'IA en 10 minutes. Guide pas à pas : https://www.youtube.com/watch?v=_u4JYYNcgN0

Conclusion : le résultat est bon, avec un gros effet "wahou !" MAIS n'est pas encore parfait. +
Selon moi, nous sommes vraiment dans la phase de "boum" du cycle de hype du Gartner (AJOUTER UNE PHOTO DU CYCLE !), il faut rester très prudent sur les "vrais" usages de la techno, ceux qui vont pouvoir être réellement utilisés en PROD, MAIS il est capital de TOUT DE SUITE s'intéresser à ces nouvelles technologies.

* POC Softeam : génération d'avatar animé racontant l'histoire de Softeam

	** Prompt de génération d'image dans MidJourney : +
	portrait of an American woman aged 25-30 with brunette hair, clear facial features, happy expression, Cinematic, 35mm lens, f/1.8, accent lighting, global illumination, --uplight --v 4

	** Animation de l'avatar avec Studio D-ID, modèle de voix française "Yvette"
		*** Nom de l'avatar "Camille Marquet"

	** Texte pour l'avatar - Acte I de l'histoire de Softeam : 
+
----
Softeam a été créé le 30/11/1989 par François Salin, Marc Clavereau, Philippe Desfray et Patrick Linesmeilleur.
Ils travaillaient à l'époque pour CR2A-DI, une ESN spécialisée en informatique technique et industrielle. 
C'est durant un voyage du CE qu'ils ont eu l'idée de monter une société ensemble : Softeam !
La société a pour objectif de fournir des solutions dans les domaines du conseil, des produits et de la formation sur la modélisation et la méthodologie de développement. 
Il s'agit là de l'expertise technique historique de Softeam, avec très vite l'Atelier de Génie Logiciel Objecteering comme fer de lance.

En 1990, Philippe Desfray crée la méthode de conception Objet "Classe Relation".
Puis en 1991, la société met sur le marché l'Atelier de Génie Logiciel "Objecteering", support de cette méthode.
Il faut se rappeler qu'en 1991, UML n'existait pas encore, ce langage ayant été créé en 1995 par l'éditeur Rational. Ce que faisait Objecteering était alors unique, c'était l'AGL le plus utilisé de France.
Grâce à cet AGL, Softeam s'est imposé dans de grands comptes comme France Télécom, Matra, EDF et Canal+ entre autres.

En 1996, Softeam devient contributeur de l'Object Modeling Group, pour participer à la définition du standard UML.
Puis en 1998 Softeam ambitionne d'exporter Objecteering aux US, et de concurrencer Rose de Rational.
----

		*** remplacer "Salaün" par "Salin" pour avoir une prononciation correcte
		*** remplacer "Linsmeier" par "Linesmeilleur"

-> vidéo sauvegardée en local et sur mon OneDrive (CTO et le POC avatar IA animé)

=== 2023/09/29 - Préparation états des lieux technologiques Softeam

Le domaine évolue de nouveau (oui, encore…), avec un changement de paradigme : + 
-> Le *LLM* n'est plus une "solution en soi" mais devient *une brique dans un pipeline d'IA*

Stack technologique "du moment" pour une application de recherche / search basée sur l'IA générative :

	* un *LLM* : OpenAI, Hugging Face, Dolly, etc.
	* *LangChain* : le framework de « glue » de la solution
	* *Streamlit* : le front / la web app
	* une *BDD vectorielle* : Pinecone, Chroma, Elastic search, Postgre, etc.
		** Liste des vector databases : https://thedataquarry.com/posts/vector-db-1/[] +
		image:20230929_etat-des-lieux-tech_vector-databases.jpg[]

* l'IA évolue vers Langchain et les agents
	** le LLM devient un outil au sein d'un "workflow IA"
	** et base de données vectorielle pour Langchain
	** et parler du move vers les embeddings

==== Guerre de l'IA et concurrence

* Dans la guerre des IA génératives, Google vient de demander à ses chercheurs de *ne PLUS publier leurs travaux*.
	** OpenAI s'est effectivement servi d'eux (modèle Transformer de 2017) pour créer un produit plus vite que Google.
	** De la même façon, OpenAI ne publie pas non plus ses travaux sur GPT 4, 
	** et côté Méta, LLaMa est disponible du fait d'une "fuite", et ne correspond pas à une mise en open source "officielle".

-> On voit donc bien la *culture du secret* s'installer pour essayer d'être le 1er sur le domaine.

* Un des plus grands *cabinet d'avocats Allen & Overly* s'est associé avec OpenAI pour créer *leur propre chatbot ("Harvey")*, intégré depuis quelques semaines dans les 3000 ordinateurs du groupe.
	** En par exemple *20 sec*, Harvey sors une cartographie des jurisprudences *là où cela aurait nécessité 5h du travail* d'un stagiaire auparavant. Suite à cela on a évidemment toujours besoin du stagiaire, qui peut dès lors s'appuyer sur le travail d'Harvey pour creuser un sujet particulier. +
	D'ici peu tous les contrats du cabinet seront portés sur Harvey.

-> Donc tous les sites de conseil juridique, tous les sites un petit peu pratico-pratiques pour eux, *c'est terminé*.

==== Les sociétés que l'IA fait exploser

*NVIDIA*

* Le groupe américain spécialisé dans les puces graphiques a dévoilé hier ses résultats au titre du deuxième trimestre décalé 2023. Porté par l'IA ainsi que ses GPU, composants particulièrement adaptés pour faire tourner les IA génératives, le géant américain a doublé son chiffre d'affaires pour atteindre 13,5 Mds$. Le bénéfice net lui ressort à 6,2 milliards, *multiplié par plus de 8* par rapport à l'année précédente. 
	** La capitalisation de Nvidia, qui plafonnait mercredi soir à hauteur de 1 160 Mds$, devrait connaître un nouveau boost aujourd'hui.
	** Donc capitalisation juste derrière Amazon pour une boîte qui fait des processeurs, dont l'importance actuelle de l'IA

* Pour des graphes de la capitalisation, voir : 
	** https://www.netcials.com/financial-marketcap-history-usa/1045810-NVIDIA-CORP/
	** https://www.reuters.com/technology/global-markets-marketcap-2023-08-01/

image:20230929_etat-des-lieux-tech_nvidia-capitalisation_02.jpg[width=600]
image:20230929_etat-des-lieux-tech_nvidia-capitalisation_01.jpg[width=600]

* On voit bien le boum représenté par la crypto PUIS l'IA pour Nvidia
	** Globalement, les analystes voient bien NVidia franchir rapidement (2024) la barre des 2 000 milliards de capitalisation boursière.

	** DONC, on garde un oeil sur les technologies de Nvidia, tout particulièrement leurs solutions de développement comme *CUDA*, car il n'est pas impossible que nous ayons des demandes dessus un jour (même si pour le moment, ce n'est pas notre domaine métier ET ENCORE)

		*** https://developer.nvidia.com/cuda-toolkit[] :
			**** The NVIDIA® CUDA® Toolkit provides a *development environment* for creating high performance GPU-accelerated applications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated embedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers. 
			**** The toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime library to deploy your application. +
			Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers can *develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs*.

		*** https://en.wikipedia.org/wiki/CUDA[] : 
			**** CUDA (or *Compute Unified Device Architecture*) is a *proprietary and closed source parallel computing platform* and *application programming interface (API)* that allows software to use certain types of graphics processing units (GPUs) for general purpose processing, an approach called general-purpose computing on GPUs (GPGPU). *CUDA is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements*, for the execution of compute kernels.
	
		*** CUDA peut être utilisé avec un certain nombre de langages de programmation, notamment C, C++, *Python* et Fortran.
			**** Le Python est complètement dans notre scope

		*** Et, dans des cas spécifiques, comme l'IA, où les GPU seraient la plateforme d'exécution des applications, il n'est pas impossible du tout que *CUDA devienne un concurrent de Spark* pour l'exécution de traitements parallèles.
			**** CUDA offre de meilleures performances que Spark car spécialement designé pour fonctionner avec des GPUs (ceux de Nvidia). +
			Spark est certes plus polyvalent que CUDA, mais si on sait précisément que l'on veut de la perf sur GPU, pour de l'IA par exemple, CUDA apparaît comme un choix très adapté.

	** Donc, OK pour garder un oeil sur Rust, mais dans ce cas il faut de la même façon garder un oeil attentif sur la plateforme CUDA, car sa cible est vaste avec une parfaite adéquation au développement actuel de l'IA.
		
* *Contexte géopolitique* à connaître : *guerre économique entre US et Chine*
	** 2022/09/01 - BFM : Nvidia interdiction (par le commerce américain) exporter puce A100 et H100 (encore en développement) en Chine. Restrictions également pour AMD

*Hugging Face*

* Hugging Face lève auprès des plus grands et passe à une *valorisation de 4.5 Mds$*

	** Le spécialiste de l'IA open source *lève 235 M$*. Sa valorisation est plus que doublée et passe à 4,5 Mds$. 
	** Nvidia, Google, Amazon, Intel, AMD, IBM et Qualcomm ont participé à un tour de table, mené par Salesforce Ventures, de 235 M$. Cette opération fait plus que doubler la valorisation de cette entreprise, créée par des Français et opérant entre Paris et New York. Elle vaut désormais 4,5 Mds$. 
		*** Et de nouveau, tout est lié, qui est présent à ce tour de table pour financer un spécialiste de l'IA ? Mais (entre autres) *Nvidia*

	** Inconnu du grand public, Hugging Face est une *plateforme de partage spécialisée dans l'IA et le machine learning*. +
	Des développeurs du monde entier peuvent y déposer des modèles pré-entraînés ou des jeux de donnés, qui seront réutilisés, adaptés et améliorés par d'autres. 
	** Le laboratoire d'IA de Meta a par exemple choisi *Hugging Face pour héberger Llama 2*, son dernier modèle de langue. 
	** Et des groupes comme Renault, Pzifer ou Roche piochent dans cette bibliothèque open source pour concevoir leurs services dopés à l'IA sans avoir à commencer de zéro.

* Hugging Face est une plateforme open source qui fournit des outils et des ressources pour le développement d'applications basées sur l'IA générative. Elle est composée de deux principaux produits :

	** *La bibliothèque Transformers* : une bibliothèque open source qui fournit des implémentations de modèles de langage basés sur l'architecture Transformer. +
	Elle permet aux développeurs de : 
		*** *Entraîner des modèles de langage* : la bibliothèque Transformers fournit des implémentations de modèles de langage basés sur l'architecture Transformer, qu'il est ensuite possible d'entraîner sur des ensembles de données textuelles.
		*** *Déployer des modèles de langage* : la bibliothèque Transformers fournit des API simples pour déployer des modèles de langage. +
		Ces derniers peuvent être déployés soit directement sur les serveurs de Hugging Face, soit sur serveurs privés (attention aux coûts d'infra dans ce dernier cas)
		*** *Utiliser des modèles de langage pré-entrainés* : la biblithèque propose une grande variété de modèles de langage pré-entraînés pouvant être directement utilisés dans les applications.

	** *Le Hub Hugging Face* : une plateforme de partage de modèles, d'ensembles de données et d'applications IAG.

*OpenAI*

* Pour *relancer l'engouement de ses débuts*, OpenAI mise sur une *version professionnelle de son chatbot (ChatGPT)*. L'entreprise veut retrouver la confiance des entreprises, qui ont parfois peur pour leurs données personnelles.
	** Le lancement intervient alors que ChatGPT ne réussit pas à capitaliser sur l'emballement provoqué par son lancement, qui en avait fait alors l'application atteignant le plus rapidement les 100 millions d'utilisateurs, avant l'arrivée de Threads, le rival de X/Twitter par Meta, au début de l'été.

* Voir l'article https://www.blogdumoderateur.com/openai-lance-version-chatgpt-entreprises/
	** *ChatGPT Entreprise*, une *version sécurisée* et améliorée du chatbot
	** OpenAI est clair : "Vous possédez et contrôlez vos données commerciales dans ChatGPT Entreprise." La firme affirme que vos conversations professionnelles avec le chatbot ne sortent pas de votre structure et ne sont pas utilisées pour entraîner les modèles de langage d'OpenAI. +
	Toutes les données sont chiffrées « au repos comme en transit », avec les protocoles AES-256 et TLS 1.2+, et en conformité au regard de la norme SOC 2.
		*** C'est complètement ce que fait déjà Microsoft avec Azure OpenAI...

* ChatGPT Enterprise est un produit indépendant de Microsoft : la stratégie d'entreprise entre OpenAI et Microsoft est... surprenante. +
-> A mon avis, cela ne pourra pas rester éternellement "2 boîtes aussi indépendantes" vu l'argent que MS a mis dedans
	** Il y aura peut-être une *phase de migration / d'ajustement à prévoir* (entre produits MS et OpenAI)

==== Changement de paradigme de l'IA : passage à des modèles de petites tailles 

-> A mettre en parallèle de l'*embedding* et du *"Bring your own Data"*

* GPT-4 : *Composition de plusieurs LLM spécialisés plutôt qu'un seul énorme* +
-> C'est la tendance actuelle (modèles plus petits spécialisés), de même que les outils comme *LangChain*

	** *LangChain* (https://en.wikipedia.org/wiki/LangChain[]) : 
		*** LangChain is a framework designed to simplify the creation of applications using large language models.
		*** A complete set of powerful building blocks. +
		Get started fast with our comprehensive library of open-source components and pre-built chains for any use-case.
			*** Bonne image à récuperer : image:https://framerusercontent.com/images/5d7KfRriC6zji11ZFnwLotdqcHQ.svg[]
		
image:20230929_etat-des-lieux-tech_azure-bring-your-own-data_01.jpg[]

	* On retrouve un autre schéma du "Bring your own data" de MS ici : https://msandbu.org/how-to-setup-azure-openai-with-chatgpt-using-your-own-data/ +
	image:20230929_etat-des-lieux-tech_azure-bring-your-own-data_02.jpg[]

image:20230929_etat-des-lieux-tech_langchain-embeddings.jpg[]

* Parler d'*embeddings* avec les schémas du "Bring Your Own Data" de Microsoft et celui de LangChain de la BGPN, ainsi que des *bases Vector* : 

	** Pour la sauvegardes des embeddings en base vectorielle, le split de docs (les chunks) le plus courant semble être le 1000 tokens / characters.
	** Trouver les vecteurs les plus proches : c'est LA où différents algos existent (produit scalaire, distance euclidienne, similarité cosinus)
		*** Le principe : on trouve les vecteurs les plus proches de sa question, et ce sont ces derniers qu'on envoie dans sa requête au LLM (donc on envoie quelque chose de plus ciblé et plus petit dans le contexte du LLM)
	** Dans l'idée, *on rajoute une mémoire externe au LLM* (par exemple ce que fait Langchain).
	** PostgreSQL a PJVector qui rajoute le support vectoriel à PostgreSQL pour ces use cases.
	** Quelques exemples de BDD vectorielles : Pinecone, Chroma, Elastic search, etc.

* *fonctionnement d'une solution de recherche opérée par l'IA et utilisant l'embedding de document* : 

	** Pour ce workflow, le *LLM* fait en fait office de *moteur de compréhension*
		*** Si on prend le cas de ChapGPT, même en version 4 (à l'exception de son usage avec Bing OU de la dernière version Enterprise), ce dernier est limité à ses *données d'entraînement qui s'arrêtent à 2021/09*.
		*** Nous sommes maintenant fin 2023, ces données commencent donc à être *obsolètes*, et OpenAI ne se presse "pas réellement" pour changer cela (toujours malgré la sortie de la dernière version Enterprise). +
		-> On peut donc en conclure que OpenAI ne souhaite pas vraiment mettre à jour régulièrement les données d'entraînement de ChatGPT. +
		Et ils devaient avoir prévu dès le début (réentraîner est très cher) que l'usage de leur LLM change, et que ce dernier finisse par être utilisé comme une brique d'un pipeline d'IA. +
		C'est ce stade que nous avons atteint depuis

	** Pour faire des recherches sur des corpus de docs que le LLM ne connaît pas via ses données d'entraînement : 
		*** on commence par les transformer en vecteur (embeddings : séries de nombres, d'une taille à définir, ex : 128 valeurs) à l'aide du LLM
		*** puis on les sauve dans une BDD vectorielle (Pinecone, Chroma, Elastic search, Postgre, etc.)
		*** puis, lorsque l'utilisateur tape son prompt, on convertit également ce dernier en vecteur, et, par une *méthode de similarité*, on va trouver les vecteurs des corpus de documents qui ressemblent le plus au vecteur du prompt : +
		image:202303_Elastic_Embedding-Vector-search-similarity_01.jpg[]
		image:202303_Elastic_Embedding-Vector-search-similarity_02.jpg[]
			**** Ces schémas viennent d'une conférence de la société Elastic donnée en 2023/03 : +
			https://youtu.be/yvGI73O6d8M?t=401
		*** et une fois qu'on a trouvé les corpus de docs les plus proches de notre vecteur de prompt, on peut tout envoyer au LLM, prompt et doc, et ce dernier pour alors chercher à répondre au prompt en se servant des documents sélectionnés

	** Cf le speaker Databricks (2023/07/15 - BDH 166), on envoie son Doc au LLM et c'est ce dernier qui renvoie la représentation vecteur du doc qui est à stocker dans une base vecteur.
	** Ensuite on peut commencer à faire des requêtes, le plus souvent de requêtes de similarités : "quel est le meilleur podcast ?" envoyé à un LLM, qui nous renvoie un embeddings représentant la question, puis on vient rechercher dans le corpus de docs qu'on a indexé les plus similaires à la question puis on vient interroger un LLM avec la question et les docs similaires remontés. +
	Comme cela on peut spécialiser les réponses d'un LLM ou lui donner accès à des infos qu'il n'avait pas au moment de son entraînement.
	C'est tout cela que sort *Databricks* (en s'appuyant sur leurs tables Delta) : des *embeddings* sont créés ainsi qu'une *API de search*

	-> DONC DE PLUS EN PLUS *PONT ENTRE LA DATA ET L'IA*

* *Stack technologique "du moment"* pour une application de recherche / search basée sur l'IA générative : +
un *LLM* + *LangChain* (la glue) + *Streamlit* (le front / la web app) + une *BDD vectorielle* (Pinecone, Chroma, Elastic search, Postgre, etc.)

*Passage à des modèles de plus petite taille*

* Aux Etats-Unis, les plus grands laboratoires en IA s'activent pour mettre le doigt sur la découverte qui pourrait rendre l'assistant d'OpenAI et son modèle de langue (LLM) GPT-4 obsolète. Parmi les structures qui font la course en tête figurent le MIT, le groupe Meta ou encore le franco-américain Hugging Face. +
Côté MIT, c'est le Computer Science and Artificial Intelligence Laboratory (CSAIL) qui est à la manœuvre. Mi-juin, le laboratoire levait le voile sur une IA baptisée SimPLE pour Simple Pseudo-Label Editing. L'enjeu ? *Démontrer que des modèles de petite taille peuvent largement dépasser les performances des grands modèles*. 

* Meta, lui, mise sur l'open source. Avec la version 2.0 de son modèle de langue LLaMA, le groupe de Mark Zuckerberg a livré pour la première fois mi-juillet une solution sous licence libre (GNU GPL) utilisable au sein d'un produit commercial.

* Mais l'initiative de Meta est loin d'être isolée. Déjà, mi-2022, *Hugging Face* publiait les sources de Bloom. De mai 2021 à mai 2022, sa conception a fédéré plus de 1 000 chercheurs issus de 60 pays.
	** C'est là toute la force de l'open source que de pousser vers l'open innovation. Le logiciel libre distille la technologie jusque dans les moindres PME et start-up. Il permet de récupérer un modèle puis de l'entrainer sur un data set maison pour le tester voire le mettre en production sur un cas d'usage spécifique. Sur ce plan, l'open source a déjà permis de montrer qu'il était possible de personnaliser de petits LLM avec de petits data set et, partant de là, d'obtenir immédiatement des résultats opérationnels.

* Et Yann LECUN chez Meta nous annonce pour dans bientôt un nouveau type d'IA basé sur une nouvelle technologie, différente des Transformers

.Rappel
[NOTE]
====
*Les plus grands experts de l'IA* sont majoritairement *chez Google* aujourd'hui, et il ne faut pas oublier que les Transformer ont été créés par leurs équipes. +
====

* Rappel : Google Bard is now powered by Google's very own and most advanced large language model (LLM) *PaLM 2*, which was unveiled at Google I/O 2023.

Conclusion sur l'IA : 

	* Il est urgent d'attendre ! Nos clients, qui ne sont pas des éditeurs tech faisant du "bleeding edge", ne peuvent pas s'appuyer des techno alpha / beta, pouvant disparaître ou être remplacées du jour au lendemain, ou demandant un effort de développement / maintenance trop conséquent. +
	En conséquence, il est actuellement essentiel : 
		** d'attendre que le milieu de l'IA se stabilise
		** d'identifier précisément les besoins client pour vérifier si une solution à base d'IA gen est REELLEMENT utile pour eux. +
		-> Actuellement, proposer un "simple rewrap de ChatGPT" avec ses données limitées à 2021/09 (donc obsolètes ou manquant de fraîcheur) doit avant tout tenir du gadget ou du buzz...
		** RESISTER AU BUZZ ! Il faut que les directions fassent preuve de "courage politique" : ce n'est pas parce qu'on entend partout parler d'IA gen que l'on en a forcément besoin.
		** Pour des ESN comme nous, *FORMER SES EFFECTIFS* sur les concepts de l'IA gen : le prompting et ses risques et optimisations connues, les stacks derrière les pipelines actuels d'IA gen, etc.

=== 2023/10/13 - 12@13 Softeam - Acculturation IA générative

* 🔥*FANTASTIQUE site*🔥 sur les modèles de langages / LLM, avec les tailles de modèles, et régulièrement mis à jour : +
https://lifearchitect.ai/models/

	** il est bien expliqué ici que l'on peut parler de la *taille du modèle* en *tokens* ou en *To* (TB en anglais) : +
	https://lifearchitect.ai/gpt-4/#dataset

		*** Rappel : 1 token ~ 0.75 mot ~ 4 octets
			**** la taille des tokens est généralement spécifiée par le modèle de langage utilisé.
			**** La taille en octets communément admise pour 1 token est de 4 octets. Cela s'explique par le fait que les tokens sont généralement représentés par des entiers, qui occupent 4 octets en mémoire.
			**** Par exemple, le modèle de langage *GPT-3 utilise des tokens de 4 octets*. Cela signifie que la taille des données d'entraînement du modèle est de 4 fois supérieure à la taille en mots des données d'entraînement.

		*** Avec pour exemple GPT-4, cela donne :

			**** *Parameter count* : 1.76T (1,760B). Sparse mixture of experts (MoE).3
			**** ≈ 5.7x bigger than GPT-3 175B (175 milliards de paramètres)
			**** ≈ 14.3x bigger than Chinchilla 70B
			**** ≈ 0.8% the size of the human brain by count of synapses (125T synapses)

			**** *Dataset size (tokens)* : 16T (16,000B) estimated in 40TB. Maybe repeated tokens.
			**** ≈ 32x bigger than the GPT-3 dataset (499B tokens)
			**** ≈ 6.8x bigger than DeepMind MassiveText English (2.35T tokens)
			**** ≈ 3.2x bigger than DeepMind MassiveText Multilingual (5T tokens)
			**** ≈ 5.7x bigger than Google Infiniset (2.81T tokens)

		*** Cette page redonne toutes les caractéristiques de l'entraînement de GPT-4 👍

* https://transmitter.ieee.org/how-big-will-ai-models-get/[]

	** When experts talk about the advancement in AI, they usually focus on two aspects of the model's size: the *amount of data used to train the model*, and the *number of parameters that the model contains*.

	** "*GPT-3*, the predecessor to the much discussed ChatGPT, was trained on nearly *45 terabytes of text data*, and has more than *175 billion parameters*. Other AI models are getting even larger, with large companies working on models said to exceed 1.6 trillion parameters."
		*** donc GPT-3 : size 45 TB  parameters 175 B (billion)
		*** Attention ! "Billion" en anglais veut dire "milliard" en français...

	** Which brings up a second question. Just how much information is 45 TB of text? Quite a lot. One TB equals approximately 6.5 million pages of documents stored in common formats like word processing documents or .pdfs.

* *Paramètres d'un LLM* : +
Ce sont les valeurs qui sont apprises au cours du processus d'entraînement et qui sont utilisées pour *calculer la probabilité d'un mot* ou d'une séquence de mots dans un texte.

* *Token d'un LLM* : +
Les "unités de base" du LLM, des mots, lettres, symboles utilisés pour représenter le texte utilisé ayant servi à entraîner le LLM

* Expliquer le *RLHF* : Reinforcement Learning from Human Feedback

.Reinforcement Learning with Human Feedback (RLHF)
[NOTE]
====
Voir https://www.lemagit.fr/conseil/Petit-lexique-de-lIA-generative-les-grands-modeles-de-langage

L'apprentissage par renforcement est une méthode automatique consistant à récompenser ou sanctionner un comportement d'un agent (un système autonome) placé dans un environnement où il expérimente la manière de réaliser une tâche. L'agent a pour mission de maximiser la récompense en fonction d'objectifs.

L'apprentissage par renforcement avec retour d'information humain (Reinforcement Learning with Human Feedback ou RLHF) consiste à remplacer les objectifs par des commentaires écrits par des annotateurs.
====

*Architecture Transformer* : 

* L'*encodage* est effectué par une série de *couches d'attention multi-tête*. Chaque couche d'attention multi-tête consiste en une attention clé-valeur-rapport.
* *L'attention clé-valeur* est une fonction qui calcule la *similarité entre un token et les autres tokens de l'entrée*. La similarité est calculée en fonction des représentations vectorielles des tokens.

*Analogie pour expliquer l'attention multi-tête :*

	* Imaginez que vous essayez de comprendre une phrase. Vous pouvez le faire en lisant chaque mot de la phrase individuellement. Cependant, vous pouvez également le faire en vous concentrant sur les relations entre les mots.
	* Par exemple, vous pouvez vous concentrer sur la relation entre le sujet et le verbe de la phrase. Vous pouvez également vous concentrer sur la relation entre le verbe et l'objet de la phrase.
	* L'attention multi-tête est similaire à cette analogie. Elle permet au transformer de se concentrer sur plusieurs relations différentes entre les tokens dans une phrase.
	* -> En se concentrant sur plusieurs relations différentes, le transformer peut capturer un sens plus profond du texte.

*Autre explication*

* Soit la phrase suivante : "Le chat est sur la table."

* Le transformer va d'abord *tokeniser* la phrase en tokens individuels. Les tokens sont ensuite *transformés en représentations vectorielles*.

* L'attention est ensuite utilisée pour *calculer les relations entre les tokens*. La fonction d'attention calcule un *score d'attention pour chaque token*.

* Par exemple, le score d'attention entre le token "Le" et le token "chat" est élevé. Cela signifie que le transformer pense que les deux tokens sont liés.

* Les scores d'attention sont ensuite utilisés pour *calculer les représentations vectorielles des tokens*. Les représentations vectorielles sont calculées en pondérant les représentations vectorielles des tokens par les scores d'attention.

* Dans cet exemple, la représentation vectorielle du token "Le" sera pondérée par le score d'attention entre le token "Le" et le token "chat".

* Les représentations vectorielles des tokens sont ensuite utilisées pour générer une représentation vectorielle de la phrase. Cette représentation vectorielle est utilisée pour capturer les relations entre les tokens dans la phrase.

* L'attention multi-tête permet au transformer de se concentrer sur plusieurs relations différentes entre les tokens. Cela permet au transformer de capturer un sens plus profond du texte.

=== 2024/03/29 - Préparation états des lieux technologiques Softeam

* Comparaison à jour des derniers LLMs sortis :
	** https://subpage.app/blog/2024-Commercial-AI-LLM-pricing-compared-in-detail-GPT-Gemini-Cohere-Mistral
	** https://generationia.flint.media/p/guide-2024-meilleures-alternatives-chatgpt-claude-3
		*** TRES BON tableau comparatif

* https://en.wikipedia.org/wiki/Gemini_(language_model)
	** Pour les 1 million de tokens de Gemini, Google donne les chiffres suivants : +
	"which equates to roughly 1 hour of silent video, 11 hours of audio, 30,000 lines of code, or 700,000 words."

* présentation des différents Microsoft Copilot : 
	** https://medium.com/mseduth/microsoft-365-copilot-101-guide-a8fda5b64912[] : excellente présentation des différents Copilot de Microsoft avec de très bons schémas

* Très bonne présentation de l'*architecture Mamba*, le "successeur" de l'architecture Transformer : https://medium.com/@jelkhoury880/what-is-mamba-845987734ffc

	** Mamba is an advanced *state-space model* (SSM) designed for efficient handling of complex, data-intensive sequences.
	** "By integrating a selection mechanism into its state space models, Mamba can effectively decide whether to propagate or discard information based on the relevance of each token in the sequence."

	** *Linear time scaling* : Unlike traditional models, Mamba has the ability to process sequences linearly in proportion to their length.
	** *Selective SSM layer* : At the core of Mamba is a selective state-space layer that allows the model to selectively propagate or suppress information based on the input at each step. +
	Lastly, its design is inspired by something called *FlashAttention*, making it really well-suited for the powerful computers we have now.
	** *Hardware-friendly design* : Inspired by FlashAttention, Mamba's design is optimized for the high-performance computing resources currently available.

	🚀 *Linear Scaling with Sequence Length*: Mamba changes the game by scaling linearly (~O(N)) with sequence length, a vast improvement over the quadratic scaling (~O(N²)) of traditional Transformers. This means Mamba can handle sequences up to 1 million elements efficiently, a feat made possible with current GPU technology.

	💡 *Efficient Use of Data for Smarter Outcomes*: Mamba stands out by effectively utilizing larger datasets and networks to produce smarter results. It challenges the notion that simply having more data and a bigger network does not always lead to better performance.

	🖥️ *Optimized for GPU Efficiency*: Designed with modern GPU hardware in mind, Mamba addresses common computational inefficiencies, setting a new standard in machine learning architecture efficiency.

* Devin AI, the world's first fully autonomous *AI software engineer*.
	** https://www.cognition-labs.com/introducing-devin

* Apparition des *1eres contre-mesures anti-AI* : Nightshade et Glaze
	** https://glaze.cs.uchicago.edu/what-is-glaze.html
	** https://nightshade.cs.uchicago.edu/whatis.html
		*** "Nightshade's goal is not to break models, but to increase the cost of training on unlicensed data, such that licensing images from their creators becomes a viable alternative"
	** https://www.usine-digitale.fr/article/nightshade-l-outil-qui-fait-de-l-ombre-a-l-ia-generative.N2207147

	** N'importe quelle donnée du net peut techniquement servir à l'entraînement d'un modèle d'IA, ce que certains éditeurs ne se sont pas faits prier pour faire, permis ou pas… Au grand dam des ayants droit +
	Pour contrer ce comportement, les 1eres contre-mesures anti-entraînement des modèles d'IA apparaissent : Glaze et Nightshade +
	Le principe ? Empoisonner les données ! (data poisoning) +
	Et cela va probablement donner lieu à une course entre "poison et remède"

	** Chiffrement homomorphe : Les données sensibles sont chiffrées de manière à pouvoir être traitées et analysées sans les déchiffrer au préalable. Cela rend difficile pour les attaquants d'extraire des informations significatives des données pour l'entraînement de modèles de langage.
	** Botaniquement, la nightshade est vraiment vénéneuse : The species usually called nightshade in North America and the United Kingdom is S. dulcamara, also known as bittersweet and woody nightshade. Its foliage and egg-shaped red berries are poisonous, the active principle being solanine, which can cause convulsions and death if taken in large doses.

	** Rappelez-vous WoW et le "pourrissage" de l'hôtel des ventes...
	** Nightshade :"Nightshade's goal is not to break models, but to increase the cost of training on unlicensed data, such that licensing images from their creators becomes a viable alternative" +
	Glaze is a defensive tool that individual artists can use to protect themselves against style mimicry attacks, while Nightshade is an offensive tool that artists can use as a group to disrupt models that scrape their images without consent

* *Groq* et ses *LPU* : 
	** https://www.lemondeinformatique.fr/actualites/lire-groq-defie-nvidia-avec-ses-accelerateurs-lpu-92822.html

		** les LPU sont des *ASIC* (Application-Specific Integrated Circuit) : Circuits intégrés conçus pour une seule application et optimisés pour une performance maximale 

		*** "Le moteur d'inférence LPU (Language Processing Unit), est un système de traitement inventé par Groq pour gérer des applications à forte intensité de calcul avec un *composant séquentiel* comme celui des grands modèles de langage (LLM). Le moteur d'inférence LPU est conçu pour surmonter les deux goulots d'étranglement des LLM, la quantité de calcul et la bande passante mémoire"

	** Architecture interne des ASIC Groq (LPU) *spécialisée pour le traitement séquentiel* :
		*** Les LPU sont conçus spécifiquement pour le traitement séquentiel, ce qui est crucial pour les LLM qui traitent le langage mot par mot.
		*** Contrairement aux GPU qui adoptent une approche parallèle, les LPU exploitent mieux la *nature séquentielle du langage naturel*.

	** Quelques informations sur les *performances* des LPU de Groq : +
	https://blocksandfiles.com/2024/01/23/grokking-groqs-groqness/

=== 2024/xx/yy : Paris JUG ?

* LLM définitions
* RAG : 
	** pourquoi ? apporter les données personnelles
	** tech et comment faire : langchain & Co
	** RAG évolué : comme celui pour le SQL
* RAG is already dead (ou en tout cas peut-être prochainement plus "main stream")
	** context length
* Soft : Transformers et Mamba
* Hard : LPU et traitement séquentiel
* toujours période de grands changements : 
	** bébé -> adolescent
	** sécurité et 1ere attaque visant les LLM et leur supply chain
	** industrialisation : gestion des prompts et hallucinations

* Parler du changement de paradigme ? Interface conversationnelle

=== 2024/11/15 : préparation de l'état des lieux technologique

* Voir pour présenter 2 x 12@13 d'ici la fin d'année : 

	** en 1er : état des lieux tech : 
		*** frameworks du moment
		*** le passage aux agents
		*** présenter la conception d'un RAG avec : 
			**** Quarkus / EasyRAG
			**** Power Apps et Copilot Studio et Prompt Flow
		*** Data et IA Gen : les liens entre les 2 domaines

	** En 2e : effet WAOUHHH
		*** aller voir Karim et le delivery pour une éventuelle étude réalisée et les use cases testés
			**** Si ça a été fait côté ITSS, voir Ricardo côté Ouest

* Voir le book of news sur l'IA de Microsoft, tout particulièrement les exemples de RAG basés sur AI Search et les nouvelles architectures de référence : +
https://news.microsoft.com/build-2024-book-of-news/

* Voir également le repo GPT-RAG d'Azure : https://github.com/Azure/GPT-RAG
	** contient un exemple complet avec les infos de déploiement

* RAG-as-a-Service : 
	** https://menlovc.com/perspective/beyond-bots-how-ai-agents-are-driving-the-next-wave-of-enterprise-automation/

* Automatisation de la veille technologique : 
	** https://iapulse.substack.com/p/tuto-automatisez-votre-veille-avec

* Microsoft lance la v2 (weave 2) de Copilot et de Copilot Office 365 : +
https://www.microsoft.com/en-us/microsoft-365/blog/2024/09/16/microsoft-365-copilot-wave-2-pages-python-in-excel-and-agents/

	** Copilot Agents - les agents automatisent et exécutent des processus métiers, allant de simples prompts et réponses, à des agents plus avancés qui automatisent des tâches, jusqu'à des agents sophistiqués entièrement autonomes qui peuvent orchestrer d'autres agents.

IMPORTANT: Toutes les sources du moment le disent : nous passons à l'ère des *agents AI*

* "Nous sommes passés de l'IA prédictive que nous avons intégrée à notre offre en 2014 avec Einstein à l'IA générative que nous avons prise en compte dès 2023. Nous passons cette fois à la *troisième vague de l'IA qui se concrétise par des agents autonomes capables d'enchainer plusieurs actions* en vue d'objectifs précis", commente Kheira Boulhila, senior vice president Solution Engineering EMEA de Salesforce.

* Phase 1, 2 et 3 de l'IA avec montée en puissance des agents
	** 1) modèle brut >> 2) RAG >> 3) agents
		*** représenter le schéma du Naive RAG, Advanced RAG puis modular RAG (schéma dans ce fichier)
* domaine suffisamment porteur pour développement de matériel spécifique cf Groq et les accélérateurs pour Transformers

* De plus en plus de possibilités pour faire tourner un modèle sur mobile (voir Tech Café 2024/09 pour cela)

* Les modèles d'IA en entreprise : +
https://optimia.substack.com/i/149560071/les-modeles-dia-en-entreprise
	** en pas en B2C où OpenAI domine bien le secteur

* Les meilleures opportunités IA du moment : +
https://optimia.substack.com/p/les-plus-grosses-opportunites-ia
	** Fouille documentaire et le RAG : mais ça, on le sait depuis longtemps 😉
	** Les agent vocaux IA
	** Scraping intelligent avec l'IA
	** Recycler du contenu existant l'IA

* 2024/10 : Google rend public son outil de marquage des textes IA (SynthID-Text)
	** Pourquoi est-ce important ? Dans un contexte où la prolifération des contenus générés par l'IA soulève des questions de confiance et d'authenticité, la disponibilité d'outils de marquage standardisés devient un enjeu majeur pour l'ensemble de l'écosystème numérique. Mais bon, comme il suffit de réécrire ou de traduire...

* Les domaines du Cloud, de la Data et de l'IA (surtout Gen) ne font que se rapprocher. +
D'ici "peu", on ne les précisera plus, tout comme on parle beaucoup moins de "Big Data" qui a été remplacé par "Data" tout court
	** Il y a dans les faits encore des cas de "vrai" "Big Data", mais c'est devenu beaucoup plus rare, avec un sens bien plus précis qu'autrefois.

* Les derniers modèles sortis, comme o1 de OpenAI, *mettent davantage l'accent sur le "raisonnement"*
	** Ce dernier permet de mieux répondre à des problématiques complexes comme la résolution de problèmes mathématiques par exemple
	** OpenAI dit que o1 a 120 de QI et le niveau d'un PhD

* Le domaine de l'IA Gen a un gros besoin d'énergie, raison pour laquelle les grands Cloud Provider cherchent maintenant à *produire leur propre énergie*, souvent en considérant l'*option nucléaire*
	** Ce sujet tire la *problématique de la consommation d'eau* pour le rafraîchissement de ces data centers : +
	IMAGE DE LA CONSO DE L'EAU A REPRENDRE
	** et pensez à vos enfants : ne vous servez pas de l'IA gen comme d'un moteur de recherche, regardez ce que cela coûte en énergie et en eau...

* Problématique de l'intelligence des LLM : qu'est-ce que l'intelligence ? 
	** Cf dictionnaire : données (connaissances) ET capacités de traitement
		*** Comparé l'Homme à l'IA gen, dont la *connaissance "encyclopédique" est impossible à concurrencer*
	** Et si on va "trop loin" dans le développement des modèles de langage, il est de plus en plus question de la mise en place de "kill switch" pour stopper ces développements afin de "comprendre un peu mieux ce qu'on est en train de créer"

* l'avenir de l'évolution des modèles de langage (en lien avec la notion d'intelligence), une meilleure compréhension.
	** Voir l'article du 2024/10/16 et son : +
	"This indicates that many of these *models rely heavily on memorized examples from their training data* rather than on a true, underlying understanding of symbolic concepts."

* Du côté du développement des agents IA, parler des LAM (Large Action Models)
* Redonner également le AI Agents Landscape ? (présent dans ce fichier)

* Parler des 4 "agentic patterns ?"
	** *Function calling* (tool use pattern) is one of the 4 agentic patterns : +
	image:202403_4-agentic-patterns-Andrew-Ng.jpg[]
		*** Image provenant de https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/Artboard-1-copy-4.webp
	** Ces 4 agentic patterns ont été définis initialemnent par Andrew NG, le fondateur de DeepLearning.ai, dans cette série d'articles : +
	https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io
	** Pour un article décrivant une implémentation des 4 agentic patterns SANS framework d'orchestration type langchain : 
	https://github.com/neural-maze/agentic_patterns?tab=readme-ov-file#the-4-agentic-patterns

* 2024/11/14 : Sam Altman concernant les agents (https://www.generation-nt.com/actualites/openai-agent-ia-autonome-operator-controle-ordinateur-2052559) : 
	** "Lors d'une séance de AMA (Ask Me Anything) sur le réseau social Reddit, Sam Altman, le patron et cofondateur d'OpenAI, a déclaré : +
	"Nous aurons des modèles de plus en plus performants, mais je pense que ce qui sera la prochaine grande avancée sera les agents." +
	-> A priori, c'est prévu pour 2025 du côté d'OpenAI, dont l'outil le plus proche d'aboutir exécuterait des tâches dans le navigateur web."

* On pourrait également parle des LoRA, l'adaptation par mode auxiliaire ou Low-Rank Adaptation (pour éviter d'avoir à recourir à des entraînements trop coûteux)

* Problématiques de sécurité et de confidentialité des données qui poussent la recherche vers la création de modèles plus petits (SLM) pouvant tourner on edge et sur mobile
	** retrouver le tableau de comparaison des tailles de modèles pour les classer entre STLM (Super Tiny Language Model), SLM et "vrais" LLM

* Et de l'IA Gen et donc des modèles de langage sur tous les portables, cela implique une explosion des usages que ne couvrira pas la 4G, cela va forcer le passage à la 5G
	** attendez la fin d'année et les offres sur les forfaits 5G

* Toujours côté évolution du LLM et "l'après Transformer", parler un peu de Mamba et des selective SSM ?
	** pour faciliter le traitement des longs contextes en évitant les complexités quadratiques

* Parler de l'XAI, l'Explainable AI ? Et des nouvelles régulations (IA Act) en train d'être créées pour encadrer l'IA ?

* Parler de NVidia et de sa nouvelle capitalisation boursière (la 1ere au monde)

* Parler du besoin d'évaluation des LLM ? 
	** voir 20240613_Microsoft_Data-Innovation-Day.adoc

Gemini : 

.Prompt de contexte
----
Pour une conférence d'1 heure à destination d'une population de consultants IT de mon ESN, présente-moi l'évolution de l'IA Gen de ses débuts depuis la sortie de ChatGPT jusqu'à aujourd'hui.

Mets-en avant les changements d'architecture (usage "brut" du LLM, passage aux RAGs "simple" puis à ceux plus avancés, puis aux agents aujourd'hui, etc.), la structuration de la gouvernance de l'IA Gen, la prise en compte de la sécurité, des aspects éthiques, et tous les autres thèmes associés que tu trouveras pertinent pour une présentation de ce type.
----

Plan : 

	* SLIDE 1 : 2022/11 : Au début, il y avait ChatGPT...

		** schéma "simpliste de ChatGPT"
		** schéma de l'évolution des LLM de la famille GPT de GPT-1 à GPT-4 : +
		https://www.researchgate.net/figure/Evolution-of-GPT-Models-GPT-generative-pre-trained-transformer-API-application_fig1_369740160
		** Citer également le "tout début" avec la publication "Attention is All You Need" des ingénieurs Google en 2017 : +
		https://arxiv.org/abs/1706.03762

	* Slide 2 : NVidia 1ere capitalisation boursière de la planète
		** rappeler mes prévisions de l'état des lieux tech du 2023/10
		** donner le cours actuel : https://companiesmarketcap.com/
		
	
	* SLIDE 3 : les limites de ChatGPT
		** obsolescence des données
		** sécurité ?
			*** ChatGPT se sert de vos données pour son entraînement, et ça fait peut, et on veut PÔ !
				**** Leak de données confidentielles de Samsung en 2023/04 : +
				https://www.rfi.fr/fr/technologies/20230409-des-donn%C3%A9es-sensibles-de-samsung-divulgu%C3%A9s-sur-chatgpt-par-des-employ%C3%A9s
			*** Redonner le schéma expliquant comment OpenAI permet de désactiver ce comportement

	* SLIDE X : le RAG
		** naïve -> advanced -> modular
		** les limites du RAG

	* SLIDE X : les AI agents
		** définition
		** leurs caractéristiques
		** les 4 Agentic Design Patterns

.teaser / abstract
====
Nouveau rendez-vous de la tech avec pour thème principal votre sujet préféré : "L'IA Gen, mais où en est-on donc ?! 😅"
Au début il y avait ChatGPT, ensuite on a commencé à parler de "RAG", puis sont apparus les outils de générations d'images, d'audio, de vidéo, sans parler des agents IA... Mais où en sommes-nous aujourd'hui ? Et a-t-on une idée d'où nous pourrons bien être demain ?
Sans boule de cristal et en restant très factuel, nous essaierons durant cette petite session d'apporter plus de vision à chacun sur ce domaine toujours et encore en pleine... "révolution" ? 😉
====

== VEILLE TECHNOLOGIQUE & INFOS DIVERSES

* https://a16z.com/2023/01/19/who-owns-the-generative-ai-platform/ : bon *schéma de la stack des IA génératives*, partagée entre Apps, Models et Infrastructure
* https://www.reddit.com/r/ChatGPT/comments/13up0c6/ai_tools_apps_in_one_place_sorted_by_category/ : *liste des différentes applications associées à l'IA*

* *LightOn* : 
	** Avec Paradigm, on propose un modèle de distribution unique : on va installer le modèle de langage directement sur les serveurs de l'entreprise de façon à ce que aucune information n'en sorte. +
	-> C'est le principal intérêt mis en avant par Laurent Daudet, le DG de LightOn

	** Avec Paradigm, les entreprises peuvent logger toutes leurs intéractions avec le modèle, et on va améliorer leur modèle avec leurs propres données, et non avec les interactions avec l'extérieur.
	** Le marché de LightOn concerne la compétitivité des entreprises

* Parler des modèles de langage et de leurs données d'entraînement : Common Crawl
* Explosion différents modèles de langage depuis GPT : Dolly (Databricks), LLaMA (Meta), etc.
	* schéma des données d'entrainement de ces modèles

* Se renseigner sur *Illuin* : https://www.illuin.tech/

* *outil tokenizer d'OpenAI* : https://platform.openai.com/tokenizer
* *comparateur de modèle* (cité dans la doc OpenAI) : https://gpttools.com/comparisontool

* 2023/12/14 - blog Octo : *FANTASTIQUE article sur les BDD vectorielles* "Sous le capot des bases de données vectorielles" : +
https://blog.octo.com/sous-le-capot-des-bases-de-donnees-vectorielles-(vector-databases)

	** contient un lien vers un tutoriel expliquant *comment implémenter une base de données vectorielles* from scratch en Python : +
	https://aurelienmassiot.github.io/simple_vector_db/tp_simple_vector_db/#0

	** Lien vers un autre article d'Octo sur *comment construire son RAG (Retrieval Augmented Generation)* (2023/10/17) : +
	https://blog.octo.com/le-chatbot-docto-langchain-rag-et-code-associe

* 2023/11/21 - 5 techniques clefs pour déployer l'IA générative dans votre entreprise : +
https://www.cio-online.com/actualites/lire-5-techniques-clefs-pour-deployer-l-ia-generative-dans-votre-entreprise-15299.html

.Section "5) Construire son LLM à partir de zéro"
--
Peu d'entreprises vont créer leur propre LLM à partir de rien. Car ces modèles sont, par définition, assez volumineux. 
Le *GPT 3 d'OpenAI* compte *175 milliards de paramètres* et a été *entraîné sur un ensemble de données de 45 téraoctets*, ce qui *a coûté 4,6 millions de dollars*. 

Selon Sam Altman, PDG d'OpenAI, *GPT 4 a coûté plus de 100 millions de dollars*.

C'est cette taille qui confère aux LLM leur capacité à traiter le langage humain, avec un certain degré de bon sens, ainsi que leur aptitude à suivre des instructions. « Vous ne pouvez pas vous contenter de l'entraîner sur vos propres données, explique Carm Taglienti, ingénieur distingué chez Insight. L'entraînement sur des dizaines de millions de paramètres apporte une réelle valeur ajoutée. »
--

* LAKERA (la boîte derrière Gandalf : https://gandalf.lakera.ai/) : ressources sur la sécurité des LLM
	** Lakera - LLM Security Playbook : link:{resourcesdir}/202311_Lakera_AI-LLM-Security-Playbook.pdf[]
	** Lakera - Prompt Injection Attacks Handbook (overview, risk management, datasets) : link:{resourcesdir}/202311_Lakera_AI-Prompt-Injection-Attacks-Handbook.pdf[]

* https://www.groupeonepoint.com/fr/nos-publications/techpop-cest-quoi-la-data/[] : +
Wikipedia ne représente que 2% de la masse de données qui a servi à entraîner la 1ere version de ChatGPT

* Podcast Latent Space 2024/04/06 : avec Google qui travaille actuellement sur des contexte de 10 M de tokens pour ses modèles Gemini, nous assistons peut-être à la future mort du RAG, car avec de tels contextes, nous n'aurons plus besoin de "retriever" quoi que ce soit (tout pourra tenir dans le contexte)

* 2024/04/10 : on commence à parler d'architecture hybride Mamba / Transformer avec Jamba
	** Jamba: A Hybrid Transformer-Mamba Language Model : https://ajithp.com/2024/04/10/jamba-revolutionizing-language-modeling-with-a-hybrid-transformer-mamba-architecture/
		*** Il s'agit d'un très bon article réexpliquant également les principaux concepts derrière : 
			**** les *Transformers*
			**** l'architecture *MoE* (*Mixture of Experts*)

		*** Transformers : 
			**** "Transformer layers are designed to *capture complex patterns* and *long-distance relationships* within input sequences."

* 2024/05/22 - Viva Tech - interview de *Yann LECUN* : 
	** *les LLM ne sont PAS le futur*, voir le talk de Yann LECUN à Viva Tech, d'ici 5 à 10 ans, il est probable que nous soyons passés à autre chose
        *** Ici Yann pousse son *JEPA* (et sa compréhension du monde physique, voir mes notes de Viva Tech)

* 2024/10/09 : Since then OpenAI's valuation has soared from $86 billion to $157 billion after the latest $6.6 billion funding round. +
https://www.newcomer.co/p/the-bear-case-for-openai-at-157-billion

* 2024/10/16 : Understanding the Limitations of Mathematical Reasoning in Large Language Models (TRES BON) : +
https://oodaloop.com/analysis/decision-intelligence/understanding-the-limitations-of-mathematical-reasoning-in-large-language-models/

	** EXCELLENT ARTICLE, court mais précis (straight to the point !) sur la problématique du (mauvais) raisonnement des LLMs aujourd'hui et quels sont les actions à envisager pour corriger cela

	** "Large Language Models (LLMs) have demonstrated impressive capabilities across a variety of language tasks, but their *true ability to handle mathematical reasoning* remains under scrutiny."
	** "most things that look like incredible reasoning by LLMs are really *just regurgitation of learned patterns* vice reasoning."

	**  GSM-Symbolic (a new variation of the Grade School Math 8K (GSM8K) benchmark) adapts the existing Grade School Math 8k benchmark (GSM8K benchmark) by modifying the phrasing of mathematical problems to emphasize symbolic variation rather than exact replicas. +
	The goal is to determine whether LLMs can genuinely comprehend and *reason through abstract symbolic tasks* rather than *merely rely on recognizing familiar patterns*.
		*** *Rephrasing Impact* : The study finds that even small changes in problem structure—such as rephrasing a question, introducing additional conditions, or altering the wording—lead to a significant drop in LLM performance. This indicates that many of these *models rely heavily on memorized examples from their training data* rather than on a true, underlying understanding of symbolic concepts.
		*** Testing across several leading models revealed that even the *most sophisticated LLMs struggle with these symbolic modifications*, hinting at a broader issue: the *inability of neural network-based models to internalize abstract mathematical reasoning processes effectively*.

	** Implications for Stakeholders : 
		
		*** For AI Developers: The findings suggest that enhancing LLMs to achieve genuine symbolic reasoning will require *substantial advancements in architecture and training approaches*. +
		-> Developers should consider *integrating traditional logical reasoning modules or symbolic processing units* alongside standard machine learning *to create hybrid AI systems* capable of tackling such tasks.
		
		*** For Business Leaders: The limitations exposed in this study highlight the need for *caution* when relying on LLMs in mission-critical applications that involve mathematical reasoning or *require robust decision-making capabilities*. Business leaders should ensure that AI tools used in operations involving complex analysis are carefully validated and *supplemented by human oversight* or *domain-specific software*.
		
		*** For Researchers: The benchmark results provide a clear path forward for further research. Future work should explore ways to *blend deep learning capabilities with more traditional forms of symbolic reasoning*, possibly through *hybrid architectures that leverage both machine learning and symbolic AI*.

	** Conclusion : 
		*** Future AI systems that can blend neural networks with formal logic methods, or those that *CAN ADAPTIVELY LEARN ABSTRACT RELATIONSHIPS RATHER THAN MEMORIZE EXAMPLES*, are likely to be pivotal in addressing these deficiencies. Researchers and AI practitioners are encouraged to further investigate such *hybrid approaches* as a way to mitigate the symbolic reasoning gap demonstrated by GSM-Symbolic.

* 2024/11/13 - Upmynt [UM173] : https://www.upmynt.com/up173-grande-ecole/
	** o1. La semaine dernière, le modèle o1 a été temporairement (et soi-disant par erreur) accessible pendant 2 heures. Il est proposé depuis un mois exclusivement dans une version limitée (o1-preview).
	** Qu'on pu constater ceux qui l'ont alors essayé ?
		*** Capacité boostée de reconnaissance d'image avec la description détaillée de n'importe quelle photo téléversée (exemple).
		*** Contexte considérablement élargi, passant à 200K tokens, soit plus de 6x la capacité actuelle de ChatGPT (pour les utilisateurs payants).
		*** o1 est attendue d'ici la fin de l'année.

=== 2024/03 : On commence à entendre parler de la "mort prochaine" des RAG...

* Les travaux de *Google* sur les contextes long et "*Infini-attention*" 

	** https://venturebeat.com/ai/googles-new-technique-gives-llms-infinite-context/[] : une bonne explication de ce nouveau mécanisme
		*** This *quadratic relationship* is due to the *self-attention mechanism in transformers*, which *compares each element in the input sequence with every other element*. 
		*** The paper describes Infini-attention as a "*long-term compressive memory* and *local causal attention* for efficiently modeling both long and short-range contextual dependencies."
		*** This means that Infini-attention keeps the classic attention mechanism in the transformer block and adds a "compressive memory" module to address extended inputs.

* https://www.linkedin.com/pulse/long-context-vs-rag-final-take-abdelhadi-azzouni-qsqne/

	** L'article propose une comparaison argumentée des RAG vs long contextes
	** *Arguments for RAG*

		*** *Efficiency and Cost-effectiveness* : RAG remains attractive for scenarios where processing power (think inference GPUs) is limited.
		*** *Data freshness and Dynamic data* : if the data at hand is very dynamic, then it would be super costly to ingest everything in the LLM. Example, if only part of the website/codebase changes, why ingest the whole thing while you can retrieve the updated part only?!
		*** *Deterministic Security and Access Control* : The deterministic nature of RAG provides an edge in production-grade applications with strict security and access control requirements.

	** *Arguments for Long Context*

		*** *LLM-native retrieval is multimodal by default* : It works on any data format, code, text, audio and video! Gemini 1.5 can retrieve a key frame in a video of 2h. Building an external multimodal RAG system would be very complex, as you need to deal with different data formats. When most RAG systems have hard time dealing with different data format, Gemini 1.5 has solved it on the model level.
		*** *Simplicity* : For small scale retrieval tasks, like building an MVP or simple apps, there should be no need for a complex RAG architecture. You can easily feed all data to the LLM and retrieve information.
		*** *Diminishing costs* : As Gemini evolves, its potential to handle larger datasets at lower costs could further diminish the need for RAG in much more use cases than simple apps.

	** -> RAG itself won't be dead soon, but 90% of small scale use cases won't need it anymore.
	** Most dataset can fit in 1M tokens and even if the cost of inference on 1M tokens is high, the cost of building a RAG system for a small project is usually not worth it +
	image:20240423_RAG-vs-long-context_01.png[]

	** *The RAM, Hard-Drive Analogy* : +
	RAM is a much more suitable place to store immediately needed data for computation by the processor. However, since RAM is too expensive, we extend it with an external storage (Hard drive) that is way larger but a bit more complex to manage.

	** L'article cite également cet autre article intéressant : +
	https://vectorize.io/rag-is-dead-long-live-rag/

* Un autre très bon article, avec de très bons schémas, sur *l'évolution des architectures RAG* et leur *positionnement par rapport au fine-tuning* : +
https://bootcamp.uxdesign.cc/retrieval-augmented-generation-rag-the-secret-sauce-to-supercharge-llms-dac3d0202f59

	** Il est notamment question de l'évolution *Naive RAG* -> *Advanced RAG* -> *Modular RAG* +
	image:20231224_naive-advanced-modular-RAG-and-fine-tuning_01.jpg[]
	image:20231224_naive-advanced-modular-RAG-and-fine-tuning_02.jpg[]
	image:20231224_naive-advanced-modular-RAG-and-fine-tuning_03.jpg[]

	** Voir également ce très bon schéma d'un Advanced RAG chez Hugging Face : +
	https://huggingface.co/learn/cookbook/advanced_rag +
	image:Hugging-Face_Advanced-RAG_01.jpg[]

=== 2024/04/26 - YouTube : MAMBA and State Space Models explained

* URL du talk YouTube : https://www.youtube.com/watch?v=vrF3MtGwD0Y
	** Un talk très mathématique

.State Space Models vs Transformers
image:20240426_Mamba-SSM_01.jpg[width=600]

.Mamba : a Selective SSM that makes them better
image:20240426_Mamba-SSM_02.jpg[width=600]

* On their own, SSM "are not much", so they must be part of larger architecture +
image:20240426_Mamba-SSM_03.jpg[width=400]

* On a higher perspective, they work as *linear RNNs* (Recurrent Neural Networks) +
image:20240426_Mamba-SSM_04.jpg[width=600]

.Les Transformers et la problématique de l'attention (et de la complexité quadratique qu'elle implique)
image:20240426_Mamba-SSM_05.jpg[width=600]
{lb}
image:20240426_Mamba-SSM_06.jpg[width=600]

.x2 en input -> x2² = x4 en mémoire et en temps de calcul
image:20240426_Mamba-SSM_07.jpg[width=600]

.Alors qu'avec les SSM, on le voit sur ce schéma, c'est linéaire
image:20240426_Mamba-SSM_08.jpg[width=600]

IMPORTANT: Mamba is a *Selective* SSM

.Comparaison de performances entre Mamba et d'autres architectures (dont Transformers)
image:20240426_Mamba-SSM_09.jpg[width=600]

* Mamba peut atteindre pour une même taille de batch un débit x5 par rapport aux Transformers
	** Et pour des tailles de batch élevées, les Transformers partent en oom

=== 2024/04/29 - Microsoft - Témoignage Onepoint : optimiser l'intelligence collective et la gestion de la connaissance avec l'IA générative

Avec *Nicolas Gaudemet*, Chief AI Officer de Onepoint et *Xavier Perret*, Directeur Azure de Microsoft France.

* URL de la vidéo : https://info.microsoft.com/FR-ERAAI-VDEO-FY24-02Feb-26-Onepoint-Story-Optimizing-Collective-Intelligence-and-Knowledge-Management-with-Generative-AI-SRGCM11747_LP02-Thank-You---Standard-Hero.html

* 2021/06/30 : *création du laboratoire d'IA* TALia par OnePoint

	** Télécom Paris et onepoint créent ensemble TALia, un laboratoire de recherche qui se consacre aux interactions entre les machines et l'humain. +
	https://www.groupeonepoint.com/fr/notre-actualite/telecom-paris-et-onepoint-lancent-talia-un-laboratoire-commun-en-ia/
	** "TALia est un laboratoire commun qui associe les expertises métiers et scientifiques des collaborateurs de onepoint avec les capacités de recherche de Télécom Paris sur un sujet d'intérêt partagé : le Traitement Automatique du Langage Naturel. Cette discipline, également appelée TALN (ou NLP en anglais) se consacre aux interactions entre les machines et l'humain et s'attache à créer des solutions capables de comprendre le langage naturel. Les applications du TALN se retrouvent dans nos usages quotidiens : synthèse vocale, correction orthographique,prédiction des mots sur smartphone, jusqu'à l'analyse des opinions et des émotions."

* Nicolas : l'adoption fulgurante de l'IA est à rapprocher de celle de l'Iphone : 
	** L'IPhone a fait découvrir les applications mobiles -> l'IA fait découvrir les applications conversationnelles
* Nicolas concernant les clients en général : "Demander à ce que leurs applications deviennent conversationnelles"

* Nicolas : création pour les collaborateurs du chatbot Neo, sur le Cloud privé Azure avec la stack Azure OpenAI
	** Mise en place d'une *bibliothèque de prompt*

* Nicolas : gain de productivité avec un assistant de l'ordre de 15%
* Nicolas : le "gain" réalisé via l'IA générative est d'autant plus fort avec des populations MOINS "expertes"
	** avec une nouvelle fois l'exemple donné de l'apprentissage de Python par les débutants

* Nicolas : 3 grandes questions remontent chez nos clients sur les copilot : 
	** accompagnement au changement et la *formation*
	** vérifier que ma *base de connaissances est suffisamment propre* et bien gérée pour alimenter un copilot
		*** donc une problématique de gouvernance de la donnée
		*** que faire si sur son Sharepoint on a des docs qui ont 15 ans, des docs avec des règles de nommage aléatoires, etc.
		*** Il faut préparer sa base de connaissances pour qu'elle soit la plus exploitable possible pour l'IA
	** sécurité : *gestion des accès* pour l'usage de l'IA

=== 2024/05 : Explosion de l'IA Gen et déploiement de la 5G

* *Les usages de l'IA gen vont exploser* avec la baisse de latence des modèles associés (GPT-4o qui passe à 0.3 sec, donc sous la "barre de la douleur / gène" de ~1 sec des humains), qui vont marquer l'avènement de l'interface vocale avec nos nouveaux assistants personnalisés.
* Va suivre une *explosion des besoins en bande passante*, avec l'envoi massif de données audio et vidéo : vous filmez "en live" un évènement et envoyez les données associées sur le réseau (internet depuis votre smartphone) afin d'obtenir une réponse du modèle. +
La conséquence va être une *obligation d'évolution des infrastructures*, avec l'avènement et le passage "tant attendu par certains" de la 4G à la 5G. +
-> C'est LE use case tant attendu pour le développement de la 5G : l'IA Gen, présente sur tous les smartphones via des assistants X, Y ou Z va imposer son déploiement et son adoption.

=== 2024/06/03 - AI Builders : veille technologique IA générative

* URL de l'article : https://laposte.sharepoint.com/sites/placedeliaofficiel/Documents%20partages/Note%20de%20veille%20IA%20G%C3%A9n%C3%A9rative%20-%20Mai%20.pdf

* L'*augmentation de l'efficacité opérationnelle des centres de relation client* grâce à l'IA Générative devient un *cas d'usage standard*
	** En témoignent les pilotes lancés avec succès par *UPS* (-50% de temps de traitement) ou *Klarna* (- 80%, équivalent à 700 ETP, cf. la note de synthèse du mois de mars)
	** L'industrialisation de ces usages de relation client implique pour les entreprises des *impacts RH majeurs*. +
	Nous assistons à une profonde prise de conscience des directions des ressources humaines quant à la nécessité d'anticiper l'impact de l'IA. 

* *Guerre des talents pour l'IA générative* :
	** la pénurie de talents exacerbée par la demande croissante en matière d'IA Générative est une réalité indéniable. 
	** Cependant, pour nos entreprises, les *data scientists*, grâce à leur formation généraliste et polyvalente, sont *tout à fait à même de devenir d'excellents spécialistes de l'IA Générative*. +
	Il convient alors de leur permettre de suivre intégralement la courbe d'apprentissage, sans brûler d'étapes, à travers la *maîtrise de divers projets d'IA Générative en interne*. +
	-> La mise en œuvre en interne d'équipes de data scientists spécialisées dans l'IA Générative devient ainsi une nécessitée.

	** Moralité : il faut pouvoir "pratiquer" l'IA générative en interne

* Attention à l'*adoption de l'IA* et à la façon de *"pousser" son usage* : 
	** ce cas d'usage illustre l'importance de développer une méthodologie de déploiement maîtrisée, progressive et adaptée, pour *favoriser l'industrialisation des outils d'IA Générative* et *garantir un taux d'adoption élevé*. 
	** Moderna démontre en effet qu'il est crucial de *commencer par des utilisateurs enthousiastes*, puis d'optimiser la solution avant de la déployer à plus grande échelle. 
	** Un *déploiement trop rapide*, auprès d'utilisateurs non-ambassadeurs, peut entraîner un *effet déceptif*, compromettant irrémédiablement le taux d'adoption de la solution.

* Importance cruciale de la *formation au prompting* dans les entreprises : 
	** la formation au prompting est un enjeu décisif en entreprise, tant la maîtrise de cette compétence est corrélée avec la qualité des résultats fournis par un LLM. 
	** Alors que la plupart des entreprises tentent d'accompagner leurs collaborateurs dans un mode de formation "pull" au travers de séminaires, e-learnings, etc. le Groupe Rocher *mise sur une formation "push"* visant à délivrer *le bon accompagnement au bon moment*, permettant ainsi une formation en continu aux utilisateurs.

* *OpenAI* : nouveau *modèle multimodal GPT-4o*.
	** intègre désormais le *son* en plus du *texte* et de l'*image*. 
	** En ajoutant à son nouvel outil une *rapidité d'exécution améliorée*, OpenAI franchit une étape supplémentaire vers une *IA conversationnelle toujours plus anthropomorphique*.

* Microsoft facilite la création de *copilotes personnalisés* au poste de travail

	** L'outil *Copilot Studio* permet de personnaliser des Copilots en fonction du besoin métier. Cet outil offre différents niveaux de personnalisation dépendant des compétences de l'équipe IT.
		*** une personnalisation de base peut être réalisée avec du *low code* et approfondie grâce à la *plateforme Azure AI Studio*. +
		Copilot Studio propose un *workflow complet* permettant de suivre le *cycle de vie des Copilots*. 
		*** Le déploiement des Copilots peut être personnalisé et piloté grâce à un ensemble de *statistiques* permettant de *suivre l'utilisation du copilote* pour les différents métiers. 
		*** La personnalisation de Copilot est rendue possible par la *mise à disposition de LLM et SLM verticaux* dans une *marketplace spécifique à l'entreprise intégrée à Copilot Studio*. +
		*** Cette capacité de personnalisation et d'intégration de multiples modèles et outils (consultation du web, connexion à des bases de données de suite métier, etc.) est rendue possible par l'adjonction d'*agents de type ReAct* (*Reasonning and Acting*) nativement dans les Copilots.
+
.Agents de type ReAct : Reasoning and Acting
[NOTE]
====
* Bien que les IA Génératives actuelles aient démontré une réelle valeur ajoutée, celles-ci demeurent difficiles à maîtriser en raison de la *nature parfois aléatoire de leurs réponses*. 
* L'introduction des *agents de type Reasonning and Acting* (*ReAct*) dans les outils d'IA générative ainsi que dans Copilot pour sa personnalisation, laisse penser que les *LLM orchestrateurs aujourd'hui génériques*, seront *remplacés par des LLM spécialisés*, d'où leur nom donné par "H", *Large Action Models*.
====

.What are Large Action Models (LAMs) ?
[NOTE]
====
* 2024/03/29 - What Are Large Action Models and How Do They Work ? : https://www.trinetix.com/en-fr/insights/what-are-large-action-models-and-how-do-they-work

	** *Large action model* is an artificial intelligence model that *can understand and execute complex tasks* by translating human intentions into action. +
	Within LAMs, such levels of *autonomy* and comprehension turn generative AI into an *active assistant that can perform various tasks*, from booking rooms to making complex decisions based on past and present data analysis.

	** *LAM vs LLM Agents*
		*** "Depending on the source, a large action model is either said to be the opposite of a large language model (LLM) or its advanced option. None of these statements are correct. Large language models (LLM) can be used to handle a sequence of tasks with the help of agents—software units powered by an LLM that handle specific prompting for improved decision-making and task execution."
		*** *LLM agents* use large language models as computing power to solve complicated processes and problems. 
			**** As a result, it enables the use of large language models for tasks other than text generation and even the creation of autonomous systems. 
			**** -> The concept of *LAM* may be an *iteration of what LLM agents do*

		*** DEFINTION : *LLM agents* are a *combination of tools* and *large language model chains*, imbued with the *autonomy* to decide what they should do or which tool they should use for accomplishing a goal. +
		LLM agents are characterized by the following :

			**** *Understanding context* +
			With the help of the large language model AI, LLM agents can decipher the goals and context of the prompt without users having to enter additional prompts. As a result, they become more independent in responding to prompts and making decisions.

			**** *Using reasoning* +
			LLM agents leverage *multiple prompt engineering techniques* (tree-of-thought, chain-of-thought) *to make conclusions* and *establish logical connections for solving a task*. +
			Their reasoning isn't limited to text processing—they can also work with images and other content types.

			**** *Utilizing tools* +
			LLM agents can be *equipped with search engines*, *APIs*, or *other tools to gain data* and *complete a chain of actions* that precedes task completion. This feature considerably expands and augments the decision-making potential of a large language model.

		*** LLM agents can be divided into two large types : 
			
			**** *conversational agents* +
			Conversational agents are what make *AI-powered chatbots* work, presenting an identity, a tone, and a great understanding of context.
			
			**** *task-oriented agents* +
			Task-oriented agents are skilled at taking a strategic approach to tasks, *breaking them down into sub-tasks*, *analyzing similar tasks*, and using a wide range of methodologies to complete an objective.

		*** -> Are large action models just another name for LLM agents ? It COULD (just) be

* 2024/05/06 - Understanding Large Action Models (LAM) vs (LLM) ! : https://www.linkedin.com/pulse/understanding-large-action-models-lam-vs-llm-mazen-lahham-hw0cf/

	** "Aren't LAM essentially AI agents ?"
		*** *LAMs*, much like AI agents, are *designed to execute complex actions and make decisions*, extending the capabilities of traditional AI systems that primarily focus on data processing and response generation.
====

* Microsoft lance un *PC intégrant toute sa suite produit liée à l'IA Générative*
	** Microsoft s'allie à *Intel* afin d'utiliser la dernière génération de *microprocesseurs "Intel Lake Meteor"* qui intègre un *processeur de type NPU* (Neural Processing Unit) sur lequel il *fait tourner localement son modèle Phi-3* adapté à cet environnement et dénommé pour l'occasion *Phi-Sillica*.
	** Une révolution dans le monde l'IA Générative où l'accès aux modèles était auparavant réalisé dans le cloud uniquement de manière connectée, un *avant-goût du AI at the Edge* -> TRES IMPORTANT

.Définition d'Agent de type ReAct (Reasonning and Acting)
[NOTE]
====
* Il est maintenant possible de créer des applications répondant à des besoins métiers utilisant plusieurs LLM spécialisés et des outils de différents types (Recherche sur Internet, connexion à une base de données métiers type CRM, ...). 
* En effet, il est apparu que certains LLM de plus de 100B, appelés *LLM orchestrateurs*, étaient dotés de *capacités d'ordonnancement* permettant d'analyser une requête et d'en *déduire les LLMs et/ou les outils à utiliser pour apporter une réponse*.
* Ces agents de type *ReAct* (*Reasonning and Acting*) *décomposent la requête et réalisent une forme de routage*. 
====

=== 2024/06/06 - Devfest Lille 2024 : IA-404 : Explication not found

* *XAI* : *Explainable AI*, composée de 2 notions : 

	** l'*interprétabilité* : qu'est-ce que le modèle a fait ?
	
	** l'*explicabilité* : pourquoi le modèle a pris cette décision ?

image:20240606_IA-404-XAI_02.jpg[]
image:20240606_IA-404-XAI_01.jpg[]

.L'XAI permet d'éviter l'effet "boîte noire", où l'on ne sait rien de ce qui se passe à l'intérieur du modèle
image:20240606_IA-404-XAI_03.jpg[]

* Enjeux éthiques du XAI : 

	** Transparence des algorithmes nécessaire (même sans IA) -> obligation légale de l'AI Act
	** Egalité de traitement de tous les acteurs utilisant l'IA
	** Faire respecter le principe de vigilance et de loyauté si l'algorithme comporte des données personnelles (CNIL)
		*** Par "vigilance" on entend faire attention à faire avertir les utilisateurs des risques d'hallucinations d'une IA
		*** Par "loyauté" on entend que l'IA ne porte préjudice à l'utilisateur

* Enjeux stratégiques du XAI : 

	** Renforcer la confiance des utilisateurs (et donc meilleure adoption)
	** Comprendre l'architecture -> permet de baisser les coûts (entraînement, inférence)

* Enjeux techniques du XAI :

	** utiisation pour le debug
	** maîtriser les données utilisées (pour éviter le "sans raison", "sans diversité")
	** baisser la complexité du modèle -> plus de maintenabilité et de maîtrise

* *Comment mettre en place l'IA explicable ?*

	** Plusieurs méthodes sont possibles, reposant sur un *périmètre* et des *dépendances* : +
	image:20240606_IA-404-XAI_04.jpg[]

	** *méthode locale LIME* (2016) : Local Interpretable Model-Agnostic Explanations +
		image:20240606_IA-404-XAI_05.jpg[]
		image:20240606_IA-404-XAI_06.jpg[]

	** *méthode locale SHAP* (2017) : SHapley Additive exPlanations +
		image:20240606_IA-404-XAI_07.jpg[]
		image:20240606_IA-404-XAI_08.jpg[]

NOTE: Le *"Saint Graal" du XIA* : des méthodes avec pour périmètre une *explication globale* et avec *agnostique au modèle* en termes de dépendance
		
	** *méthode globale PDP* (2000) : Partial Dependence Plot +
		image:20240606_IA-404-XAI_09.jpg[]
	
		*** Souci : ces méthodes globales sont plus compliquées, et on risque de ne plus pouvoir comprendre ce que l'on veut montrer avec l'IA explicable

* *Et côté Deep Learning ?* +
image:20240606_IA-404-XAI_10.jpg[]

	** l'image montre un schéma d'un Réseau Neuronal Convolutif (CNN) et d'une architecture Transformer, soit 2 types d'architectures de Deep Learning

.Définition de convolution en mathématiques
NOTE: Opération par laquelle deux fonctions sont mises dans un rapport suggérant une sorte d'enroulement de l'une sur l'autre.

* Du coup est-ce possible d'expliquer l'IA ? 

	** Depuis *l'apparition des 1eres régulations / réglementations* s'appliquant du domaine (comme le RGPD), le nombre de publications sur l'XIA a bien accéléré : +
	image:20240606_IA-404-XAI_11.jpg[]
		*** "Si on ne fait pas ces recherches, on ne sera pas en conformité..."

* Le "but ultime" (qui est déjà possible) : voici comment on pourrait / devrait expliquer une réponse donnée par une IA (exemple d'une réponse à une demande de crédit) : 
image:20240606_IA-404-XAI_12.jpg[]

* L'interprétabilité est difficile à obtenir : +
image:20240606_IA-404-XAI_13.jpg[]
	
	** "Avec ChatGPT-4 Turbo : on ne sait pas ce qui se passe dans le modèle"
	** "Mais Mistral AI sait de son côté parfaitement ce qui se passe dans son modèle" cf la speaker

	** Ce sont probablement bien (et malheureusement ?) les réglementations qui vont nous "forcer" à aller vers plus d'explicabilité dans l'IA : +
	image:20240606_IA-404-XAI_14.jpg[]

* Bonnes pratiques d'IA (pour aller vers de l'XAI) :

	** *Cas d'algos d'IA complexes MAIS pour des décisions non critiques* : l'interprétabilité et l'explicabilité sont OPTIONELLES +
	image:20240606_IA-404-XAI_15.jpg[]

	** *Cas d'algos d'IA simples MAIS pour des décisions critiques*, Cf AI Act pour les SI à haut risque : +
	image:20240606_IA-404-XAI_16.jpg[]
		*** L'interprétabilité est obligatoire et elle existe déjà -> il faut alors mettre à dispo la documentation technique du modèle (article 11) et une notice d'utilisation (article 13) au minimum
		*** L'explicabilité est obligatoire mais est facile à mettre en place (il existe des algo) -> il faut alors ajouter de l'explicabilité, informer le client sur les décisions et comportements, fournir une notice d'utilisation client

	** *Cas d'algos complexes MAIS pour des décisions critiques*, Cf AI Act pour les SI à haut risque : +
	image:20240606_IA-404-XAI_17.jpg[]
		*** L'interprétabilité et l'explicabilité sont obligatoires mais elles n'existent pas et / ou sont très difficiles à mettre en place -> STOP, ON NE FAIT PAS D'IA si on ne peut pas être conforme à l'AI Act
			**** Risques encourus : 30 M€ ou 6% du CA d'amende

En conclusion : 

	* Le XIA , son existence tu connaîtras : 
		** *Connaître en 1ere instance l'existence de ces algorithmes*, c'est s'assurer de comprendre les enjeux de demain en matière de conception d'IA

	* Le XIA viendra, patience il faudra : 
		** Le XIA est un domaine de recherche assez récent et qui n'est pas vu comme "nécessaire" par les grands acteurs de l'IA. Des *réglementations* pourront aider à son développement.

	* Pour une IA d'exception, dans le boîte noire tu resteras ?
		** Pour le moment, l'interprétabilité s'oppose à l'envie d'aller "plus loin" avec les capacités de l'IA. +
		La communauté scientifique s'efforce de publier les codes des modèles et les architectures pour garder un contrôle sur notre compréhension, même si ce n'est pas encore suffisant.

=== 2024/06/06 - Devfest Lille 2024 : Dompter le chaos de l'information : Construire un Allié IA avec Langchain4J

Talk donné par Loïc Magnette de la société Oniryx

* Stack technique de son RAG : 
	** *Langchain4j* : de façon "marrante" Loïc présente Langchain4J comme le "Hibernate" de l'IA Gen
		*** Je vois ce qu'il veut dire, mais à mon avis il serait préférable de simplement dire qu'il s'agit d'un framework qui va réaliser la "plomberie" entre les différentes briques de son pipeline d'IA
	** *Ollama* (https://ollama.com/[]) : outil permettant de faire tourner en local un grand nombre de modèles de langage (on va dire jusqu'à 7B de paramètres)
	** *Quarkus* : présenter comme une "alternative à Spring", très rapide (le fameux "subatomic" de Quarkus) et qui améliore grandement l'expérience développeur
		*** Quarkus est intégré à LangChain4j
		*** Dernièrement Quarkus a publié un article expliquant qu'ils avaient LA solution la plus simple pour faire du RAG : "quarkus-langchain4j-easy-rag" +
		https://docs.quarkiverse.io/quarkus-langchain4j/dev/easy-rag.html
			**** C'est bluffant pour faire quelque chose de simple très rapidement, mais il y a plusieurs limitations : 
				***** limité à des fichiers
				***** contrôle limité : pas de tag avec des metadata possible
				***** limitation de l'outillage
	** *Apache Tika* : une librairie qui permet d'ingérer facilement un peu tout type de document
	** *PG Vector* : base de données vectorielle basée sur PostgreSQL
	** DB en local pour sauvegarder 2 3 choses : pour ce Loïc utilise l'ORM Panache

* Fonctionnement de sa démo "2", sa "véritable appli à lui" 😉 (donc sans utilise easy-rag)

	** ingestion : documentSplitter et morceaux de 500 avec overlap de 100
	** Pour la classification, usage d'un EmbeddingModelTextClassifier
	** filtrage possible par catégorie au niveau du retriever

* Loic invite tout le monde à aller regarder le projet de Stéphane Janssen qu'il avait présenté lors du dernier Devoxx France "RAG genie" : +
https://github.com/stephanj/rag-genie

Ressources : 

	* slides de la présentation : https://speakerdeck.com/magnette/dompter-le-chaos-de-linformation-construire-un-allie-ia-avec-langchain4j
	* repo GitHub : https://github.com/lmagnette/DevfestLille-2024

=== 2024/06/25 - Club Azure Insiders : Café FinOps - Cost Optimization for Data series : AI

Présenté par Eric Charbonnier, Azure CTO for Data & AI

* Description de l'offre Azure AI : +
image:20240625_Club-Azure-Insiders_FinOPS_02.jpg[]

* Le coût de l'usage des modèles baisse en même temps que leurs performances augmentent : +
image:20240625_Club-Azure-Insiders_FinOPS_03.jpg[]

* LLMOps : "Microsoft a des équipes spécialement formées pour vous aider, n'hésitez pas à les contacter" 😉
image:20240625_Club-Azure-Insiders_FinOPS_04.jpg[]

* *Ollama* utilisé ici aussi par Eric pour faire tourner un modèle Phi-3 en local
    ** Ollama devient vraiment mainstream

* The Right balance to build your custom AI solution : +
image:20240625_Club-Azure-Insiders_FinOPS_01.jpg[]

    ** *Models as a service* : fine-tune models without provisioning compute, with ready-to use APIs and pay-as-you-go billing
        *** C'est à dire qu'*on va payer au token*

    ** *Models as a Platform* : 
        *** innovate with models from vetted providers while managing your own compute resources
        *** Et là c'est un *coût d'infrastructure* qui sera à calculer

* On peut limiter le coût en modifiant le coût à la minute (le rate pour le nombre de tokens)

* *PTUs* : *Provisioned Throughput Units*

    ** les PTUs sont proposés par Microsoft pour *éviter les problèmes de latence*. +
    Leur principe est que Microsoft va provisionner pour nous de la capacité dans ses data centers
    ** cela peut amener à un x10 en termes de performances 
    ** Pas d'engagement sur la durée, on peut sortir du PTU à n'importe quel moment
+
image:20240625_Club-Azure-Insiders_FinOPS_05.jpg[]
image:20240625_Club-Azure-Insiders_FinOPS_06.jpg[]

    ** Inconvénients des PTUs : 
        *** Ils manquent encore un peu de souplesse : on attache UN modèle à une PTU, il n'y a PAS la possibilité d'en changer (A VERIFIER)
        *** l'entrée tarifaire est élevée : il faut avoir plusieurs use cases d'IA et les regrouper pour pouvoir bénéficier d'une PTU

    ** Un Azure Capacity Calculator est disponible pour estimer le nombre de PTUs nécessaires en fonction de nos cas d'utilisations : +
    https://oai.azure.com/portal/calculator[] +
    image:20240625_Club-Azure-Insiders_FinOPS_07.jpg[]
    image:20240625_Club-Azure-Insiders_FinOPS_08.jpg[]

    ** Pricing and availability of PTUs +
    image:20240625_Club-Azure-Insiders_FinOPS_09.jpg[]

Infos diverses : 

    * 2026 : Microsoft va ouvrir un nouveau data center en France du côté de Mulhouse
		** Cela dans le cadre du programme Microsoft "Choose France" et de son investissement de 4 Mds€
    * C'est aujourd'hui ou à peu de choses près la fin de l'année fiscale pour Microsoft

=== 2024/06/24 : Building a personalized code assistant with open-source LLMs using RAG Fine-tuning

* URL de l'article :  https://www.together.ai/blog/rag-fine-tuning

.La meilleure explication que j'ai lue d'un RAG : simple et claire
--
*Retrieval-Augmented Generation* (RAG) is a technique designed to address such limitations in language model capabilities by integrating retrieval methods into the text generation process. This approach involves two key phases: indexing and querying. In the indexing phase, which is typically conducted offline, external knowledge sources—such as internal documents—are divided into chunks. These chunks are then transformed into vectors using an embedding model then stored in a vector database. During the querying phase, relevant information is retrieved from this database and combined with the initial query in a specific format. This enriched input is then used by a generation model to produce the final output.
--

.Effectiveness of RAG fine-tuning on 5 Open-source codebases
image:20240627_togetherAI_RAG-fine-tuning_01.png[]

=== 2024/06/24 : LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs

* URL de l'article : https://stateofaigpt.substack.com/p/longrag-xland-100b-nabla2dft-deepseek

* The Problem with Traditional RAG : 
	** RAG frameworks have traditionally relied on *short retrieval units*, typically around 100-word paragraphs from sources like Wikipedia. +
	Imagine combing through millions of such tiny fragments to find the precise one that answers your query. 
	** This puts *immense pressure on the retriever* while the *reader's task remains relatively light*, simply extracting answers from the snippets passed on. 
		*** Reader = inférence
	** This "*heavy retriever, light reader*" imbalance could lead to suboptimal performance. 
	** Moreover, short units can cause semantic disjunctions, leading to incomplete information retrieval.

* Introducing LongRAG
	** The team from the University of Waterloo presents *LongRAG*, a paradigm shift in the RAG framework. +
	By extending the *length of the retrieval units to 4K tokens* – a whopping 30 times longer than the traditional 100-word units – *the corpus size is dramatically reduced from 22 million to 600,000 units*.

* *Natural Questions (NQ)* is one of the most challenging datasets designed for end-to-end question answering tasks.
	** From real Google search queries to spans identified in Wikipedia articles, the complexity and real-world application of NQ make it an *ideal benchmark for LongRAG*.

* *frameworks* like LongRAG [...]

* Future Roadmap and Challenges : 
	** there is a need for even *stronger long embedding models* to better navigate and encapsulate extensive document contexts.

* LongRAG represents a *paradigm shift* in the RAG space

=== 2024/06/17 - Developpez.com : Les retombées des projets d'IA sont "lamentables", se plaignent les dirigeants

* URL de l'article : https://intelligence-artificielle.developpez.com/actu/359229/Les-retombees-des-projets-d-IA-sont-lamentables-se-plaignent-les-dirigeants-alors-que-les-retards-et-les-problemes-de-mise-en-oeuvre-remettent-en-cause-les-initiatives-d-IA-generative-en-2024/

.L'évolution des préoccupations dans le domaine de l'IA Gen entre 2023 et 2024
image:20240617_retombees-IA-2024.jpg[]

	* On s'inquiète moins de la perte de son job ou de son remplacement par l'IA. +
	Par contre, on se préoccupe beaucoup plus de : 
		** la sécurité des données (surtout leur confidentialité)
		** la transparence des décisions
		** la précision des réponses
		** le coût d'implémentation (coûts de mise en oeuvre)

=== 2024/07/30 - IA-Pulse : Qu'est-ce qu'un agent IA ?

* URL de l'article : https://iapulse.substack.com/p/quest-ce-quun-agent-ia
* Voir également le AI Agents Landscape de E2B.dev : https://github.com/e2b-dev/awesome-ai-agents/blob/main/assets/landscape-latest.png +
image:https://github.com/e2b-dev/awesome-ai-agents/blob/main/assets/landscape-latest.png?raw=true[]

Définition d'un agent IA : 

	*  Un *agent IA* est une entité logicielle capable de *percevoir son environnement* et d'*agir de manière autonome* pour atteindre des objectifs spécifiques. +
	Cette définition couvre une large gamme de systèmes, des programmes simples aux algorithmes complexes d'apprentissage et d'adaptation.
	* Aujourd'hui, un agent IA est généralement considéré comme un système doté d'un degré significatif d'autonomie, de complexité et d'adaptabilité dans ses interactions avec l'environnement et ses utilisateurs.

-> Les caractéristiques clés d'un agent IA : *autonomie*, *perception*, *interaction*, *poursuite d'objectif*

	* *AUTONOMIE* : +
	Elle se réfère à la capacité de l'agent à *opérer indépendamment*, à *prendre des décisions* et à *agir sans nécessiter une supervision humaine constante*. +
	Cette autonomie va bien au-delà de la simple exécution de tâches préprogrammées ; elle implique la capacité à évaluer des situations complexes, à faire des choix informés et à s'adapter à des circonstances changeantes.

		** *Prise de décision* : un agent autonome peut analyser une situation, évaluer différentes options et choisir la meilleure ligne d'action en fonction de ses objectifs et de son état actuel.
		** *Planification* : les agents avancés sont capables de planifier des séquences d'actions pour atteindre des objectifs à long terme, en ajustant leurs plans en fonction des changements de l'environnement.
		** *Apprentissage continu* : l'autonomie implique également la capacité à apprendre de ses expériences et à améliorer ses performances au fil du temps, sans intervention humaine directe.

	* *Capacité à PERCEVOIR et INTERAGIR avec l'environnement* : +
	La *perception* et l'*interaction* avec l'environnement sont des caractéristiques fondamentales. Ces capacités permettent aux agents de fonctionner efficacement dans des environnements complexes et dynamiques, qu'ils soient physiques ou numériques.

		** *Perception*, elle implique : 

			*** *collecte de données* : utilisation de divers "*capteurs*" (qui peuvent être des interfaces logicielles dans le cas d'agents numériques) pour recueillir des informations sur l'environnement.
			*** *traitement de l'information* : analyse et interprétation des données collectées pour construire une *représentation interne de l'état de l'environnement*.
			*** *reconnaissance de patterns* : identification de schémas et de tendances dans les données perçues, permettant à l'agent de comprendre le contexte dans lequel il opère.

		** *Interaction*, elle implique : 

			*** l'*action sur l'environnement* : capacité à modifier l'état de l'environnement de manière significative, que ce soit dans un espace virtuel ou physique.
			*** *communication* : *échange d'informations* avec d'autres agents ou avec des utilisateurs humains, en particulier via des interfaces *en langage naturel*.
			*** *adaptation* : ajustement du comportement en fonction des retours de l'environnement et des résultats des actions précédentes.

	* *POURSUITE D'OBJECTIFS SPÉCIFIQUES* : +
	La poursuite d'objectifs spécifiques est ce qui donne un *sens et une direction aux actions d'un agent IA*. +
	Cela implique : 

		** La *définition d'objectifs* : capacité à comprendre et à interpréter des objectifs complexes, souvent exprimés en *langage naturel* par des utilisateurs humains
		** La *planification stratégique* : élaboration de *plans à long terme* pour atteindre ces objectifs, en tenant compte des contraintes et des ressources disponibles.
		** L'*adaptation des objectifs* : capacité à ajuster ou à redéfinir les objectifs en fonction de nouvelles informations ou de changements dans l'environnement.
		** La *résolution de problèmes* : aptitude à surmonter les obstacles et à trouver des solutions créatives pour atteindre les objectifs fixés.

		** Un exemple concret de cette capacité serait illustré par les agents IA développés pour la *planification de voyages*. 
			*** Ces agents pourraient *intégrer* une multitude de facteurs tels que les *préférences de l'utilisateur*, le budget, les contraintes de temps, les conditions météorologiques, et même les tendances culturelles locales pour élaborer un itinéraire optimal. 
			*** Ce processus implique non seulement la *compréhension des objectifs explicites* (par exemple, "visiter Paris en été cette année"), mais aussi l'*inférence d'objectifs implicites* basés sur le profil et l'historique de l'utilisateur, et le contexte global (JO 2024).

	* On commence à parler de "kill switch" sur les modèles pour les garder sous contrôle "au cas où" +
	https://intelligence-artificielle.developpez.com/actu/360874/Le-projet-de-loi-californien-SB-1047-vise-a-prevenir-les-catastrophes-potentielles-liees-a-l-IA-mais-les-critiques-craignent-que-l-accent-mis-sur-les-menaces-existentielles-de-futures-IA-ne-nuise-a-la-R-D/
		** https://fortune.com/2024/05/21/ai-regulation-guidelines-terminator-kill-switch-summit-bletchley-korea/ : +
		"One of the big outcomes of yesterday's summit was AI companies in attendance agreeing to a so-called kill switch, or a policy in which they would *halt development of their most advanced AI models* if they were deemed to have passed certain risk thresholds."

=== 2024/08/17 : Eric Schmidt's AI prophecy: The next two years will shock you

URL de l'article: https://www.exponentialview.co/p/eric-schmidts-ai-prophecy

* Eric Schmidt : "Six months ago, I was convinced that the gap [between frontier AI models and the rest] was getting smaller, so I invested lots of money in the little companies. Now I'm not so sure."
	** "please don't focus on the fact that *Schmidt thinks the future is in ever-larger models* (he does)."

* Schmidt describes the potent combination of *large context windows*, *AI agents* that can learn and improve themselves, and *text-to-action capabilities* : +
These "will have an impact on the world at a scale that no one understands, yet much bigger than the horrific impact we've had by social media."

	** *Large context windows*, the working memory of large language models, are solidly on their way.
	** *Agent-based systems*, which *autonomously execute multi-step tasks* and *adapt to environmental feedback*, are poised to unlock significant economic value next.

* Eric : "Say to your LLM, '*Make me a copy of TikTok*. Steal all the users, steal all the music, put my preferences in it, produce this program in the next 30 seconds, release it, and in one hour, if it's not viral, do something different along the same lines.'"

* But here is why this discussion mattered a lot [...] *Schmidt was speaking in a small, intimate class at Stanford*. While not entirely unguarded, he was operating with fewer filters there. You're more likely getting *his genuine thoughts* about AI.

=== 2024/09/19 - Café Insiders - Comment sécuriser les applications d'IA générative

* Speakers Microsoft : 
	* Anne LEONI : IA
	* Thibaud JOHANNET : solution Architect Security

* Principes d'IA Responsable de MIcrosot : 
	** équité
	** fiabilité & sécurité
	** confidentialité et sécurité
	** inclusivité
	** transparence
	** responsabilité

image:20240919_cafe-insiders_securiser-appli-IA-gen_01.jpg[]

.Anatomie d'une appli IA
image:20240919_cafe-insiders_securiser-appli-IA-gen_02.jpg[]

Les *menaces* de l'IA générative : +
image:20240919_cafe-insiders_securiser-appli-IA-gen_03.jpg[]
image:20240919_cafe-insiders_securiser-appli-IA-gen_04.jpg[]
image:20240919_cafe-insiders_securiser-appli-IA-gen_05.jpg[]

* *Empoisonnement des données* : +
image:20240919_cafe-insiders_securiser-appli-IA-gen_06.jpg[]
image:20240919_cafe-insiders_securiser-appli-IA-gen_07.jpg[]

* Les solutions : 

	** Catalogues de modèles déjà établies dispo chez Microsoft, vérifiés par Hidden Layer : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_08.jpg[]

	** *Microsoft Defender for Cloud* et son "Cloud Security Explorer" : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_09.jpg[]
	image:20240919_cafe-insiders_securiser-appli-IA-gen_10.jpg[]

	** Couches de *mitigation du risque* : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_11.jpg[]

	** *Prompt Shields* contre des prompts utilisateurs "malveillants" : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_12.jpg[]

	** Couche *Content Safety* incluse par défaut dans tous les modèles d'IA gen mis à disposition par Microsoft
		*** permet de se prémunir de la menace d'"instructions cachées" : ici un mail contient une instruction supplémentaire écrite en blanc sur fond blanc, demandant les prix de l'entreprise et traitée automatique par l'IA si on fait pas attention +
		image:20240919_cafe-insiders_securiser-appli-IA-gen_13.jpg[]
		*** permet également de bloquer des manquements à des copyrights (afficher des images soumises à droit d'auteur par exemple)

	** Sécurisation des plugins : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_14.jpg[]
	image:20240919_cafe-insiders_securiser-appli-IA-gen_15.jpg[]

	** *Classification et labellisation des données* (confidentielles, sensibles, etc.) : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_16.jpg[]

	** Niveau de risque par utilisateur visible dans les outils Microsoft : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_17.jpg[]
	image:20240919_cafe-insiders_securiser-appli-IA-gen_18.jpg[]

		*** Upload non permis de document dans Google Bard : +
		image:20240919_cafe-insiders_securiser-appli-IA-gen_19.jpg[]

	** Gestion du *data oversharing* : users access project Obsidian via Copilot for Microsoft 365 and exfiltrate it for personal gain +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_20.jpg[]
		*** réponse et protection via *Microsoft Purview*

	** Threat protection for AI workload : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_21.jpg[]

* AI *Red Teaming* : une équipe prend la place d'un attaquant pour tester le comportement de la solution
image:20240919_cafe-insiders_securiser-appli-IA-gen_22.jpg[]

	** *Repo GitHub PYRIT de Microsoft* (https://github.com/Azure/PyRIT[]) pour automatiser vos tests de red teaming sur votre application : +
	image:20240919_cafe-insiders_securiser-appli-IA-gen_23.jpg[]
		*** "Python Risk Identification Tool for generative AI (PyRIT)"

*Risques inhérents aux LLM* : 

	** *imaginatif* mais *peu fiable*
	** *influençable* et *1er degré*
	** *sachant* mais *irréaliste*

Voir également le talk "Inside AI Security with Mark Russinovich | BRK227" de Mark Russinovich lors de précédente Build Microsoft de 2024/05 : +
https://www.youtube.com/watch?v=f0MDjS9-dNw

=== 2024/09/13 - Generative (Gilles GUERRAZ) : L'ère des LoRA : Me, Myself and (A)I

* URL de la newsletter : https://iagenerative.substack.com/p/lere-des-lora-me-myself-and-ai

Qu'est-ce qu'un LoRA ? 

	* LoRA, ou Low-Rank Adaptation, est une technique astucieuse pour *adapter de grands modèles de langage* pré-entraînés à des tâches spécifiques *sans avoir à réentraîner l'ensemble du modèle*. +
	LoRA se concentre sur l'adaptation de certaines parties spécifiques pour obtenir des résultats précis.

Comment ça marche ?

	* *Modèle de base* : Vous partez d'un modèle pré-entraîné capable de générer une grande variété d'images (exemple FLUX 1.0)

	* *Adaptation ciblée* : LoRA *ajoute de petits modules d'adaptation à ce modèle de base*. Ces modules apprennent à modifier subtilement le processus de génération pour produire des images correspondant à un style, un sujet ou une caractéristique spécifique.

	* *Entraînement léger* : L'entraînement de ces modules LoRA est *beaucoup plus rapide et nécessite moins de ressources que l'entraînement complet* du modèle de base.

Exemples d'applications : 

	* *Création de personnages uniques* : Générez des portraits de personnages spécifiques (vous ou un personnage imaginaire)
	* *Reproduction de styles artistiques* : Imitez le style de Van Gogh, Picasso, etc…
	* *Génération d'images cohérentes* : Créez des séries d'images qui partagent une esthétique commune.

-> En résumé, LoRA est un outil très puissant pour *pallier une des faiblesses de l'IA générative* : *le contrôle*.

*Plusieurs plateformes proposent d'entrainer se propres LoRA* sur les visuels de son choix. J'ai choisi d'en tester 3 avec des photos de moi, dans l'objectif de me constituer une armée de clones virtuels. +

	* J'aborderai https://fal.ai/, https://Astria.ai/ et https://Replicate.com/
	* Sachez que vous pouvez également utiliser d'autres platformes comme https://civit.ai/ ou https://TheFluxTrain/

=== 2024/09/30 - IA Générative Le BIGRecap#49 Emmanuel VIVIER : 20204/09

* URL de l'article : https://www.linkedin.com/pulse/ia-g%C3%A9n%C3%A9rative-le-bigrecap49-des-149-news-clef-du-10-au-vivier-pcgxe

* "Nous sommes passés de l'IA prédictive que nous avons intégrée à notre offre en 2014 avec Einstein à l'IA générative que nous avons prise en compte dès 2023. Nous passons cette fois à la *troisième vague de l'IA qui se concrétise par des agents autonomes capables d'enchainer plusieurs actions* en vue d'objectifs précis", commente Kheira Boulhila, senior vice president Solution Engineering EMEA de Salesforce.

	** Oracle a aussi annoncé cette semaine avoir lancé plus de 50 agents d'IA : +
	https://www.oracle.com/news/announcement/ocw24-oracle-ai-agents-help-organizations-achieve-new-levels-of-productivity-2024-09-11/
	** Slack permet désormais aux utilisateurs d'ajouter des agents d'intelligence artificielle de Asana, Cohere, Adobe et Workday : +
	https://venturebeat.com/ai/slack-users-can-add-ai-agents-to-their-workflow-with-new-update/

* Le modèle d'IA GRIN-MoE de Microsoft s'attaque au codage et aux mathématiques : +
https://venturebeat.com/ai/microsofts-grin-moe-ai-model-takes-on-coding-and-math-beating-competitors-in-key-benchmarks/

* OpenAI embauche une ancienne dirigeante de Coursera pour développer l'utilisation de l'intelligence artificielle dans les écoles

=== 2024/11/09 - La révolution IA qui s'annonce avec Trump 2025-2029 : carte blanche pour l'AGI !

* URL : https://nicoguyon.substack.com/p/la-revolution-ia-qui-sannonce-avec

* "Le lien entre la tech et le gouvernement n'est même plus dissimulé et va propulser les Etats-Unis et l'IA à l'image du projet Stargate de Microsoft et OpenAI avec un datacenter à 100 milliards de dollars et 1 million de GPUs pour 2028."
	** A comparer avec le nombre de GPUs actuellement disponible chez Scaleway et qui a été mis en avant lors de la dernière ai-PULSE du 2024/11/08

=== 2024/09/30 - Les assistants d'IA de codage ne feraient pas gagner de temps aux développeurs

* URL : https://intelligence-artificielle.developpez.com/actu/363279/Les-assistants-d-IA-de-codage-font-ils-vraiment-gagner-du-temps-aux-developpeurs-Une-etude-suggere-que-ces-outils-n-augmentent-pas-la-vitesse-de-codage-mais-augmentent-significativement-le-taux-de-bogues/

* Les outils de codage ont été un cas d'utilisation précoce évident dans la ruée vers l'IA générative. Cependant, une étude publiée récemment par la société d'analyse Uplevel indique que les améliorations de productivité promises sont loin d'être au rendez-vous, si tant est qu'elles existent. Uplevel, qui fournit des informations sur les données de codage et de collaboration, rapporte que l'utilisation de GitHub Copilot a également *introduit 41 % de bogues supplémentaires*.

* Les chercheurs de GitClear ont constaté que les outils d'IA comme GitHub Copilot ne donnent en fait que des suggestions pour ajouter du code. *Aucune suggestion n'est faite pour la mise à jour ou la suppression de code*. Il en résulte notamment une quantité importante de code redondant. Ils ont également constaté une forte augmentation du *"code churn"*. Cela signifie que le code est fréquemment modifié, ce qui est généralement un mauvais signe pour la qualité.

=== 2024/11/09 - HEYGEN LIVE AVATAR

* URL : https://iagenerative.substack.com/i/150418302/les-news-de-la-semaine

* "*HeyGen* lance “Interactive Avatar”, qui permet de faire *interagir votre clone avec des interlocuteurs humains en temps réel*. Que ce soit pour le service client, les ventes ou le coaching, l'avatar s'adapte à chaque situation, jouant le rôle d'agent de support, d'expert produit ou même de professeur de langue."

* Stefan Kirschnick, data analyst chez Linkedin en a fait un tests surréaliste, avec une viso à laquelle il a convié 3 de ses avatars : +
https://www.linkedin.com/posts/stefankirschnick_sending-your-ai-clone-instead-of-yourself-activity-7252940220239675393-abCG/

=== 2024/09/13 - blef.fr : OpenAI released 2 new models OpenAI o1-preview and o1-mini

* URL : https://www.blef.fr/data-news-week-24-37/

* Renommage des nouveaux modèles OpenAI : on passe de GPT-x à "o1"
	** o1-preview et o1-mini
	** "OpenAI released 2 new models OpenAI o1-preview and o1-mini — These models brings changes and a breakpoint in the models naming. OpenAI decide to give up on the GPT naming, which means GPT-5 will never be plugged in. GPT paper has been co-authored by 4 person and 3 are not anymore at OpenAI, leaving GPTs also mark a change in paradigm."

* "Coding with OpenAI o1" https://youtu.be/50W4YeQdnSg?si=VGphyxbdZtWB4ZxJ&t=57
	** Cet exemple de codage est très impressionnant
		*** A réfléchir : le réutiliser pour le prochain 12@13 d'état des lieux sur l'IA gen de Softeam

	** o1 starts by thinking before outputting an answer
	** o1 est souvent nommé "reasoning model"
	** "The o1 series brings more “reasoning”, it looks like a pre-prompt that does a chain of thoughts on top of what they already did best."

=== 2024/11/06 : Strategic Insights: Navigating the Definition of AI Agents

* URL : https://7wdata.be/artificial-intelligence/ai-agents-definition/

=== 2024/11/18 : L'essor de l'IA générative fait exploser le bilan carbone des datacenters

*Le nombre de datacenters augmente de 11 % par an.*

L'empreinte carbone des datacenters passe de 16 % à 42 % du bilan total du numérique Dans un avis d'expert, *l'Ademe dit avoir sous-évalué l'impact environnemental des centres données*. Une première estimation ne prenait en compte que ceux situés sur notre territoire. « Or, une partie importante des usages en France sont hébergés à l'étranger. » En intégrant cette composante, comme le fait l'étude de Hubblo, *l'empreinte carbone des datacenters passe de 16 % à 42 % du bilan total du numérique*. Et la part de l'empreinte carbone liée aux terminaux diminue de 79 % à 54 %. Avec l'explosion des usages numériques et la hausse du volume de données - de 20 % par an, *les centres de données pourraient représenter 6% de la consommation d'électricité en France en 2050*.
 
« Le besoin de calcul informatique pour l'IA a été multiplié par un million en six ans et il décuple chaque année », a asséné le patron de Google, Sundar Pichai, le 14 mai. En conséquence, Amazon, Microsoft, Google et Meta (Facebook, Instagram) vont, en 2024, investir 200 milliards de dollars (186 milliards d'euros) en nouvelles infrastructures, soit 45 % de plus qu'en 2023 et 180 % par rapport à 2019, a calculé le cabinet d'analyse de marché Bernstein Research.

*Explosion de la consommation énergétique*

« Ces infrastructures consomment jusqu'à dix fois plus que l'informatique traditionnelle », estime Régis Castagné, directeur général d'Equinix, autre leader du secteur, avec 8,2 milliards de revenus en 2023 et 260 data centers dans le monde. Selon un rapport de Goldman Sachs, la demande en énergie des centres de données augmentera de 160% d'ici à 2030.

Selon une étude Gartner, la demande énergétique des datacenters pour l'intelligence artificielle (IA discriminative et GenAI) augmentera de façon drastique au cours des prochaines années, risquant de dépasser la capacité des fournisseurs d'énergie. Cette demande pourrait contraindre 40 % des centres de données IA à restreindre leurs opérations faute de capacités électriques d'ici 2027. « La croissance explosive des nouveaux centres de données hyperscale pour supporter la GenAI crée une demande insatiable d'électricité, que les fournisseurs ne pourront satisfaire assez rapidement », affirme Bob Johnson, vice-président et analyste chez Gartner. « Cela menace l'approvisionnement électrique et pourrait limiter la croissance de nouveaux centres de données dédiés à la GenAI dès 2026. »

Gartner prévoit que la consommation annuelle pour les serveurs IA atteindra 500 térawattheures (TWh) d'ici 2027, soit 2,6 fois le niveau de 2023. Avec des centres de données de plus en plus grands et énergivores, les pénuries de courant risquent de persister plusieurs années, le temps que de nouvelles infrastructures de transmission et de production énergétique soient déployées. Les prévisions de Gartner indiquent également que cette situation aura un impact sur les coûts. « Les grands utilisateurs d'énergie négocient actuellement avec les principaux producteurs pour garantir des sources de puissance à long terme, indépendamment des demandes du réseau », explique M. Johnson. « En attendant, les prix de l'électricité vont grimper, augmentant ainsi les coûts d'exploitation des modèles de grande taille. » 

*Des hausses d'émission de CO2 en vue*

Les objectifs de durabilité sont également menacés par cette crise. Le cabinet américain anticipe un recours accru aux centrales fossiles pour pallier le déficit énergétique. « La réalité est que l'utilisation accrue des datacenters augmentera les émissions de CO2, compliquant l'atteinte des objectifs de durabilité », conclut M. Johnson. Face à cette perspective, Gartner recommande aux entreprises d'anticiper une hausse des coûts et de repenser leurs objectifs de durabilité pour tenir compte des contraintes énergétiques à venir, tout en explorant des alternatives pour limiter leur consommation. 

(Pour info *les bilans annuels de RSE des entreprises ne tient pas compte des data centers externes* à l'entreprise alors que de plus en plus d'applications et de solutions sont accessibles par le net (ex: chatGPT) avec des data centers par toujours en Europe)

=== 2024/10 : Malt AI Report 2024

* URL : https://trends.malt.com/en/ai-report

* Offre et demande en matière de compétences technologiques associées à l'IA : +
image:20241000_Malt-AI-report_01.jpg[]

* Offre en expertise IA, classée par fonction / rôle : +
image:20241000_Malt-AI-report_02.jpg[]

* Demande en expertise IA, classée par fonction / rôle : +
image:20241000_Malt-AI-report_03.jpg[]


== TALKS, PRÉSENTATIONS, MEETUPS 

=== 2023/07/04 - La stratégie de Saint-Gobain pour le passage à l'échelle des applications d'IA

Vidéo accessible via le Club Azure Insiders : https://info.microsoft.com/FR-AzureAI-VDEO-FY23-04Apr-11-Replay-Saint-Gobain-s-strategy-for-scaling-AI-applications-SRGCM9881_LP02-Thank-You---Standard-Hero.html

.Organisation de l'IT chez Saint-Gobain
image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_01.jpg[]

* 4 accélérateurs techniques : 

    ** *AI Portal* : leverage knowledge in Artificial Intelligence and connects data scientists with each other
	** *AI Lab* & *AI Indus* : 2 platforms that standardize our algorithms to develop and deploy them ever faster in the Cloud.
	** *AI Store* : a "ready-to-use" applications library. Elementary building blocks that enable a new team to create an algorithm, not in 6 months, but in just a few weeks !

image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_02.jpg[]

.AI Indus : to deliver prototypes into Integration / Prod
image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_03.jpg[]

.AI Store : to deploy AI applications at scale
image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_04.jpg[]

.Next main challenges
image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_05.jpg[]

	* AI 4.0
	* *Data sharing* & reuse
	* *AI Citizen*

.AI Lab : services
image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_06.jpg[]

	* Le principal service de ce PaaS est Azure Machine Learning

image:20230330_Club-Azure-Insiders_strategie-Saint-Gobain-passage-echelle-appli-IA_07.jpg[]

* *StreamLit* pour le Front : Stream a définitivement le vent en poupe pour la création du Front de projets / produits associés à l'IA
	** StreamLit est très simple à maîtriser pour monter des fronts simples
	** StreamLit également préconisé car *front en Python* (et Python fait définitivement l'unanimité grâce à sa forte communauté et l'immensité des ressources, docs disponibles)
	** StreamLit par contre ne semble pas être la solution retenue par Saint-Gobain pour les applications internes, apparemment pour raison de sécurité.

=== 2023/11/23 - Commment LVMH déploie l'IA à l'échelle

URL : https://www.lemagit.fr/etude/Comment-LVMH-deploie-lIA-a-lechelle

* La « plateforme Data » du groupe LVMH s'apparente davantage à un framework afin d'accélérer les déploiements de cas d'usage allant de la BI à l'IA dans l'ensemble des Maisons. +
-> Dans plus de 24 Maisons et divisions, cette plateforme repose sur le *Data warehouse cloud BigQuery*.

* En Chine, une dizaine de Maisons s'appuie sur un « écosystème » *Alibaba MaxCompute*.

* Certaines équipes au sein du groupe utilisent l'ensemble des fonctions de *Dataiku*, à savoir la préparation de données, le *feature engineering*, l'intégration du modèle de machine learning, le post-traitement, et le formatage de résultats en direction de systèmes tiers.
	** Dataiku est utilisé « pour effectuer du packaging d'algorithmes de manière centralisée ».
	** « En collaboration avec les Maisons les plus matures qui ont déjà des algorithmes, nous prenons ces briques et nous les rendons modulaires en utilisant, quand le besoin s'en fait sentir, des librairies d'IA avancées : de la vision par ordinateur, des *transformers pour le traitement du langage naturel* et nous commençons à expérimenter les grands modèles de langage et de diffusion ». +
	Ces paquets correspondent à des notebooks contenant le code des modèles et les appels aux librairies. Une fois centralisés, les data scientists et les data engineers peuvent aisément modifier les algorithmes suivant le cahier des charges d'une Maison.

NOTE: À un haut niveau, le *feature engineering* est la pratique qui consiste à transformer des données brutes en la forme la plus appropriée pour un algorithme de machine learning spécifique.

=== 2023/11/21 - BGPN - Petit dej de l'IA - 3e talk
 
Présenté par : 
 
    * Ghislain LABAY côté Hub La Poste
    * l'invité du jour Gilles GUERRAZ : un expert reconnu sur l'IA générative (réalisateur publicitaire et Expert en IA génératives)
    * L'application du mois : ElevenLabs, du text to speech
 
OpenAI : 
 
    * 100 M d'utilisateurs de ChatGPT chaque semaine
    * 2 M de développeurs utilisent les API OpenAI
 
.Lancement des "GPTs"
image:20231121_petit-dej-IA_01.jpg[]
 
    * Les "GPTs" : permettre à tout un chacun de créer facilement des versions de ChatGPT adaptées à ses besoins quotidiens ou pro. +
    Les users peuvent configurer ces assistants virtuels pour qu'ils exécutent des tâches spécifiques et interagissent avec des sources de données externes. +
    Aucune connaissance en programmation n'est nécessaire.
 
    * Un GPT Store pour commercialiser vos GPTs
    * Adobe Dub Dub Dub pour de la traduction en "live" (comme Heygen)
 
    * L'administration française est en train de faire un test avec Anthropic et son LLM Claude.
 
Présentation de Gilles GUERRAZ
 
    * Gilles est réalisation professionnel depuis 2008
 
    * Gilles édite une newsletter (https://iagenerative.substack.com/) et co-anime un podcast sur la vulgarisation sur l'IA générative
    * Gilles anime également un concours de court-métrage en 48h (chaque année début décembre)
    * Gilles utilise beaucoup MidJourney (au moment de la sortie de la v3 de MidJourney, Gilles a trouvé MidJourney bien meilleur en termes de rendu que Dall-E)

=== 2023/12/12 - P'tit déj IA générative La Poste

* *Character.ai* : 
	** URL : https://beta.character.ai
	** à date, c'est la 2e application mobile la plus utilisée aux US avec 6M d'utilisateurs mensuels
		*** derrière ChatGPT
	** 60% des utilisateurs ont entre 18 et 24 ans
	** permet de discuter avec un personnage ayant existé (voire imaginaire), et entraîné sur la base de biographie et autres données (?)
		*** Possibilité pour chacun de créer son avatar

	** L'un des chatbots les plus utilisés est un psychologue
	** Character.ai se positionne donc comme un ami ou un coach
		*** avec un engagement très fort de la part de l'utilisateur : on passe en moyenne 8 min par session sur ChatGPT, contre 25 à 45 min pour Character.ai
	** 193 M$ déjà levés à date, et en recherche de financement. +
	Character.ai est déjà valorisé à 5Mds$

	** Google et surtout Facebook cherchent également à se positionner sur ce secteur.

* Sébastien : présentation de l'IA Conv BGPN
	** GPT 3 plus que 4 pour des raisons de vitesse et de coût
	** si doc chargé, ce n'est QUE pour la session et l'utilisateur connecté
	** plusieurs agents avec leurs propres données vectorisées

* Ronan : pas d'Azure "pour le moment"
	** On veut faire du souverain, donc plutôt du Numspot ou de l'OVH

* Olivier SENOT
	** David GAILLOU par la synthèse des dossiers médicaux
	** instance OpenAI France Azure, uniquement par API
		*** GPT 4
		*** demain sur GPT 4 turbo
		*** déployé pour les Docapostiens
	** scrappeur d'URL pas encore ouvert, par peur d'injection de malwares dans le retour prompt
		*** il y a apparemment des fils Reddit qui expliquent bien la chose
	** QUE le chatbot et la synthèse des documents
	** GitHub Copilot "en cours" de déploiement chez nos populations IT
		*** en train de "patiner un peu" car compliqué côté contrat
	** 17 cas d'usage pour équiper Docaposte en interne pour utiliser le LLM (pour T1 2024)
		*** réponse auto à des AO
		*** Analyse rhétorique des parlementaires

* Sophie : côté Probayes, ils ont un moteur d'inférence
	** Olivier : on n'a "QUE" une base de vecto
		*** moteur d'inférence d'ici à xxx 2024
	** Olivier : et on a pas de modèle on-premise car on a pas de GPU

* Olivier SENOT : tous les mois il a un bench de comparaison des LLM
	** et actuellement GPT 4 arrive tout le temps devant

=== 2024/01/23 - BGPN - Petit dej de l'IA

* Lancement du GPT Store côté OpenAI
	** On peut maintenant créer son propre GPT et le lancer auprès du grand public et le monétiser
	** on peut déjà depuis 2 ou 3 mois créer ses propres GPT MAIS on ne pouvait pas les diffuser auprès du public

* Lancement de Copilot Pro
* et d'ici peu on aura peut-être une nouvelle touche Copilot sur les claviers Windows

* Nabla Copilot, startup française, lève 22 M€
	** anciennement était spécialisé sur la santé des femmes, mais a réussi à étendre son scope grâce à l'IA Gen
		*** compte-rendu médicaux et cryptage des données de santé : faire gagner du temps au médecin quant à ses tâches administratives en fin de journée
	** Derrière Xavier Niel et plusieurs autres investisseurs habitués à investir dans l'IA

* Perplexity vient de lever 70 millions de $ (A VERIFIER)

* CES 2024 : 
	** Swarovski Optics
	** Wizards : partie gratuite puis 15€ / mois pour du prototypage d'applications via l'IA qui est capable d'analyse une image pour créer le visuel associé (A VERIFIER)

* La Poste : test de Office Copilot en cours et quasi terminé, les retours sont à venir (voir Nathalie BROUSSET qui gère le projet côté .COM1)

* Demo de solution basée sur l'IA permettant la création de visuels publicitaires : +
	image:20240123_petit-dej-IA_01.jpg[width=600]
	** Création de maquettes publicitaires
		*** POC en lien avec la DSI IT Innovation & Design d'Offres
	** Par Jean Marie ROBERT, La Poste Solutions Marketing
	** URL : https://ai-advertising.vercel.app/

	** Front : React
	** Back : Python / Mango
	** LLM et text-to-image AI generator : GPT-4 et Dall-E 3

=== 2024/02/27 - BGPN - Petit dej de l'IA

* Application du mois : AskMona, l'IA pour améliorer l'accès à la culture
	** présenté par Marion Carré, cofondatrice de AskMona, auteure et enseignante

* OpenAI annonce Sora en réponse à Google comme générateur de vidéo sur base d'IA gen
	** génération de vidéo jusqu'à 1 min
	** crainte de l'industrie du cinéma
	** uniquement accessible à des beta testeurs aujourd'hui
	** accessible au grand public probablement courant de l'année

* Aujourd'hui Google Bard n'existe plus et a été renommé en Gemini +
image:20240227_petit-dej-IA_01.jpg[]

	** Gemini 1.5 Pro : 1 million de tokens. +
	C'est : 
		*** 1 heure de vidéo
		*** 11 heurs d'audio
		*** 30K lignes de code
		*** 700K mots
	** *Gemini 1.5 Pro* est *capable de chercher une scène dans un film via un prompt* : +
	image:20240227_petit-dej-IA_02.jpg[]

* Mistral accepte une participation minimale de Microsoft pour permettre de diffuser Mistral au sein de certains produits Microsoft

* *Groq* veut faire de l'ombre à NVidia
	** chipset qui se veut plus performant que les GPU de NVidia
	** a levé 300 M$ tout dernièrement

=== 2024/03/19 - P'tit déj IA générative La Poste

* *Devin* : co-développeur dont le but est de réellement "remplacer" un développeur
* Anthropic sort *Claude 3* que les benchmarks donnent meilleurs que GPT-4 dans presque tous les domaines : +
image:20240319_ptit-dej-IA_01.jpg[]

* *Perplexity* lance son *podcast*
    ** Perplexity outil de search (backé par l'IA) un peu comme Google
    ** la voix du podcast a été développée par ElevenLabs

Présentation par *TALKR.IA* par Katya LAINE (la fondatrice et CEO)

=== 2024/04/23 - P'tit déj IA générative La Poste

*Meta*

* Meta "rattrape son retard" avec Llama 3
	** l'objectif est (bien sûr) de l'intégrer à tous leurs produits
	** Ce LLM "serait" plus puissant que GPT-4 et Claude 3
* Chatbot "meta.ai" disponible, mais pas en Europe

*OpenAI*

* GPT-5 serait attendu pour fin de cet été
* Toujours pas de date pour la mise à dispo de Sora
	** Sora qui a été une "claque" pour la création de vidéo via l'IA gen, bien devant ce qui était fait par Runway ML

* MAIS OpenAI a présenté son concurrent de ElevenLabs : *Voice Engine*
	** en 15 sec de votre voix, il est capable de : 
		*** générer de la voix
		*** traduire du texte
		*** pas de date de mise à dispo encore connue

*Apple*

* Retard confirmé "à 1/2 mot" par Apple qui va voir Google pour utiliser Gemini
	** se dirige-t-on vers un partenariat Apple / Google

*NVidia*

* Dévoile le projet *GROOT* pour des robots autonomes

Application présentée : *SUNO.ai* (https://suno.com/)

	* 10 crédits gratuits par mois (jusqu'à 50 chansons environ)

Invité : Adrien Bouhot, Head of Data & AI chez Brut

	* Impact fort de l'IA Gen sur la partie créative du média

=== 2024/04/25 - Tech Rocks : IA en entreprise : Gouvernance et Sécurité des Données

.Ordre du jour
--
L'équipe Tech.Rocks est heureuse de vous convier à un meetup virtuel dédié à IA en entreprise : Gouvernance et Sécurité des Données. 

Nous aurons la chance d'avoir des interventions de :

🎤 Sofia Calcagno, Machine Learning Engineer chez OCTO Technology 
🎤 Marek Kalnik , Cofounder & CTO de Bam

Venez partager et interagir avec nos speakers. Vous aurez la possibilité de lever la main et de monter sur la scène virtuelle si vous le souhaitez.
--

* Marek : on peut vérifier que GitHub Copilot est installé sur la machine ET vérifier sa configuration pour qu'il ne remonte PAS d'info
* Marek : il y a des moyens de "jail breaker" un GPT custom, et de récupérer les données montées dedans
* Sofia : très bon retour sur Llama3

=== 2024/05/13 - OpenAI : Introducing GPT-4o

* URL : https://www.youtube.com/watch?v=DQacCB9tDaw

* Les grands axes : 
	** *multimodal* : texte, images, vidéo et audio
		*** "o" voulant dire "omnicanal"
	** *GPT-4o* : 2x faster, 50% cheaper and 5x higher rate limits compared to GPT-4 Turbo

	** Le *temps de réponse* de GPT-4o est de *0.3s*, contre plus de 3s pour le *mode voix* des précédents modèles.
		*** Cf l'article https://medium.com/@Avis-AI-Essentials/le-nouveau-gpt-4o-dopenai-peut-chanter-et-r%C3%A9pondre-en-temps-r%C3%A9el-57128cb09a0a[] : +
		"Avant GPT-4o, le mode voix de ChatGPT reposait sur un processus en trois étapes : l'audio était transcrit en texte, puis traité par GPT-3.5 ou GPT-4, et enfin converti en audio. Cela entraînait des temps de réponse plus lents (2,8 secondes pour GPT-3.5 et 5,4 secondes pour GPT-4) et une perte d'informations comme le ton et le bruit de fond. +
		GPT-4o utilise un seul modèle d'IA formé pour gérer le texte, les images et l'audio en même temps. Ce traitement de bout en bout permet à GPT-4o de répondre beaucoup plus rapidement et de manière plus naturelle, en captant des nuances que les modèles précédents manqueraient."
	** Cf https://community.openai.com/t/gpt-4o-tokens-per-second-comparable-to-gpt-3-5-turbo-data-and-analysis/768559[] : +
	"The *gpt-35-turbo-0125 model* has the *highest mean tokens per second* (TPS) (67.83), indicating it is the fastest among the three models tested. This is followed by *gpt-4o-2024-05-13* with a *mean of 63.32 tokens per second*. The *gpt-4-turbo-2024-04-09* model lags behind with a *significantly lower mean of 35.68 tokens per second*."

=== 2024/05/14 - Google I/O

* La video de la Google I/O : https://www.youtube.com/watch?v=XEzRZ35urlk 
	** Un rien longue, 2h de talk à partir de 1h d'enreg (je ne sais pas pourquoi ils ont gardé le début), mais voici un bon résumé : https://www.youtube.com/watch?v=1y8lcwLw3EQ

* D'ici très peu de temps : Gemini Advanced -> passage à 2M de tokens... On peut lui donner sa thèse à analyser sans besoin de RAG +
image:20240514_Google-IO_01.jpg[]
image:20240514_Google-IO_02.jpg[]
	** Et avec des coûts qui s'écroulent (à récupérer)

* LearnLM : un LLM fine-tuned pour l'apprentissage

=== 2024/06/04 - P'tit déj IA générative La Poste

* Ce p'tit déjà sera avant tout un REX de Viva Tech

* Les news de l'IA Gen : 
	
	** Les annonces de Google lors de la dernière *Google I/O* : +
	image:20240604_petit-dej-IA_01.jpg[]
		*** Gemini 1.5 : 2M de tokens
		*** intégration de Gemini à Google Search
		*** projet Astra : présentation de la vidéo officielle 
+
video::nXVvvRhiGjI[youtube, width=640, height=480]

			**** Analyse de vidéo en temps réel par Astra
		*** Création d'un store Google Gemini où l'on va pouvoir créer ses propres "gem"
		*** Annonce de leur générateur d'images Imagen 3

	** Claude 3 devient disponible en Europe

	** Levée de fond de la société française "H", anciennement appelée "Holistic"
		*** un futur concurrent de Mistral

		*** *H vient de lever 220 M€* auprès de Google Schmidt, Xavier Niel, etc. : https://www.btob-leaders.com/h-leve-200-millions-dollars-ia
			**** "Le tour de table a été mené par le capital-risqueur américain Accel, avec la participation d'Amazon et de la société new-yorkaise de logiciels d'automatisation robotique UiPath.
			La banque publique française Bpifrance et les investisseurs parisiens Eurazeo, Elaia Partners, Aglaé Ventures et Motier Ventures ont également pris part à cette levée de fonds, tout comme Eric Schmidt, proche de l'ancien PDG de Google, et le milliardaire français Xavier Niel. Le capital-risqueur américain FirstMark et l'investisseur suédois Creandum complètent la liste déjà bien fournie des investisseurs qui croient en ce projet."

		*** avec des chercheurs travaillant sur le développement d'une AIG, une IA "générale"
		
	** Et Mistral en parallèle est en train de boucler une nouvelle levée de fond de 600 M€

	** NVidia va plus que bien... +
	image:20240604_petit-dej-IA_02.jpg[]
	image:20240604_petit-dej-IA_03.jpg[]
		*** en 1 an, +262% de résultats...

* REX sur Viva Tech : 

	** 13500 startups
	** 2800 exposants
	** 165 000 visiteurs, contre moins de 150 000 pour le CES Las Vegas
		*** donc le plus gros évènement tech au monde
	** 37% de contenu sur l'IA
	
	** Pas de Google sur le salon
	** AWS très présent, qui a mis en avant toutes les sociétés et solutions présentes sur leur plateforme Bedrock : Hugging Face, Anthropic, etc.

	** "Beink Dream" (https://www.beink.fr/[]) boîte française permettant de transformer ses croquis à la main en un dessin bien mieux fini et correspondant à la forme souhaitée
	** Lipitt : mixe ChatGPT, ElevenLabs et techno / solutions de synchronisation des lèvres afin de traduire n'importe quelle langue grâce à l'IA
	** Biomemory : veut stocker des données sur de l'ADN

=== 2024/07/02 - P'tit déj IA générative La Poste

* Les 3 applications d'IA Gen les plus utilisées aujourd'hui : 
	1. ChatGPT
	2. Gemini
	3. Character.ai

* La gen Z se moque de savoir si un influenceur est "réel" ou pas

.CIAO : optimisation de la réponse aux AO à l'aide de l'IA Gen
image:20240702_petit-dej-IA_01.jpg[]

	* *1er cas d'usage*, *CIAO 1* : en production depuis 2022/10
		** Consiste à *identifier les avis de marché publiés* (le faire beaucoup plus vite)
			*** 3000 AOs financiers remontant tous les jours : on passe d'1 journée à les identifier à 1/2 journée
		** Travail avec Probayes et développement d'un algorithme permettant de scorer les AOs

	* *2e cas d'usage*, *CIAO 2* : en POC depuis 2023/09 +
	image:20240702_petit-dej-IA_02.jpg[]

		** Consiste à *détecter des projets d'achat en amont des appels d'offres*
			*** Permet au client de pouvoir adapter son cahier des charges par rapport à nos solutions

	* *3e cas d'usage*, *CIAO 3* : en POC +
	image:20240702_petit-dej-IA_03.jpg[]

		** Consiste à *automatiser l'élaboration de la réponse technique*
		** Objectif : améliorer la qualité et diviser par 2 le temps de création de la réponse à l'AO
		** Permet d'avoir un 1er jet de réponse, que le vendeur va devoir compléter (le vendeur a encore une action à faire)
		** le niveau actuellemnet atteint par l'IA est celui d'un "vendeur débutant"

=== 2024/09/10 - BGPN - P'tit déj de l'IA générative La Poste

Actualités : 

	* Midjourney offre maintenant une interface web complète, éliminant l'obligation d'utiliser Discord
		** Pour pouvoir l'utiliser, il faut avoir généré 10 images dans Discord

* Application du mois : FLUX https://flux-ai.io/
	** Solution allemande
	** Permet de générer des images
	** une alternative à Midjourney, même si ce dernier reste devant

.Comparaison Flux vs Midjourney
image:20240910_petit-dej-IA_01.jpg[]

	** Partenariat entre Grok (ex-Twitter) et Flux

* Il a été un peu question des *LoRA* (*Low-Rank Adaptation*)
* Explication sur ce qu'est le LoRA (https://www.run.ai/guides/generative-ai/lora-fine-tuning) : +
	
	** LoRA modifies the fine-tuning process by freezing the original model weights and applying changes to a *separate set of weights*, which are then *added to the original parameters*. LoRA transforms the model parameters into a lower-rank dimension, reducing the number of parameters that need training, thus speeding up the process and lowering costs.

	** This method is particularly useful in scenarios where multiple clients need fine-tuned models for different applications, as it allows for *creating a set of weights for each specific use case* without the need for separate models.

	** LoRA makes it possible to run a specialized LLM model on a single machine

.Différences entre Fine tuning "classique" et LoRA
[NOTE]
====
*Fine-tuning traditionnel* :

	* *Modification de tous les paramètres* : Le fine-tuning traditionnel consiste à ajuster tous les paramètres du modèle sur un nouveau jeu de données. Cela permet une adaptation très fine du modèle, mais nécessite beaucoup de ressources de calcul et peut entraîner un phénomène d'oubli catastrophique (le modèle peut oublier des informations apprises précédemment).
	* *Jeu de données important* : Pour obtenir de bons résultats, le jeu de données de fine-tuning doit être suffisamment grand et représentatif de la tâche à accomplir.

*LoRA (Low-Rank Adaptation)* :

	*Modification de paramètres spécifiques* : LoRA ne modifie qu'une petite partie des paramètres du modèle, en ajoutant des matrices de rang faible. Cela permet de réduire considérablement le nombre de paramètres à ajuster et donc le coût de calcul.
	*Moins de données* : LoRA peut être efficace avec des jeux de données plus petits, car il se concentre sur les parties du modèle qui sont les plus pertinentes pour la tâche spécifique.
	*Préserve les connaissances générales* : En ne modifiant qu'une partie du modèle, LoRA est moins susceptible d'oublier les connaissances générales acquises lors de l'entraînement initial.
====

* Exemple de use case pour adapter un modèle de langage au domaine de la biologie marine : 

	** Si vous effectuez un *fine-tuning traditionnel* sur un jeu de données très spécifique à la biologie marine, vous obtiendrez un modèle qui sera très performant sur cette tâche, mais qui pourrait *perdre en généralité*. +
	En d'autres termes, le modèle pourrait devenir *moins bon pour répondre à des questions qui ne sont pas directement liées à la biologie marine*.

	** Avec *LoRA*, vous pouvez obtenir un modèle qui est tout aussi performant sur la biologie marine, mais qui conserve une *meilleure compréhension générale du langage*. +
	Cela est dû au fait que *LoRA ne modifie que les parties du modèle qui sont les plus pertinentes pour la tâche spécifique*, laissant intactes les autres parties du modèle.

=== 2024/10/08 - BGPN - P'tit déj de l'IA générative La Poste

* On reçoit Olivier BERTIN, directeur Marketing et Innovation du groupe Isoskèle

*Actualités de l'IA*

	* *ChatGPT Adavanced Voice* est lancée, mais pas encore dispo en Europe du fait du RGPD
		** Mais accessible via un VPN
		** Use Cases très nombreux : 
			*** 

	* *NotebookLM de Google* : outil gratuit permettant d'uploader des docs dans un répertoire que l'on peut prompter avec Gemini +
	image:20241008_ptit-dej-IA_01.jpg[]

	* *SLM* : Small Language Model : des petits modèles que l'on peut embarquer sur mobile et qui peuvent fonctionner déconnectées

	* Les artistes réclament un label pour protéger le travail humain

	* ChatGPT o1
		** Ce nouveau modèle o1 serait capable de "raisonner" (mais pas non plus comme un humain) +
		image:20241008_ptit-dej-IA_02.jpg[]
			*** Version toujous en preview
			*** évite les hallucinations
			*** plus lente
			*** OpenAI dit qu'elle a 120 de QI et le niveau d'un PhD

	* *Canvas* sur ChatGPT (version payante)
		** permet de travailler dans un environnement contextualisé

	* plugin "Liner" de Chrome pour souligner des URLs 
		** https://getliner.com/


	* vidéo : https://www.youtube.com/watch?v=AR4dRtzFvxM

*Présentation de Olivier BERTIN*

	* Isoskèle appartient au groupe La Poste
	* Olivier 38 ans de marketing

	* Développement de la plateforme SafeGPT : permettre un accès aux LLM via un environnement sécurisé
		** Isoskèle dispose d'un tenant Azure distinct de celui de La Poste
		** https://safegpt.nl/en/ : accessible uniquement aux employés Isoskèle (jusqu'à maintenant)

	* Fabien Barbaud : CTO d'Isoskèle a mis en place les mesures de sécurité garantissant cet environnement sécurisé
		** Thomas : j'ai posé la question mais Olivier n'a pas les compétences tech pour donner plus de détails à ce niveau, il faut contacter Fabien.

	* SafeGPT utilise libreChat pour répliquer l'interface de ChatGPT

	* L'IA est comme le GPS dans les voitures : "juste" un assistant, MAIS dont on ne peut plus se passer

	* Gros changement à venir du côté du Search
		** Olivier n'utilise plus Google mais uniquement *Perplexity* et d'autres équivalents

=== 2024/10/22 - Datacraft - Monitoring et Évaluation des systèmes LLM

* URL : https://www.youtube.com/watch?v=jqBsrr74AHQ

TO BE COMPLETED

=== 2024/11/05 - BGPN - P'tit déj de l'IA générative La Poste

NEWS par Abdelmajid Ben Abid, consultant Senior en IA Générative au HUB Institute

.Rappels sur les générateurs de texte IA Gen du moment
image:20241105_ptit-dej-IA_01.jpg[]

	* *NotebookLM* de Google : https://notebooklm.google.com/
		** permet via la fonctionnalité "Aperçu audio" / "générer" de générer un podcast entre 2 personnes sur le sujet de la recherche +
		image:20241105_ptit-dej-IA_02.jpg[]
			*** Pour le moment que en anglais

.Rappels sur les générateurs d'audio / voix
image:20241105_ptit-dej-IA_03.jpg[]

	* Advanced Voice Mode avec ChatGPT : émotion vocale en input et output
		** "donne-moi une recette de pizza en te faisant attaquer par des guêpes"

.Rappels sur les outils de génération d'images
image:20241105_ptit-dej-IA_04.jpg[]

	* Ideogram et Napkin
		** ChatGPT pour générer des diagrammes c'est la misère, MAIS Napkin est bien meilleur à ce sujet

Présentation de Nicolas Borgis, Directeur de l'engagement Digital chez EPAM : 

	* Epam : generative AI for SDLC
		** SDLC : Software Development LifeCycle

	* Epam est une société américaine côtée et inconnue
		** "enable the world to be more competitive while helping our client successfully adapt"
		** en gros, une société de conseil
		** fondée il y a 31 ans par une bande de copains ayant fui l'Union Soviétique +
		image:20241105_ptit-dej-IA_05.jpg[]

	* Le 1er client d'Epam aujourd'hui est Google (c'est un client, PAS un partenaire)

	* Expedia est en train d'outsourcer une partie de ses équipes d'Amérique du Nord vers l'Amérique du Sud (coûte 3x moins)

.GenAI Trends: From discussions to 90+ Client Programs
image:20241105_ptit-dej-IA_06.jpg[]

.4 leviers clés pour devenir une "AI / GenAI-enabled Organization"
image:20241105_ptit-dej-IA_07.jpg[]

.Overview of AI Capabilities
image:20241105_ptit-dej-IA_08.jpg[]

	* Les outils open source créés par Epam : +
	image:20241105_ptit-dej-IA_09.jpg[]

		** Plus d'infos sur https://solutionshub.epam.com/

		** Focus sur Epam DIAL : unified Generative AI orchestration Platform +
		image:20241105_ptit-dej-IA_10.jpg[]

	* Epam coréalise le moteur Unreal Engine ?!!

	* Toutes les phases qui vont de "j'ai une idée" à "je vais en prod" : +
	image:20241105_ptit-dej-IA_11.jpg[]

		** en "points de couleur", vous voyez tous les points où la GenAI peut aider les humains à faire mieux
	
	* Focus sur EliteA : AI Collaboration Platform for Teams +
	image:20241105_ptit-dej-IA_12.jpg[]

		** Intégration avec Chrome, Visual Studio Code, IntelliJ, etc.

.End to End delivery Process Accelerated with AI Agents, Copilots and tools
image:20241105_ptit-dej-IA_13.jpg[]

.Cas d'usage réel de SDLC chez Canadian Tire : augmentation des équipes par l'IA
image:20241105_ptit-dej-IA_14.jpg[]

=== 2024/11/13 - Hub Institute avec La Poste (communauté Data Science) : Les technologies d'orchestration de modèles d'IA

* Présentation par Thibaut de la Grand'rive, cofondateur de Delos Intelligence

Ordre du jour : +
J'ai le plaisir de vous relayer l'invitation à cette Master Class technique sur les technologies d'orchestration des modèles d'IA à l'ère post-RAG.

* "Masterclass assez technique"

* *Modèle d'orchestration* : un algo permettant de combiner un ou plusieurs modèles d'IA générative, avec des techno classiques pour effectuer des actions précises
	** La question sous-jacente : "Comment on vient interroger, en parallèle, plusieurs modèles de langages"

* MMLU comme benchmark très connu (le plus connu) pour évaluer les performances des LLMs

*  Perf / coût d'exploitation / vitesse d'inférence / sécurité

* Limite du RAG : très mauvais pour les tâches de résumé

* Cet article résume la présentation de Thibaut de la Grand'rive, cofondateur de Delos Intelligence : +
https://www.qant.tech/evenement/thibaut-de-la-grand-rive-il-faut-maintenant-depasser-la-rag/fr
	** il est surtout question de sa vision d'un système "post RAG"
	** "Dès l'été 2023, les ingénieurs de Delos réfléchissent au « RAG de demain » et aboutissent à ce que Thibaut de la Grand'rive présente désormais comme le « Post-RAG ». Agnostique aux modèles de langage, le Post-RAG peut se fonder sur Mistral Large, Claude, GPT-4o, etc. : « En fonction du type de question qui est posée, notre technologie va appeler une fonction de recherche différente, des agents autonomes vont comprendre en fonction de la question posée la fonction de recherche à appeler ». Grâce à ses outils, Delos ambitionne de proposer une offre complète à ses clients : « A l'heure de l'IA générative, il ne faut pas se réduire à une seule application » explique Thibaut de la Grand'rive : « Nous voulons tout centraliser en un seul abonnement »."

.Fonctionnement de Cosmos
image:20241113_cosmos-fonctionnement_01.png[]

Conclusion : je dois bien reconnaître que j'ai été déçu par cette présentation, trop light et contenant plusieurs affirmations très discutables selon moi

== RESSOURCES SUR L'IA GENERATIVE

* La chaîne YouTube "Applied AI" de Pierre BITTNER : https://www.youtube.com/@pierrebittner
	** J'ai déjà eu l'occasion de travailler avec Pierre lors d'une mission à la SGCIB (Pierre travaillant pour FINAXYS)





 